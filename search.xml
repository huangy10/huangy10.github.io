<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Docker Volume的权限问题]]></title>
    <url>%2Fposts%2F25188%2F</url>
    <content type="text"><![CDATA[这里我们要解决的是使用Docker过程中常见的Volume权限问题。具体而言，当我们用-v将宿主机的路径绑定到Docker镜像的内部路径时，有时候会导致Docker镜像缺少对这个目录的访问权限，从而导致进程出错。 Why 当我们绑定宿主目录到镜像时，如果该目录不存在，Docker也会自动创建该目录。这种方式创建出来的目录的拥有者是root用户。如果该目录已经存在，那么其拥有者就取决于宿主配置的情况了。 由于Docker内部的用户空间和宿主的用户空间是独立的，如果镜像内运行进程的用户和宿主目录的拥有者不符合，就会出现权限问题。 How to solve it 由于镜像内和宿主的用户名空间是不同的，所以通过用户名的方式来变更宿主目录的所有权会失效。然而，事实上用户系统是通过uid来标识不同的用户的，我们只需要将宿主的路径的拥护者改为镜像内用户相通的uid即可。镜像内用户的uid可以通过如下方式查看，例如： 12jovyan@8fed6b266a3c:~$ iduid=1000(jovyan) gid=100(users) groups=100(users) 继而再修改宿主机上对应目录的拥有者： 1sudo chown -R 1000 /path/to/volume Further Research 上面的方法可以解决Volume访问权限的问题，不过会产生潜在的漏洞。从镜像内获得的uid在宿主上可能表示的是不同的用户，在宿主机上修改目录的拥有者会导致数据被同一服务器上的其他用户访问，带来安全性上的问题。 另一方面，如果有多个镜像需要共享一个Volume，而他们内部的运行用户的uid不同的话，就需要在宿主上进行更加复杂的用户以及组的配置。 更优雅的执行方法有下面两种： Use Named Volume Named Volumes 由容器自行配置权限问题 Reference 谈谈 Docker Volume 之权限管理（一） What is the (best) way to manage permissions for Docker shared volumes? Why Docker Data Containers (Volumes!) are Good Use volumes Different Types of Volumes]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>debug</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书破万卷,下笔如有神]]></title>
    <url>%2Fposts%2F60435%2F</url>
    <content type="text"><![CDATA[能够获得暴利的职业，都有一个共同特点：可扩展性（scaling），一次劳动可以服务成千上万的人。 软件、电影、游戏行业都具有可扩展性，作品的生产成本是固定的，但可以被消费无数次，所以有巨大的获利空间，创造出许许多多的富豪。另一方面，理发师、厨师、出租车司机一次劳动，只能服务少数几个人，就不具有可扩展性，很难获得暴利，生存得很辛苦。 最近，我读到美国一个风险投资家的文章。他说了一句发人深思的话： &quot;写作是最具可扩展性的活动。你呆在家里，不去参加活动/会议，只是在网上写下自己的想法，然后你就具有了最好的可扩展性。&quot; 我想了一下，还真是这样。你写了一篇文章，想让其他人看到，只要到处张贴就行了。每次转贴，就是扩展了一次。这比其他产品的扩展容易多了。面包师傅想要更多的人尝到自己的面包，只能多开面包店；网站要扩展，只能购买更多的服务器。相比之下，文字的扩展简直是零成本。 大公司每年花费数十亿美元用于广告，以求人们关注他们的产品。但是，一个好的作家可以免费获得这种扩展性。这就是为什么你应该把自己的想法写下来的原因，这么好的免费传播渠道，为什么不用呢？你以为，写下来不会有人看。错，其实是有人会看到的，如果他们觉得有价值，就会帮你传播出去。 这篇文章转载自阮一峰的博客。这篇文章其实说了一个非常简洁明了却价值巨大的道理，也给我们启示：我们应该如何规划自己的职业道路。只是靠出售自己的时间，即便是清北的同学，也只是能做到一个尚算富裕，但是辛苦中产阶级。要更上一层楼，还是需要手握资本。而怎么获得资本呢？其实就是靠文章里说的“可扩展性的工作”。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandoc渲染引擎导致Hexo Tag渲染失败的临时解决办法]]></title>
    <url>%2Fposts%2F62502%2F</url>
    <content type="text"><![CDATA[在Hexo+Next: 使用Latex公式这篇文章中我发现在使用Pandoc作为Hexo的渲染引擎时，Hexo的标签功能会有问题，具体表现为Hexo的标签内部的内容会输出markdown源码，而非渲染后的html。 问题研究 经过我的研究，这是因为hexo-render-pandoc在注册自己的renderer时，只注册了异步渲染的renderer，而没有注册同步渲染的renderer，而Hexo的标签中主要是用同步renderer。以当时我使用的NexT的note标签为例。其实现代码为： 12345678910'use strict';function postNote(args, content) &#123; return `&lt;div class="note $&#123;args.join(' ')&#125;"&gt; $&#123;hexo.render.renderSync(&#123;text: content, engine: 'markdown'&#125;).split('\n').join('')&#125; &lt;/div&gt;`;&#125;hexo.extend.tag.register('note', postNote, &#123;ends: true, async: true&#125;);hexo.extend.tag.register('subnote', postNote, &#123;ends: true, async: true&#125;); 由于没有注册同步渲染器，这里的hexo.render.renderSync渲染会失败，从而返回的是content中的原本内容，也即Markdown形式的源码。 解决办法 彻底的解决办法，自然是在hexo-render-pandoc中同时注册同步渲染器。不过我自己尝试之后发现作为同步渲染器，pandoc和Hexo使用模板引擎貌似有冲突。更细致深入的修改最好还是由原作者来进行（我已经提交了Issue）。 这里我给出一个临时的解决办法：既然hexo-render-pandoc只注册了异步渲染代码，那么我们在Tag的实现代码中调用异步渲染的接口就可以了。仍然以NexT主题的note标签为例，可以将代码修改成： 12345678910111213141516'use strict';function postNote(args, content) &#123; return hexo.render.render(&#123;text: content, engine: 'markdown'&#125;) .then(function (res) &#123; return `&lt;div class="note $&#123;args.join(' ')&#125;"&gt; $&#123;res.split('\n').join('')&#125; &lt;/div&gt;` &#125;) // return `&lt;div class="note $&#123;args.join(' ')&#125;"&gt; // $&#123;hexo.render.renderSync(&#123;text: content, engine: 'markdown'&#125;).split('\n').join('')&#125; // &lt;/div&gt;`;&#125;hexo.extend.tag.register('note', postNote, &#123;ends: true, async: true&#125;);hexo.extend.tag.register('subnote', postNote, &#123;ends: true, async: true&#125;); 经过这样修改就可以了。不过这种方法仍然只是权宜之计，要是去修改每个Tag的实现，就太繁琐了。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Next: 使用Latex公式]]></title>
    <url>%2Fposts%2F20215%2F</url>
    <content type="text"><![CDATA[这次更换主题的很大一个动因就是因为在NexT这个主题上，开启Latex的支持很方便。网上关于这方面的文章其实不少，但是大部分都不全面，照本宣科下来，很可能不能用。这些教程一般就给了_config.yml文件的配置以及pandoc依赖安装，但是一些关键细节缺失了。这篇文章里我梳理了一下整个流程。 0. Reference 英语好的话，其实可以尝试直接阅读官方文档。 1. Install Dependencies Next支持mathjax和katex两种渲染方式，其中katex的速度更快，但是对于Latex的支持有一定的限制。所以除非你的博客数量实在是过于庞大，不然就可以直接使用mathjax。 mathjax可以选用下面两种渲染引擎的中的任一一种 hexo-renderer-kramed hexo-render-pandoc 使用hexo-render-pandoc还需要安装pandoc渲染引擎。其安装方法可以参考 pandoc官网。如果在macOS上可以使用 Homebrew安装. 这里以pandoc为例： 123# 需要先卸载默认的渲染引擎npm un hexo-renderer-marked --savenpm i hexo-renderer-pandoc --save 替换渲染器之后会导致NexT note功能出现问题，note内的元素内容无法渲染，会输出markdown源代码。 这个问题我在hexo-render-pandoc上提了一个Issue，看原作者什么时候能够更新解决吧。 2. Configuration 配置NexT主题的_config.yml文件 12345math: enable: true ... engine: mathjax #engine: katex 很多文章都漏掉了在配置中一个重要的信息：在主题配置math下有一个名为per_page的选项，其值为true或者false。这个选项用来控制是否对每个篇文章都渲染数学公式。默认情况下是true，这意味只对Front Matter中含有mathjax: true的文章进行公式渲染。将per_page设置为false，则会对每一篇文章都尝试进行公式渲染。 由于公式渲染时一个很费时的操作，因此还是保持默认配置，通过Front Matter进行渲染控制. 3. How to use 3.1 行内嵌套公式 如：质能方程\(e=mc^2\) 1如：质能方程$e=mc^2$ 3.2 独占一行的公式 如： \[ 1=\sum_{i=0}^{m}\sum_{k=0}^{W_i-1}b_{i,k}=\sum_{i=0}^{m}b_{i,0}\sum_{k=0}^{W_i-1}\frac{W_i-k}{W_i}=\sum_{i=0}^{m}b_{i,0}\frac{W_i+1}{2}\\ =\frac{b_{0,0}}{2}\left[W\left(\sum_{i=0}^{m-1}(2p)^i+\frac{(2p)^m}{1-p}\right) + \frac{1}{1-p}\right] \] 12345如：$$1=\sum_&#123;i=0&#125;^&#123;m&#125;\sum_&#123;k=0&#125;^&#123;W_i-1&#125;b_&#123;i,k&#125;=\sum_&#123;i=0&#125;^&#123;m&#125;b_&#123;i,0&#125;\sum_&#123;k=0&#125;^&#123;W_i-1&#125;\frac&#123;W_i-k&#125;&#123;W_i&#125;=\sum_&#123;i=0&#125;^&#123;m&#125;b_&#123;i,0&#125;\frac&#123;W_i+1&#125;&#123;2&#125;\\=\frac&#123;b_&#123;0,0&#125;&#125;&#123;2&#125;\left[W\left(\sum_&#123;i=0&#125;^&#123;m-1&#125;(2p)^i+\frac&#123;(2p)^m&#125;&#123;1-p&#125;\right) + \frac&#123;1&#125;&#123;1-p&#125;\right]$$ 更多latex的使用方法，请参考官方文档]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华GPA事件备份:2019.04.16]]></title>
    <url>%2Fposts%2F34235%2F</url>
    <content type="text"><![CDATA[大图预警]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haproxy支持Ipv6]]></title>
    <url>%2Fposts%2F12489%2F</url>
    <content type="text"><![CDATA[Haproxy Haproxy is a reliable, high performance TCP/HTTP Load Balancer 这是官网对于Haproxy的介绍，其作用的类似于Nginx，是一个均衡负载的服务器。其相比于Nginx的好处是其代理TCP流量的功能配置起来非常的简单。我这里主要拿Haproxy来配置Shadowsocks的跳板机。 前一段时间，GFW的墙好像又加高了，很多时候在教育网外连接服务器不是很可靠。所以我考虑干脆在教育网环境下做一个跳板服务器，这样在外面可以先跳到教育网，然后再从教育网过墙。 教育网的另一个好处是有IPv6。貌似IPv6上面的拦截比较弱，而且，绝大多数的高校对于IPv6都是免流量费的。因此，我们可以从IPv4公口进，然后走IPv6出。 How to 不过，问题是通过apt安装的haproxy是不支持IPv6的！ 我们只能自己动手从源码编译了： 12345wget http://www.haproxy.org/download/1.7/src/haproxy-1.7.2.tar.gztar -xzf haproxy-1.7.2.tar.gzcd haproxy-1.7.2make TARGET=linux2626 USE_GETADDRINFO=1sudo make install]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>ss</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[政史:珍珠港事件前日方决策过程梳理]]></title>
    <url>%2Fposts%2F10462%2F</url>
    <content type="text"><![CDATA[在知乎上看到的比较好的回答，作为备份放在这里： 原文链接：https://www.zhihu.com/question/306368870/answer/639051842 archive.is上的备份网页：http://archive.is/4dOL3 珍珠港俯视图（1941年10月30日） 以下是原文内容： 因为再不突袭，日本人这大东亚战争就算是白打了。 咱们这里需要补充一个小知识，在20世纪30年代末，日本的能源结构是这样的：80%的石油来自美国，10%的石油来自东印度群岛，只有7%左右的石油可以自给。那么问题来了，日本从918开始折腾到40年，找到能替代美国的石油生产地了么？ 没有。不仅石油高度依赖美国，铁和各种军需物资都严重依赖美国，甚至可以这么说，要是没有美国人提供的这些物资，日本这侵华战争就根本打不起来。 1937年美国对日出口总值为2.89亿美元,其中石油、精炼油、废钢铁、原棉这四项战略物资就达1,42亿美元,约占二分之一。以石油一项而论,日本所需石油来自美国的份额,1937年占80%,1939年占85%。——齐世荣.绥靖政策研究.,北京：首都师范大学出版社,1998：413 据统计，1937－1938年，日本从美国进口的军需品占其军需品总进口额的55%。1937年，美对日废钢铁的出口量是1931年的40倍之多。——杨玉圣.中国人的美国观.上海: 复旦大学出版社，1997：152 （1937、1938年日本）从美国输入铁合金为77.53%和82.71%,铜的比例高达95.18%和90.89%,煤油及其产品为6.271%和65.57%,汽车及零件为9.241%和64%,飞机及零件为70.19%和7.692%,金属工作母机为69.53%和67.09%。——沈庆林.中国抗战时期的国际援助.上海人民出版社,2000：53 这就是二战中最讽刺的地方，美国人是日本人在二战前期最主要石油来源国，而且没有之一。日本人觉得不能任由老美这么掐着自己的脖子，于是1934年出台了《石油工业法》表示要加强本国石油产业建设，效果……一般吧；然后37年又搞了个《合成油法案》，表示要开动大日本帝国先进之科技手段以煤改油，效果……更一般。 考虑到1937年日本的财政收入才47亿日元，而以当时的汇率来看大概3日元可以折合1美元，大家可以感受一下每年日美之间几亿美元的进口额意味着什么。而更倒霉的是虽然侵华战争开始以后日军进展极其顺利，然而中国是个贫穷的农业国，重工业基础极其薄弱，而工业建设又是个耗时巨大、烧钱极多的活儿……所以日本人十分郁闷地发现自己这仗是越打越大，然而钱却都进了美国人的兜。 这就是为什么37年日本人在扬子江上炸了美国船，罗斯福把这事按下去的原因之一——顺便一提，日本人为了平事掏出来了2214007.36刀，1937年的两百万美元啊……日本人在占领区甚至搞了一次“抵制美货”的闹剧，然而美国人对此并不在意：有本事你抵制我的石油啊？ 美国国内群众此时对日本人的反感情绪已经是十分强烈了，甚至有几百名学生代表参与了焚烧日本丝绸的行动。等到了1938年美国政府觉得实在不能再这么容忍日本人了！必须上点手段了！于是政府向上百家工厂写信：建议不要跟日本人做生意。 这就是赫赫有名的“道义禁运” 6月11日,赫尔在记者招待上公开谴贵对和平居民的空袭轰炸,随后他写给美国148家注册出口飞机和飞机部件的厂家,表示:政府强烈反对把飞机和航空设备出售给世界上任何对和平居民进行轰炸的国家——赫尔回忆录·第一卷：569 道义禁运的效果极其明显，立竿见影，日本人37年从美国进口的飞机及部件达到248.4万美元，38年为1745.4万美元，增长了7倍。 这么拖拖拖一直拖到39年重庆轰炸，美国人民一看艾玛这太惨了，咱们真的不能再卖给日本人石油了，罗斯福表示那不成啊，你不卖给他石油了他狗急跳墙去打英荷东印度群岛怎么办？为了避免战争扩大咱们还是继续做生意吧…… 对日本人来讲，事情非常尴尬——你要是想继续从美国人手里拿到物资，就必须按照美国人的意思，控制战争规模；而你想控制战争规模又控制不下来，TG在敌后遍地开花，老蒋死活就不投降，你占领的地方地大物博可就是没有好用的石油，重工业基础又弱到不行。所以日本人思前想后，最后还是向东南亚伸出了魔爪。 1939年2月，日本占领海南岛；3月，日本人又搞定了距马尼拉700英里的南沙群岛；6月，派兵封锁天津英租界，7月强迫英国人跟自己一起建设“东亚新秩序”，正在欧洲被希特勒搞得焦头烂额的英国人几乎没怎么犹豫，就在7月24号跟日本人签订了“有田——克莱琪协定”，承认了日本在中国有“特殊需要”。 这下美国人终于坐不住了，7月26号美国政府正式通知日本没，咱们那个美日商约即将在六个月后废止——半年时间，你自己想想清楚，到底还要不要铁和石油了。日本人终于发现这自己扛不住啊！赶紧还是跟美国人谈谈吧，于是9月25日，海军稳健派、熟悉米英鬼畜内部动向之大将野村吉三郎任专职外相，开始跟美国进行谈判，美国人说这事好办，你们开放长江下游、尊重我们在华权利，有钱大伙一起赚嘛！只要你们肯把中国的利益让出来一点，咱们这个商约还是可以再签的。 未果。 这期间的态势十分有趣，日本人在诺门坎吃了大败仗，彻底打消了北进的念头；敌后大规模扫荡、扫荡、再扫荡，八路就是扫不干净；正面战场进入相持状态，长沙会战、随枣会战都没能达成预定的战略目标，日本国内的经济开始遭不住了。 美国人此时反而比较克制，由于罗斯福担心“再进一步就会激怒日本”，所以1940年1月日美商约失效之后两国的贸易竟然还在诡异的继续着，然而谁也不知道这样的日子会持续多久。 对日本来说，他们必须做出选择了。 1940年3月，日本拟定了军需物资自给自足计划，将更多的精力投入到了东南亚 日本政府深切关怀足以改变荷属东印度群岛现状的任何事态——1940年4月15日,外相有田八郎讲话,太平洋战争史·第二卷：21 日本人在东南亚的脚步越来越快，而美国人则在抓紧时间，卖出自己的最后一份石油。所以一方面是日趋紧张的局势，而另一方面则是不断攀升的石油贸易，美孚石油在7月18日向国务院报告，说日本人提出要买下他们的全部产量！美国政府内部已经吵到不可开交，罗斯福接到的报告说假如我们再不限制日本人购买航空汽油，我们自己军队就可能出现6到9个月的汽油供应不足！ 在巨大的压力面前罗斯福终于决定对日本进行禁运，经过漫长的扯皮与大撕逼之后，政府官员们最终达成了一致，在7月26日宣布对航空发动机燃料及润滑油和第一号高熔度的废钢铁实行出口管制。先总统 蒋公激动地浑身颤抖，跟美国大使表示艾玛你们太够意思了！ 总统和国务卿的伟大而辉煌的举动，减轻了中国自卷入冲突以来面临的极严峻的危机。——先总统 蒋公 在这个后来被无数人称颂的禁运限制里，国务院表示辛烷值87以上的航空汽油都必须禁运！ &gt; 日本人：解释解释，什么叫“辛烷值87以上的航空汽油都必须禁运”？ &gt; 国务院：难道你不懂什么叫禁运？ &gt; 日本人：我要你解释解释，什么叫他妈的“辛烷值87以上的航空汽油都必须禁运”？ &gt; 石油公司：87号以上禁运的意思，就是他妈的87号以下不！禁！运！，还有，往86号航空汽油里加铅可以他妈的提高辛烷值！你懂了没有！？ &gt; 日本人：哦大哥，原来这就是他妈的禁运啊！小弟明白了！ 于是1940年7月到12月，日本从美国进口的86号航空汽油同比增加了550%。 此时日本的经济已经开始在崩溃的边缘上晃悠了，国家总动员法的条款几乎已经全都实施了，结果40年日本西部和朝鲜还遭遇了旱灾，粮食收成不好，好多人连吃大米都成了问题。关键是此时日本的外汇储备也接近枯竭，再这么拖下去用不了多久你想买都买不成了！最后高层达成一致，再不对东南亚下手咱们就得先完蛋了。于是1941年7月2日，御前会议最终制定了《适应形势变化的帝国国策纲要》，表示就算是跟米英鬼畜开战，咱们也得南进！7月24日，日本出兵印度支那南部。 然后罗斯福炸了：老子不禁运你石油就是为了不让你打那边，你自己心里没点数么？于是26号冻结了日本在美的全部资产；英国人表示弟儿你说的对，我们也禁运，然后切断了日本在婆罗洲的石油供给。27号荷兰人跟进，冻结日本资产。这下子事情再也没有回转的余地了。 日本人的精神一下子紧张了起来（……为什么才紧张！？），军方此前一直认为我把印度支那南部这么一占，你们这些米英鬼畜还不得乖乖坐下来跟我和谈么？咱们这和平近在眼前啊！ ……以此确保东亚的战略要地。由此或可使英美荷死心不再压迫日本,并给重庆政府以打击,以找到解决日中战争的突破口,进而或许有助于打开日荷谈判。所以只有尽快抓住时机实行“战略上先发制人之措施”,才能避免同英美作战,此即不战而胜之上策——信天清三郎,日本外交史·下册：668 1941年11月，两艘日本油轮自洛杉矶附近海域空载而归。大怒的日本人……切断了英美使馆的取暖油供应。（……我是一直没搞懂日本人的脑回路）而在此之前，8月份美国人已经提出了自己的条件：日本从中国撤军、各国在中国机会均等以及日本改变三国同盟，这个条件被日本人毫不犹豫地拒绝了。9月6日，日本御前会议批准了《帝国国策施行要点》，指出10月上旬外交依然没有进展，则准备开战。 日本人最开始的计划是咱们先赶紧在东南亚占地盘，然后建立个防御圈——考虑到东南亚还有个美属菲律宾，那美国人妥妥是要来跟咱们打的，到时候咱们舰队决战，拼个你死我活！ 然后联合舰队的指挥官山本五十六对此表示了不同意见——美国人啥工业能力？你什么工业能力？心里没点数么？既然已经料到要打，那为什么不趁着美国人还没有完全动员的时候直接先下手为强？要知道，海军要想重建，那难度可比陆军难多了。咱们一鼓作气消灭美国的太平洋海上力量，然后趁着美国人重建海军无暇的关口逼他就范，承认咱们大日本帝国在亚洲的霸权那是十分合理的！ 11月20日，日本向美国提出最后一个谈判方案，日本人表示这绝对是自己最后的底线了 1.日本政府和美国政府都保证,除了目前己驻有日军的法属印度支那以外,不向东南亚和南太平洋地区的任何地方进行任何武装进军。 2.一俟日本和中国之间恢复和平,或在太平洋地区建立了公正的和平,日本政府保证撤走目前驻扎在法属印度支那的军队。同时,日本政府宣布在本协议(以后将包含在最后协议中)订立时,准备把现驻法属印支南部的军队移驻该地区北部. 3.日美两国政府将进行合作,以保证两国在荷属东印度群岛取得所需要的货物和商品。 4.日本政府和美国相互保证把通商关系恢复到日方资金被冻结前的状态.美国政府将按日本所需的数量供应石油。 5.美国政府保证不采取任何措施和行动,不利于日本和中国之间为谋求全面和平所作的努力。——United States Department of State.Papers relating to the foreign relations of the United States, Japan, 1931–1941, Volume II 美国人对此表示难以置信，并回复了一份由国务卿起草的备忘录，基本上重申了自己在8月份提出的要求。美国人所不知道的，是在自己做出这个回复以前，一支规模空前的舰队已经在单冠湾集结完毕了，那上面的飞行员此前曾反复地练习过如何低空投放鱼雷和炸弹。罗斯福此时还在犹豫要不要向日本示好，以挽回两国之间的关系，11月22日美国国务院远东司甚至接到命令，起草一份新的草案，有限度地恢复对日本的石油、食品及药物供应。然而由于中国及英国的强烈反对，这份草案最终也没能实施。 1941年12月1日，日本御前会议做出了决定：与美国开战。 1941年12月7日，珍珠港事件爆发，美国太平洋舰队遭到重创。 1942年，日本军队逼近东印度群岛的巴厘巴板炼油厂，1943年第一季度，日本的石油危机大大缓和。 石油问题已经基本得到解决——东条英机·1943 以上。 后记：这篇文章的作者设置了禁止转载，不过我这博客也没什么人看，我放在这里也是为了备份，也许将来某天知乎挂了或者作者决定退出知乎了删除了这篇问答？另外，作者的这篇文章里面还是有一些戏谑口吻的地方，我打算围绕着作者写的主干，做一做考据，让这篇文章能够成为之后“键政”的有力资料。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
        <tag>政治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[996 License 1.0]]></title>
    <url>%2Fposts%2F12613%2F</url>
    <content type="text"><![CDATA[Copyright (c) 996 License Version 1.0 (Draft) Permission is hereby granted to any individual or legal entity obtaining a copy of this licensed work (including the source code, documentation and/or related items, hereinafter collectively referred to as the &quot;licensed work&quot;), free of charge, to deal with the licensed work for any purpose, including without limitation, the rights to use, reproduce, modify, prepare derivative works of, publish, distribute and sublicense the licensed work, subject to the following conditions: The individual or the legal entity must conspicuously display, without modification, this License on each redistributed or derivative copy of the Licensed Work. The individual or the legal entity must strictly comply with all applicable laws, regulations, rules and standards of the jurisdiction relating to labor and employment where the individual is physically located or where the individual was born or naturalized; or where the legal entity is registered or is operating (whichever is stricter). In case that the jurisdiction has no such laws, regulations, rules and standards or its laws, regulations, rules and standards are unenforceable, the individual or the legal entity are required to comply with Core International Labor Standards. The individual or the legal entity shall not induce or force its employee(s), whether full-time or part-time, or its independent contractor(s), in any methods, to agree in oral or written form, to directly or indirectly restrict, weaken or relinquish his or her rights or remedies under such laws, regulations, rules and standards relating to labor and employment as mentioned above, no matter whether such written or oral agreement are enforceable under the laws of the said jurisdiction, nor shall such individual or the legal entity limit, in any methods, the rights of its employee(s) or independent contractor(s) from reporting or complaining to the copyright holder or relevant authorities monitoring the compliance of the license about its violation(s) of the said license. THE LICENSED WORK IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN ANY WAY CONNECTION WITH THE LICENSED WORK OR THE USE OR OTHER DEALINGS IN THE LICENSED WORK. 版权所有（c） 反996许可证版本1.0 在符合下列条件的情况下，特此免费向任何得到本授权作品的副本（包括源代码、文件和/或相关内容，以下统称为“授权作品”）的个人和法人实体授权：被授权个人或法人实体有权以任何目的处置授权作品，包括但不限于使用、复制，修改，衍生利用、散布，发布和再许可： 个人或法人实体必须在许可作品的每个再散布或衍生副本上包含以上版权声明和本许可证，不得自行修改。 个人或法人实体必须严格遵守与个人实际所在地或个人出生地或归化地、或法人实体注册地或经营地（以较严格者为准）的司法管辖区所有适用的与劳动和就业相关法律、法规、规则和标准。如果该司法管辖区没有此类法律、法规、规章和标准或其法律、法规、规章和标准不可执行，则个人或法人实体必须遵守国际劳工标准的核心公约。 个人或法人不得以任何方式诱导或强迫其全职或兼职员工或其独立承包人以口头或书面形式同意直接或间接限制、削弱或放弃其所拥有的，受相关与劳动和就业有关的法律、法规、规则和标准保护的权利或补救措施，无论该等书面或口头协议是否被该司法管辖区的法律所承认，该等个人或法人实体也不得以任何方法限制其雇员或独立承包人向版权持有人或监督许可证合规情况的有关当局报告或投诉上述违反许可证的行为的权利。 该授权作品是&quot;按原样&quot;提供，不做任何明示或暗示的保证，包括但不限于对适销性、特定用途适用性和非侵权性的保证。在任何情况下，无论是在合同诉讼、侵权诉讼或其他诉讼中，版权持有人均不承担因本软件或本软件的使用或其他交易而产生、引起或与之相关的任何索赔、损害或其他责任。 https://link.zhihu.com/?target=https%3A//github.com/kattgu7/996-License-Draft/]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OC和Swift混编Frameowork优雅指南]]></title>
    <url>%2Fposts%2F56606%2F</url>
    <content type="text"><![CDATA[本文主要参考了优雅地开发Swift和Object C混编的Framework。不过实际发现，完全按照文章里面”优雅的解决方案“里面的说法操作，还是没法成功。我这里根据实际情况作出了调整。 参考的文章中在“优雅的解决方案”这个section之前的内容都是好用的，你可以用用来创建一个兼容OC和Swift的Cooca Touch Framework。 这里说的“优雅”，指的是控制OC部分接口保留的问题（详情可以参考原文部分） 原文里面只说了具体的操作步骤，没有高屋建瓴地说出这种方法的实际思路：事实上，采用module.modulemap的方法是将OC部分打包成一个可以使用Swfit语句进行导入(import)的模块。以这个视角，我们再来梳理一下操作步骤： 新建一个module.modulemap文件 文件里的内容如下： 12345module OCSource [system] &#123; //由于module.modulemap和OCSource.h是在同一个文件夹的，如果不是同一个，路径要写全 header &quot;OCSource.h&quot; export *&#125; 有一个容易犯错的问题是将这里的模块名字, OCSource命名为了Cocoa Touch Framework的名字。这样会导致编译出错，错误信息会提示你Module名字重复定义。这里的名字要区别的Framework的名字，具体是什么可以自己自由选择。不过推荐和头文件的名字一致 后一步操作是把module.modulemap的路径添加到Build Settings的Import Paths中，这是为了让我们在Swift里面import这个module的时候能够找到目标. Import Paths in Build Settings 那么，这里的$(SRCROOT)/MixFramework其实就是指的module.modulemap的路径。 将OCSouce.h文件的权限改为project Header Visibility Settings 这可以让OCSource.h不再对外可见。 然后，删除MixFramework.h(umbrella header)中#import 的OC header。 原文的内容到此结束，但是其实还是不够的。这时候如果编译，会发现你在Framework内部的Swift使用OCSource的地方都会报错说OCSource不存在。因为将OCSource.h从umbrella header中删除之后Swift就无法看到这个文件了。然而，通过module.modulemap文件我们将OCSource.h及相关的OC文件打包成了了一个Swift模块，因此我们可以在Swift代码中import进来： 1import OCSource 在报错的Swift文件中添加这个导入，就可以解决这个问题了.]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>ios</tag>
        <tag>swift</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Universal(Fat) Framework for Swift Projects]]></title>
    <url>%2Fposts%2F28461%2F</url>
    <content type="text"><![CDATA[Cocoa Touch Framework 最近在给朋友做一个项目，要求将涉及到的算法内容整理成一个单独的framework，这样可以隐藏算法细节，方便交付。这个需求可以很容易地通过Cocoa Touch Framework实现。不过在交付的时候存在一个头疼的问题：默认情况下，Xcode在编译Cocoa Touch Framework时只会编译出支持模拟器或者真机的Framework，而无法编译出同时支持模拟器和真机的Framework，即Universal(Fat) Framework。这一需求还需要进一步地利用一些系统脚本来实现。 这里假设你已经有了一个能够正常工作，编译的包含Cocoa Touch Framework的工程。我这里实现时使用的是Xcode10.2。 事实上我在调研中发现了很多不同的实现编译Universal Framework的教程，但是他们并不总是有用，我这里只遴选了我自己测试通过没有问题的思路。这一思路通过Archive过程来打包输出framework 首先从Xcode左上角选择Cocoa Touch Framework的默认scheme，然后点击Edit Scheme Edit Scheme 在Archive的post-action中添加一个运行脚本(New Run Script Action) New Run Script Action 脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748exec &gt; /tmp/$&#123;PROJECT_NAME&#125;_archive.log 2&gt;&amp;1UNIVERSAL_OUTPUTFOLDER=$&#123;BUILD_DIR&#125;/$&#123;CONFIGURATION&#125;-universalif [ "true" == $&#123;ALREADYINVOKED:-false&#125; ]thenecho "RECURSION: Detected, stopping"elseexport ALREADYINVOKED="true"# make sure the output directory existsmkdir -p "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;"echo "Building for iPhoneSimulator"xcodebuild -workspace "$&#123;WORKSPACE_PATH&#125;" -scheme "$&#123;TARGET_NAME&#125;" -configuration $&#123;CONFIGURATION&#125; -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPhone 6' ONLY_ACTIVE_ARCH=NO ARCHS='i386 x86_64' BUILD_DIR="$&#123;BUILD_DIR&#125;" BUILD_ROOT="$&#123;BUILD_ROOT&#125;" ENABLE_BITCODE=YES OTHER_CFLAGS="-fembed-bitcode" BITCODE_GENERATION_MODE=bitcode clean build# Step 1. Copy the framework structure (from iphoneos build) to the universal folderecho "Copying to output folder"# 这行是在我参考的脚本的基础上添加进去的。脚本在运行过程中有一个问题：在试图将# archive过程中生成的device framework拷贝进来时，总是拷贝的framework文件夹# 的内容，而非整个文件夹，所以我们这里手动创建这个文件夹mkdir -p "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;FULL_PRODUCT_NAME&#125;"cp -R "$&#123;ARCHIVE_PRODUCTS_PATH&#125;$&#123;INSTALL_PATH&#125;/$&#123;FULL_PRODUCT_NAME&#125;" "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;FULL_PRODUCT_NAME&#125;"# Step 2. Copy Swift modules from iphonesimulator build (if it exists) to the copied framework directorySIMULATOR_SWIFT_MODULES_DIR="$&#123;BUILD_DIR&#125;/$&#123;CONFIGURATION&#125;-iphonesimulator/$&#123;TARGET_NAME&#125;.framework/Modules/$&#123;TARGET_NAME&#125;.swiftmodule/."echo "SIMULATOR_SWIFT_MODULES_DIR: $&#123;SIMULATOR_SWIFT_MODULES_DIR&#125;"if [ -d "$&#123;SIMULATOR_SWIFT_MODULES_DIR&#125;" ]; thencp -R "$&#123;SIMULATOR_SWIFT_MODULES_DIR&#125;" "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;TARGET_NAME&#125;.framework/Modules/$&#123;TARGET_NAME&#125;.swiftmodule"fi# Step 3. Create universal binary file using lipo and place the combined executable in the copied framework directoryecho "Combining executables"lipo -create -output "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;FULL_PRODUCT_NAME&#125;/$&#123;EXECUTABLE_PATH&#125;" "$&#123;BUILD_DIR&#125;/$&#123;CONFIGURATION&#125;-iphonesimulator/$&#123;EXECUTABLE_PATH&#125;" "$&#123;ARCHIVE_PRODUCTS_PATH&#125;$&#123;INSTALL_PATH&#125;/$&#123;EXECUTABLE_PATH&#125;"# Step 4. Create universal binaries for embedded frameworks#for SUB_FRAMEWORK in $( ls "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;TARGET_NAME&#125;.framework/Frameworks" ); do#BINARY_NAME="$&#123;SUB_FRAMEWORK%.*&#125;"#lipo -create -output "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;TARGET_NAME&#125;.framework/Frameworks/$&#123;SUB_FRAMEWORK&#125;/$&#123;BINARY_NAME&#125;" "$&#123;BUILD_DIR&#125;/$&#123;CONFIGURATION&#125;-iphonesimulator/$&#123;SUB_FRAMEWORK&#125;/$&#123;BINARY_NAME&#125;" "$&#123;ARCHIVE_PRODUCTS_PATH&#125;$&#123;INSTALL_PATH&#125;/$&#123;TARGET_NAME&#125;.framework/Frameworks/$&#123;SUB_FRAMEWORK&#125;/$&#123;BINARY_NAME&#125;"#done# Step 5. Convenience step to copy the framework to the project's directoryecho "Copying to project dir"yes | cp -Rf "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;FULL_PRODUCT_NAME&#125;" "$&#123;PROJECT_DIR&#125;"open "$&#123;PROJECT_DIR&#125;"fi 上述脚本的内容主要来自于export-fat-swift-dynamic-framework，我在这里根据实际情况进行了更改 此时执行archive操作(Product-&gt;Archive)完成后会自动弹出Finder窗口显示新生成的framework的位置（应当就是位于项目根目录下）。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>ios</tag>
        <tag>swift</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时局图：论扛着红旗反红旗]]></title>
    <url>%2Fposts%2F8446%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
        <tag>政治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS:图像截取部分(Image Cropping)]]></title>
    <url>%2Fposts%2F2543%2F</url>
    <content type="text"><![CDATA[Cover 这里我们讨论的图像截取部分是指从一个完整的大图中截取一小部分出来。当然，使用js实现。 这边文章基本整理自Cropping images with Javascript， 添加了一些我的评论 例如，我们要从这样的大图中： 大图 截取出 小图 使用H5中的canvas可以简单地解决这个问题。 1. 载入原图像 1234567891011121314var loadTimer;var imgObject = new Image();imgObject.src = 'images/fozzie.jpg';imgObject.onLoad = onImgLoaded();function onImgLoaded() &#123; if (loadTimer != null) clearTimeout(loadTimer); if (!imgObject.complete) &#123; loadTimer = setTimeout(function() &#123; onImgLoaded(); &#125;, 3); &#125; else &#123; onPreloadComplete(); &#125;&#125; 注意这里我们为了演示是读取的图片文件内容，实际上除了图像文件，这里的“图像”还可以是其他形式，例如video元素，别的canvas等。 2. 当图片完成载入以后，重新绘制你要截取的那一部分 123456function onPreloadComplete()&#123; //call the methods that will create a 64-bit version of thumbnail here. var newImg = getImagePortion(imgObject, 120, 150, 150, 80, 2); //place image in appropriate div document.getElementById("images").innerHTML = "&lt;img alt="" src=""+newImg+"" /&gt;";&#125; 这个onPreloadComplete函数会在图像载入完成以后调用。在这个函数中我们会调用实际完成图片截取的函数getImagePortion 3. 图像截取 123456789101112131415161718getImagePortion(imgObj, newWidth, newHeight, startX, startY, ratio)&#123; /* the parameters: - the image element - the new width - the new height - the x point we start taking pixels - the y point we start taking pixels - the ratio */ //set up canvas for thumbnail var tnCanvas = document.createElement('canvas'); var tnCanvasContext = canvas.getContext('2d'); tnCanvas.width = newWidth; tnCanvas.height = newHeight; /* use the sourceCanvas to duplicate the entire image. This step was crucial for iOS4 and under devices. Follow the link at the end of this post to see what happens when you don’t do this */ var bufferCanvas = document.createElement('canvas'); var bufferContext = bufferCanvas.getContext('2d'); bufferCanvas.width = imgObj.width; bufferCanvas.height = imgObj.height; bufferContext.drawImage(imgObj, 0, 0); /* now we use the drawImage method to take the pixels from our bufferCanvas and draw them into our thumbnail canvas */ tnCanvasContext.drawImage(bufferCanvas, startX,startY,newWidth * ratio, newHeight * ratio,0,0,newWidth,newHeight); return tnCanvas.toDataURL();&#125; 上面的函数时原作者给出的方法，他先将图像完整地画到一个canvas(bufferCanvas)上，再将这个canvas对应的目标区域画到tnCanvas上，根据注释来看，似乎是出于性能或者适配方面的考虑。不过就我在开发桌面端网页时，可以直接将imgObj画到tnCanvas上。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】IOS的一些设计规范]]></title>
    <url>%2Fposts%2F23804%2F</url>
    <content type="text"><![CDATA[转载自BIGD团队。]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>ios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac: 将APP打包成dmg]]></title>
    <url>%2Fposts%2F62609%2F</url>
    <content type="text"><![CDATA[创建一个新的文件夹，将APP放到这个新文件夹中 打开Disk Utility &gt; File &gt; New Image &gt; Image from Folder.（中文的话，是磁盘工具 &gt; 文件 &gt; 新建映像 &gt; 来自文件夹的映像...） 在弹出的窗口中，选择在第一步中新建的文件夹 选择输出dmg文件的存储位置，然后点击保存按钮]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>MacOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】在小米电视和小米盒子上看YOUTUBE]]></title>
    <url>%2Fposts%2F5827%2F</url>
    <content type="text"><![CDATA[使用小米电视和小米盒子看YouTube上的视频，是很多中国电视用户很想做的事情，下面，我就介绍一种很简单的方法，不用ROOT小米电视或小米盒子，不用重装系统，几分钟的设置就可以在小米电视和小米盒子上看YouTube的方法。 首先需要下载两个APK应用，第一个是SmartYouTubeTV，点击这里下载最新版SmartYouTubeTV，将其复制到U盘。第二个是Shadowsocks，访问apkmirror网站，搜索Shadowsocks，找到最新版后，下载universal的apk到U盘即可。 之后，打开小米电视或小米盒子，在“设置-账户与安全”里，选择“允许安装未知来源的应用”。插入U盘，将上述两个apk文件安装到电视上。 最后，在Shadowsocks上设置好服务器地址，打开SmartYouTubeTV，选择第一个，然后可以选择登陆Google账号，登陆的时候，会让用户在手机上访问 youtube.com/activate 来登陆激活，登陆好了后，电视即可和电脑浏览器的YouTube同步了。 Smart YouTube TV里登陆Google账号后，你会发现，YouTube里的订阅、上传、历史什么的功能全部可以正常使用了，完美支持小米遥控器控制，观看视频体验极佳，完全不亚于官方的应用。 当然，用户也可以选择安装官方的YouTube应用，但必须安装Google框架等一堆东西，使用体验可能还未必好。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>转载</tag>
        <tag>翻墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在普通网络环境下上北邮人]]></title>
    <url>%2Fposts%2F54288%2F</url>
    <content type="text"><![CDATA[在学校里看剧、电影，下载破解游戏基本都靠北邮人。一方面资源比较全，另一方面是走IPv6，不需要走计费的校园网IPv4流量。不过由于北邮人只支持IPv6，而国内IPv6基本只有校园网有。问题来了，怎么在校外的纯IPv4环境下使用IPv6 Only的北邮人呢？ 从IPv4到IPv6 这是最重要的一步。你首先需要一个支持IPv6的VPS。国内目前支持IPv6的好像只有阿里云？，即便支持，国内的IPv6 VPS又贵又难用（需要申请）。因此最好的方案是采用海外的VPS。听起来用海外的VPS会很慢？其实海外的VPS主要是延时高，其实速度还是挺快的，而且P2P传输业务受到延时的影响挺小的，实测利用我的VPS可以达到5MB/s的P2P下载速度（在服务器上看上下行都是5MB/s，基本跑满了100M的带宽）。我用的VPS是Digital Ocean的旧金山节点。价格是$5一个月。平均下来每天一块钱吧。注意创建Droplet的时候要自己勾选IPv6（添加IPv6是免费的）。 选择IPv6 在服务器上我部署了Shadowsocks服务。SS服务器可以直接无痛支持IPv4到IPv6的转换。关于如何部署Shadowsocks，这方面的教程文章网上汗牛充栋，我这里就不提供了。 设置 首先需要将北邮人的网址bt.byr.cn添加到Shadowsocks客户端的代理列表。 Shadowsocks选项 点击Shadowsocks小飞机，选择“编辑PAC用户自定规则”。在弹出的框中输入||bt.byr.cn： 编辑PAC用户自定规则 然后你就能在IPv4网络环境下打开北邮人的网页啦。 接下来是设置下载客户端uTorrent的网络设置。打开uTorrent的设置(Preferences)，进入到Network。进行如下设置： uTorrent设置 注意：上面的Socks5设置中，端口会与你的Shadowsocks设置有关。如果你没有动过相关设置的话，应该就是1086端口。 查看你的Shadowsocks客户端Sock5代理端口设置的方式是单击Shadowsocks小飞机，选择偏好设置，在弹出的窗口中点击“高级”，其中“本地Socks5监听端口”即为应该填写到uTorrent设置中的代理端口。 大功告成！_(:з」∠)_]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SimpleOpenNI在Processing导出应用中的库引用问题]]></title>
    <url>%2Fposts%2F65501%2F</url>
    <content type="text"><![CDATA[在Processing中使用SimpleOpenNI时，如果尝试将本来能够正常运行的pde文件导出成应用，那么在运行时会出现java.lang.UnsatisfiedLinkError这个错误。详细信息如下： 1234567891011121314Can&apos;t load SimpleOpenNI library (libSimpleOpenNI.jnilib) : java.lang.UnsatisfiedLinkError: Can&apos;t load library: /SimpleOpenNI/library/libSimpleOpenNI.jnilibVerify if you installed SimpleOpenNI correctly.http://code.google.com/p/simple-openni/wiki/Installationjava.lang.UnsatisfiedLinkError: SimpleOpenNI.SimpleOpenNIJNI.swig_module_init()V at SimpleOpenNI.SimpleOpenNIJNI.swig_module_init(Native Method) at SimpleOpenNI.SimpleOpenNIJNI.&lt;clinit&gt;(SimpleOpenNIJNI.java:290) at SimpleOpenNI.ContextWrapper.&lt;init&gt;(ContextWrapper.java:54) at SimpleOpenNI.SimpleOpenNI.&lt;init&gt;(SimpleOpenNI.java:253) at Sketch.settings(Sketch.java:28) at processing.core.PApplet.handleSettings(PApplet.java:954) at processing.core.PApplet.runSketch(PApplet.java:10786) at processing.core.PApplet.main(PApplet.java:10511) at Main.main(Main.java:7) 根据错误信息，是在读取libSimpleOpenNI.jnilib这个库文件时失败导致的。奇怪的是，程序尝试读取的路径是：/SimpleOpenNI/library/libSimpleOpenNI.jnilib。这是一个很奇怪的绝对路径。也有人尝试直接将库文件复制到这个全局路径的位置，可以让程序运行起来。可是这种方法也太不优雅了。 为什么会出现这种现象？ 通过IntelliJ可以打开SimpleOpenNI.jar查看代码细节。可以看到SimpleOpenNI.class中确定载入库文件路径的方式如下： 1234567891011121314151617181920212223242526272829303132static &#123; String var0 = System.getProperty("os.name").toLowerCase(); String var1 = "SimpleOpenNI"; String var2 = System.getProperty("os.arch").toLowerCase(); if (var0.indexOf("win") &gt;= 0) &#123; // ... &#125; else if (var0.indexOf("nix") &lt; 0 &amp;&amp; var0.indexOf("linux") &lt; 0) &#123; if (var0.indexOf("mac") &gt;= 0) &#123; var1 = "lib" + var1 + ".jnilib"; nativLibPath = getLibraryPathLinux() + "/SimpleOpenNI/library/"; nativDepLibPath = nativLibPath + "osx/"; &#125; &#125; else &#123; nativLibPath = "/SimpleOpenNI/library/linux"; if (var2.indexOf("86") &gt;= 0) &#123; var1 = var1 + "32"; &#125; else if (var2.indexOf("64") &gt;= 0) &#123; var1 = "lib" + var1 + "64.so"; nativLibPath = getLibraryPathLinux() + "/SimpleOpenNI/library/"; nativDepLibPath = nativLibPath + "linux64/"; &#125; &#125; try &#123; System.load(nativLibPath + var1); &#125; catch (UnsatisfiedLinkError var5) &#123; System.out.println("Can't load SimpleOpenNI library (" + var1 + ") : " + var5); System.out.println("Verify if you installed SimpleOpenNI correctly.\nhttp://code.google.com/p/simple-openni/wiki/Installation"); &#125; _initFlag = false; &#125; 注意到在生成库文件路径时，/SimpleOpenNI/library/libSimpleOpenNI.jnilib，前面应该会添加getLibraryPathLinux()的结果。 123456789101112public static String getLibraryPathLinux() &#123; URL var0 = SimpleOpenNI.class.getResource("SimpleOpenNI.class"); if (var0 != null) &#123; String var1 = var0.toString().replace("%20", " "); int var2 = var1.indexOf(47); boolean var3 = true; int var4 = var1.indexOf("/SimpleOpenNI/library"); return -1 &lt; var2 &amp;&amp; -1 &lt; var4 ? var1.substring(var2, var4) : ""; &#125; else &#123; return ""; &#125; &#125; 我尝试了在不同环境下,SimpleOpenNI.class.getResource(&quot;SimpleOpenNI.class&quot;)下运行的结果。发现： 在pde运行时，获取到的是独立的SimpleOpenNI.jar下的路径，例如：/Users/lena/Documents/Processing/libraries/SimpleOpenNI/library/SimpleOpenNI.jar!/SimpleOpenNI/SimpleOpenNI.class 在导出应用中运行时，获取到的是打包后应用内的，例如.../MySketch/application.macosx/MySketch.app/Contents/Java/SimpleOpenNI.jar!/SimpleOpenNI/SimpleOpenNI.class 在函数getLibraryPathLinux中，程序会定位/SimpleOpenNI/library这个字符串，然后取出这个子字符串前的内容构成的路径。上述第二种情形内，SimpleOpenNI.jar被打包到应用内后，不在处于/SimpleOpenNI/library这个前缀目录下，所以导致定位失败。 如何解决这个问题。 在无法直接修改SimpleOpenNI的源代码的情况下，要修复这个问题，就要想办法把SimpleOpenNI.jar放到SimpleOpenNI/library目录下。我使用的macOS系统，下面的方法都是在Mac下测试。不过基本思路可以迁移到Windows上。 在生成的App上右键选择显示包内容。可以查看其内部结构： 123456789101112131415161718192021222324252627282930.├── Info.plist├── Java│ ├── Sketch.jar│ ├── NiTE2│ ├── SimpleOpenNI.jar│ ├── SimpleOpenNI32.dll│ ├── SimpleOpenNI64.dll│ ├── core.jar│ ├── data│ ├── gluegen-rt-natives-macosx-universal.jar│ ├── gluegen-rt.jar│ ├── javamp3-1.0.3.jar│ ├── jogl-all-natives-macosx-universal.jar│ ├── jogl-all.jar│ ├── jsyn-20171016.jar│ ├── libSimpleOpenNI.jnilib│ ├── libSimpleOpenNI64.so│ ├── osx│ ├── sound.jar│ ├── win32│ └── win64├── MacOS│ └── Sketch├── PkgInfo├── PlugIns│ └── jdk1.8.0_181.jdk└── Resources ├── en.lproj └── sketch.icns 可以看到SimpleOpenNI.jar位于Java目录下。我尝试过直接在此处创建目录SimpleOpenNI/library并把SimpleOpenNI.jar放进去。但是运行提示无法找到SimpleOpenNI.jar。这需要在APP运行时进一步指定CLASSPATH。有一种方法是直接在Info.plist文件里面添加-Djava.class.path运行属性，或者添加ClASSPATH环境变量，但是这种方法会要求你手动填写所有需要使用的jar依赖，甚至是包括processing的jar文件。这对于后续维护和修改很不利。所以这里我采取了另一种取巧的办法。 进入Contents/MacOS目录，删除原来的Sketch文件(你看到的应该是和你的Processing程序同名的文件，我这里用Sketch来代替)。新建一个同名的空白的文本文件，然后在文件中添加如下内容： 1234567891011121314151617181920212223242526#!/bin/bashcd "$(dirname $&#123;BASH_SOURCE&#125;)"cd ../..APP_ROOT=$(pwd)cd Contents/JavaJAR_LIBS=$(ls *.jar | tr "\n" ":")# 添加SimpleOpenNI.jarJAR_LIBS=$&#123;JAR_LIBS&#125;./SimpleOpenNI/library/SimpleOpenNI.jarAPP_NAME=$(basename "$&#123;BASH_SOURCE&#125;")# 注意：如果你内嵌的jdk的版本不同，要把jdk1.8.0_181.jdk替换成对应的版本# 如果你没有在app内部内嵌jdk，这里修改成JAVA_BIN=java，使用系统全局的java即可JAVA_BIN=$&#123;APP_ROOT&#125;/Contents/PlugIns/jdk1.8.0_181.jdk/Contents/Home/jre/bin/java$&#123;JAVA_BIN&#125; \-Djna.nosys=true \-Djava.ext.dirs=$APP_ROOT/Contents/PlugIns/jdk1.8.0_181.jdk/Contents/Home/jre/lib/ext \-Xdock:icon=$APP_ROOT/Contents/Resources/sketch.icns \-Djava.library.path=$APP_ROOT/Contents/Java \-Dapple.laf.useScreenMenuBar=true \-Dcom.apple.macos.use-file-dialog-packages=true \-Dcom.apple.macos.useScreenMenuBar=true \-Dcom.apple.mrj.application.apple.menu.about.name=$&#123;APP_NAME&#125; \-classpath $&#123;JAR_LIBS&#125; $&#123;APP_NAME&#125; 为这个文件添加可执行权限 1chmod +x ./Sketch 将~/Documents/Processing/libraries/SimpleOpenNI整个文件夹拷贝进导出APP的Contents/Java目录下。然后就可以运行了。]]></content>
      <categories>
        <category>processing</category>
      </categories>
      <tags>
        <tag>processing</tag>
        <tag>debug</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks中继:从IPv4到IPv6]]></title>
    <url>%2Fposts%2F6289%2F</url>
    <content type="text"><![CDATA[最近墙又双叒叕加高了。在春节前就发现自己的VPS无法连接，后来发现还好只是端口被封禁，换成其他的端口就能使用了。不过这才撑了半个月新的端口访问又不太稳定了。如果再换端口，或许也可以。但是不是长久之计。不过我的VPS是支持IPv6的，一般来说，墙对于IPv6流量的拦截比较弱。或许可以想办法先把自己的流量转换成IPv6然后再出去。 我也设想过要不要给代理添加混淆的功能，处于以下几方面的考虑，还是选择了流量转换的方案： 1. 手机端部分ss应用不支持混淆； 2. 未来混淆还是可能被针对性的拦截。但是IPv6则不会。GFW拦截还是拦截大鱼不拦截小鱼的。国内目前IPv6的使用范围仍然非常小，而且基本只限于教育网。因此IPv6在未来的很长一段时间内不会成为GFW的针对目标 我们这里使用HAProxiy来完成这一功能。 安装HAProxy 1234wget http://www.haproxy.org/download/1.7/src/haproxy-1.7.2.tar.gztar -xzf haproxy-1.7.2.tar.gzmake TARGET=linux2826 USE_GETADDRINFO=1sudo make install 注意，在倒数第二行的make命令中，TARGET需要根据你的内核版本来选择。USE_GETADDRINFO的作用是使得HAProxy可以对域名采用DNS查询来获取IP。使用包管理器安装的HAProxy是不带这个功能的。 设置 123456789101112131415161718global ulimit-n 51200 daemon # run as daemondefaults log global mode tcp option dontlognull timeout connect 1000 timeout client 150000 timeout server 150000frontend ss-in bind *:port # 跳板机监听端口 default_backend ss-outbackend ss-out server server1 vps_host:vps_ss_port maxconn 20480 设置文件位于/etc/haproxy/haproxy.cfg。在完成设置后，使用sudo haproxy -f /etc/haproxy/haproxy.cfg来运行。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】无人机击落客机只是时间问题]]></title>
    <url>%2Fposts%2F48586%2F</url>
    <content type="text"><![CDATA[我是一个无人机集群技术的研究者，从最近开始我打算集中整理发布一些无人机，尤其是无人机集群技术的新进展以及评论文章。 原文链接：It’s only a matter of time before a drone takes down a passenger plane Cover 2018年12月，英国第二大机场盖特威克机场，发现有一架无人机飞过机场，不得不关闭一天，几十万旅客受到影响。目前还不知道这架无人机是谁操作，为什么要飞入机场。 这个事件表明，无人机对商业航空已经构成威胁。更严重的是，&quot;反无人机&quot;技术起不了多大作用。无人机已经变得太便宜，太强大，客机将不可避免地受到影响。无论是开枪、无线电干扰、或者其他措施，都无法可靠地保护客机。这可能听起来危言耸听，但我们对无人机真的缺乏办法。 现在，消费者可以买到的最便宜无人机，只需要25美元。这些产品接受遥控器的无线信号，相对容易防范，只要干扰它们的无线电信号，就可以了。稍微昂贵的无人机有 GPS 芯片，这种无人机可以编程设置一个&quot;地理围栏&quot;，防止它们飞入指定的地理坐标范围内。 但是，上面的这些措施，只能防住普通消费者从正规渠道买到的无人机。对于具有中等技术水平的人来说，制造一架无人机很容易，自制无人机也不需要 GPS 芯片。它们也不一定需要与操作员通信，才能保持飞行，这使得无线电干扰无效。而且，强度太大的干扰信号，反而可能会影响到本来要保护的客机。 可以肯定的是，一架无人机攻击一架客机，成功机会不大。这是因为在起飞和着陆时（最容易遭遇无人机的阶段），客机的移动速度非常快，通常在每小时150到200英里之间，很少有无人机能够以50~70英里/小时的速度飞行，所以客机应该可以避开无人机。此外，飞机的设计可以承受鸟撞，如果一架无人机意外撞到客机，客机可能只会受到轻微损坏，很可能还是能够安全降落。 但是，如果无人机成群飞行，事情就会发生变化。虽然单个无人机很难攻击飞机，但是在客机的飞行路径上放置30架无人机，就可能会发生变化。考虑到无人机的价格，多架无人机群体攻击是很容易的。如果通过编程，找出客机的引擎（通过红外传感或通过图像），然后无人机携带少量爆炸物，撞击可能会致命。 总之，对于那些蓄意攻击客机的半自动或全自动无人机集群，根本就没有好的技术对策。]]></content>
      <categories>
        <category>科技新闻</category>
      </categories>
      <tags>
        <tag>无人机</tag>
        <tag>科技新闻</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netlink:用户空间与内核空间交互]]></title>
    <url>%2Fposts%2F2348%2F</url>
    <content type="text"><![CDATA[Reference 1 什么是Netlink Netlink is a socket family that supplies a messaging facility based on the ++BSD socket interface++ to send and retrieve kernel-space information from user-space. Netlink is portable, highly extensible and it supports ++event-based notifications++. 从这段描述来看Netlink可以提供类似socket接口，这意味着我们能够传输比较大量的，结构化的数据。另外，Netlink还提供了基于时间通知的功能，也适合我们时刻监控系统动态。 Netlink是一种面向数据表(datagram-oriented)的连通用户空间和内核空间的__++消息系统++__。同时，Netlink也可以用于进程间通信(InterProcess Communication, IPC)。我们这里只关注前者。Netlink构筑与通用的BSD scoket基础设施之上，因此支持使用socket(), bind(), sendmsg(), recvmsg()和其他通常的socket polling操作。 一般的BSD socket使用的是固定格式的数据结构(如AF_INET或者AF_RAW)。Netlink则提供更加可扩展的数据格式。 2 Netlink的典型应用场景 当前Netlink主要应用场景是网络相关应用，包括： advanced routing IPsec key management tools firewall state synchronization uesr-space packet enqueuing border gateway routing protocols wireless mesh routing protocols 这个应用场景与我们的需要时契合的 3 Netlink总线 Netlink允许最多32条内核空间总线。一般来说每个总线都关联到一个内核子系统中（多个子系统也可以共享一个总线）。总线共享的例子包括： nfnetlink：所有防火墙相关子系统共享 rtnetlink：网络设备管理，路由和队列管理 关于Netlink总线，我发现了一个内核的patch，其中提到，&quot;This patchset aims to improve this situation by add ing a new NETLINK_DESC bus with two commands...&quot; 4 Netlink通信类型 Netlink支持两种通信类型： Unicast：一对一通信，即一个内核子系统对应一个用户空间程序。这种通信模式一般用来发送命令，或者获取命令执行的结果。 Multicast：一对多通信。通常的场景是一个内核态模块向多个用户态监听者发送消息。这种监听者被划分为多个不同的组。一条Netlink总线可以提供多个组，用户空间可以订阅到一个或者多个组来获取对应的信息。最多可以创建 个组。 Example scenario of unicast and multicast Netlink sockets 上图给出了Unicast和Multicast的图示。注意这里unicast是同步的，multicast是异步的。 5 Netlink消息格式 一般来说，Netlink消息对齐到32bit，其内部数据是host-byte order. 一个Netlink消息总由一段16bytes的header组成，header的格式为struct nlmsghdr（定义在&lt;include/linux/netlink.h&gt;中） Layout of a Netlink message header header包含如下字段： 消息长度（32bits, 包含header的长度） 消息类型（16bits）。消息类型的划分有两大类别：数据消息和控制消息。其中数据消息的类型取决于内核模块所允许的取值。控制消息类型则对所有Netlink子系统是一致的。控制消息的类型目前一共有四种。 NLMSG_NOOP: 不对对应任何实质操作，只用来检测Netlink总线是否可用 NLMSG_ERROR：该消息包含了错误信息 NLMSG_DONE：this is the trailing message that is part of a multi-part message. A multi-part message is composed of a set of messages all with the NLM_F_MULTI flag set. NLMSG_OVERRUN：没有使用 消息标识(16bits)。一些例子如下： NLM_F_REQUEST: 如果这个标识被设置了，表明这个消息代表了一个请求。从用户空间发往内核空间的请求必须要设置这个标识，否则内核子系统必须要回复一个invalid argument(EINVAL)的错误信息。 NLM_F_CREATE: 用户空间想要发布一个命令，或者创建一个新的配置。 NLM_F_EXCL: 通常和NLM_F_CREATE一起使用，用来出发配置已经存在的错误信息。 NLM_F_REPLACE: 用户空间想要替换现有配置。 NLM_F_APPEND: 想现有配置添加配置。这种操作一般针对的是有序的数据，如路由表。 NLM_F_DUMP: 用户应用想要和内核应用进行全面重新同步。这中消息的结果是一系列的multipart message。 NLM_F_MULTI: this is a multi-part message. A Netlink subsystem replies with a multi-part message if it has previously received a request from user-space with the NLM F DUMP flag set. NLM_F_ACK: 设置了这个标识后，内核会返回一个确认信息表明一个请求已经执行。如果这个flag没有返回，那么错误信息会作为sendmsg()函数的返回值同步返回。 NLM_F_ECHO: if this flag is set, the user-space application wants to get a report back via unicast of the request that it has send. 注意通过这种方式获取信息后，这个程序不会再通过事件通知系统获取同样的信息。 Sequence Number (32bits): The sequence number is used as a tracking cookie since the kernel does not change the sequence number value at all 可以和NLM_F_ACK一起使用，用户空间用来确认一个请求被正确地发出了。 Netlink uses the same sequence number in the messages that are sent as reply to a given request For event-based notifications from kernel-space, this is always zero. Port-ID (32bits): 包含了Netlink分配的一个数字ID。Netlink使用不同的port ID来确定同一个用户态进程打开的不同socket通道。第一个socket的默认port ID是这个进程的PID(Process ID)。在下面这些场景下，port ID为0： 消息来自内核空间 消息发送自用户空间，我们希望Netlink能够自动根据socket通道的port ID自动设置消息的port ID 以上是通用Netlink header格式。一些内核子系统会进一步定义自己的header格式，这样不同的子系统可以共享同一个Netlink socket总线。这种情形成为GetNetlink。 6 Netlink负载 6.1 Type-Length-Value(TLV)格式 An example of a hypothetical Netlink payload in TLV format Netlink的消息格式由TLV格式的属性组成。TLV属性分为Length, Type和Payload三部分。这种格式具有很强的可扩展性。在内核中，TLV属性的header定义如下: 12345678910111213/* * &lt;------- NLA_HDRLEN ------&gt; &lt;-- NLA_ALIGN(payload)--&gt; * +---------------------+- - -+- - - - - - - - - -+- - -+ * | Header | Pad | Payload | Pad | * | (struct nlattr) | ing | | ing | * +---------------------+- - -+- - - - - - - - - -+- - -+ * &lt;-------------- nlattr-&gt;nla_len --------------&gt; */struct nlattr &#123; __u16 nla_len; __u16 nla_type;&#125;; nla_type：属性的取值很大程度上取决于内核空间子系统定义。不过Netlink预先定了两个重要的比特位： NLA_F_NETSTED: 是否是嵌套属性。即在payload部分，以TLV的格式存储了更多的属性。 NLA_F_NET_BYTEORDER: payload内容的字节顺序（是否是network byte order(1)) nla_len: 注意，尽管payload部分会按照32bit进行对齐，这里的长度内容是不包含对齐补全的bit的。另外，这里的长度值包含了header。 7 Netlink错误消息 Layout of a Netlink error message Netlink提供了一种包含了Netlink error header的消息类型，其格式如上图所示。这个header定义为struct nlmsgerr (&lt;include/linux/netlink.h&gt;) 12345678910111213struct nlmsgerr &#123; int error; struct nlmsghdr msg; /* * followed by the message contents unless NETLINK_CAP_ACK was set * or the ACK indicates success (error == 0) * message length is aligned with NLMSG_ALIGN() */ /* * followed by TLVs defined in enum nlmsgerr_attrs * if NETLINK_EXT_ACK was set */&#125;; error: 错误类型。定义在error.h中，可以用perror()解析。 Netlink消息，为触发此错误的消息内容。 &gt; With regards to message integrity, the kernel subsystems that support Netlink usually report invalid argument (EINVAL) via recvmsg() if user-space sends a malformed message 8 GeNetlink 前文我们提到过GetNetlink了。这一技术是为了缓解Netlink总线数量过少的问题。GeNetlink allows to register up to 65520 families that share a single Netlink bus. Each family is intended to be equivalent to a virtual bus。其中，每个family通过一个唯一的string name and ID number来注册。其中string name作为主键，而ID number在不同的系统中可能不同。 9 Netlink开发 Netlink开发涉及到内核空间和用户空间双边的开发。Linux提供了很多帮助函数来见过Netlink开发中重复性的解析，验证，消息构建的操作。 9.1 用户空间开发 从用户空间这一侧来看，Netlink sockets实现在通用的BSD socket接口之上。因此，在用户空间开发Netlink和开发TCP/IP socket应用是很类似的。不过，同其他典型的BSD socket应用相比，Netlink存在以下的不同之处： Netlink sockets do not hide protocol details to user-space as other protocols to. 即，Netlink会直接处理原始数据本身，用户空间的开发也要直接处理原始数据格式的负载。 Errors that comes from Netlink and kernel subsystems are not returned by recvmsg() as an integer. Instead, errors are encapsulated in the Netlink error message. 唯一的例外是No buffer space error (ENOBUFS)，这个错误是表明无法将Netlink消息放入队列。标准的通用socket错误，同样也是从recvmsg()中以integer形式返回。 涉及用户空间的Netlink开发的有两个库：libnl和libmnl。这些库都是用C开发，用来简化Netlink开发。Netlink用户空间的进一步开发可以参考这两个库的例子和教程。 原始API的文档：https://www.systutorials.com/docs/linux/man/7-netlink/ 9.1.1 打开socket 下面来阐述一下用户空间的Netlink开发的重要事项。前面提到Netlink使用了BSD socket的接口。一般而言，创建socket的接口长这样子（socket接口）： 1int socket (int family, int type, int protocol); 第一个参数family是socket的大类。在开发TCP/IP应用的时候，这里总是AF_INET。而在Netlink中，这里总是设置为AF_NETLINK。 type可以选择SOCK_RAW或者SOCK_DGRAM。不过Netlink并不会区分这两者。 protocol为Netlink场景下定义的具体协议类型，现有的主要协议包括： 123456789101112131415161718192021222324#define NETLINK_ROUTE 0 /* Routing/device hook */#define NETLINK_UNUSED 1 /* Unused number */#define NETLINK_USERSOCK 2 /* Reserved for user mode socket protocols */#define NETLINK_FIREWALL 3 /* Unused number, formerly ip_queue */#define NETLINK_SOCK_DIAG 4 /* socket monitoring */#define NETLINK_NFLOG 5 /* netfilter/iptables ULOG */#define NETLINK_XFRM 6 /* ipsec */#define NETLINK_SELINUX 7 /* SELinux event notifications */#define NETLINK_ISCSI 8 /* Open-iSCSI */#define NETLINK_AUDIT 9 /* auditing */#define NETLINK_FIB_LOOKUP 10 #define NETLINK_CONNECTOR 11#define NETLINK_NETFILTER 12 /* netfilter subsystem */#define NETLINK_IP6_FW 13#define NETLINK_DNRTMSG 14 /* DECnet routing messages */#define NETLINK_KOBJECT_UEVENT 15 /* Kernel messages to userspace */#define NETLINK_GENERIC 16/* leave room for NETLINK_DM (DM Events) */#define NETLINK_SCSITRANSPORT 18 /* SCSI Transports */#define NETLINK_ECRYPTFS 19#define NETLINK_RDMA 20#define NETLINK_CRYPTO 21 /* Crypto layer */#define NETLINK_INET_DIAG NETLINK_SOCK_DIAG 我们可以直接使用NETLINK_USERSOCK供自己使用，或者自己定义一个新的量。 这里的protocol应当对应的是1.1.3中提到的总线。推理过程如下： 1. https://lwn.net/Articles/746776/ 这个链接中提叫的patch描述中称：This patch set aims to improve this situation by adding a new NETLINK_DESC bus with two commands 2. 在参考文献中谈论Netlink总线时，聚到了rtnetlink这个例子。根据rtnetlink的man page， #include &lt;asm/types.h&gt; #include &lt;linux/netlink.h&gt; #include &lt;linux/rtnetlink.h&gt; #include &lt;sys/socket.h&gt; rtnetlink_socket = socket(AF_NETLINK, int socket_type, NETLINK_ROUTE); 9.1.2 绑定socket地址 在打开了一个socket之后，我们需要为socket绑定一个本地地址。Netlink的地址格式如下： 1234567struct sockaddr_nl&#123; sa_family_t nl_family; /* AF_NETLINK */ unsigned short nl_pad; /* zero */ __u32 nl_pid; /* process pid */ __u32 ; /* mcast groups mask */&#125; nladdr; 这里的nl_pid可以通过getpid()这个函数来获取当前进程的pid来进行赋值 如果要在一个进程的多个线程中打开多个socket，可以用如下公式生成nl_pid： 1pthread_self() &lt;&lt; 16 | getpid(); struct socketadd_nl中的nl_groups为bit mask，代表了广播分组。当设置为0时代表单播消息。 确定地址后可以将其绑定到socket 12// fd为socket()返回的句柄bind(fd, (struct sockaddr*)&amp;nladdr, sizeof(nladdr)); 9.1.3 发送Netlink消息 为了发送Netlink消息，我们还需要创建一个struct socketaddr_nl作为发送的目的地址。如果消息是发送给内核的，那么nl_pid和nl_groups都要设置为0。如果这个消息是一个多播消息，那么需要设置nl_groups的对应比特。设置好目的地址之后，我们可以开始组装sentmsg()API需要的消息格式 123struct msghdr msg;msg.msg_name = (void *)&amp;(nladdr);msg.msg_namelen = sizeof(nladdr); 上面是socket的通用header，我们还需要设置Netlink自己的Message header这里struct nlmsghdr定义为： 12345678struct nlmsghdr&#123; __u32 nlmsg_len; /* Length of message */ __u16 nlmsg_type; /* Message type*/ __u16 nlmsg_flags; /* Additional flags */ __u32 nlmsg_seq; /* Sequence number */ __u32 nlmsg_pid; /* Sending process PID */&#125;; 在1.5中我们队各个字段的含义有了详细的介绍。按照对应的含义进行设置。 Netlink的消息由Netlink header和payload组成。因此我们需要一次性创建包含header和payload的内存块。 12345struct nlmsghdr *nlh = (struct nlmsghdr *)malloc(NLMSG_SPACE(MAX_PAYLOAD)); memset(nlh, 0, NLMSG_SPACE(MAX_PAYLOAD));nlh-&gt;nlmsg_len = NLMSG_SPACE(MAX_PAYLOAD);nlh-&gt;nlmsg_pid = getpid();nlh-&gt;nlmsg_flags = 0; 此处使用的NLMSG_SPACE宏定义是Netlink提供的工具，其定义如下： 12#define NLMSG_LENGTH(len) ((len) + NLMSG_HDRLEN)#define NLMSG_SPACE(len) NLMSG_ALIGN(NLMSG_LENGTH(len)) 这个宏做了两件事： 在长度上加上header的长度 将Payload进行32bit对齐 设置好负载内容后（负载数据段可以通过NLMSG_DATA(nlh)来获取），就可以发送了： 123456789struct iovec iov;iov.iov_base = (void *)nlh;iov.iov_len = nlh-&gt;nlmsg_len;msg.msg_iov = &amp;iov;msg.msg_iovlen = 1;sendmsg(fd, &amp;msg, 0); 9.1.3 接收Netlink消息 接收过程是类似的。接收程序需要提前分配一个足够的buffer来接收Netlink消息： 123456789101112struct sockaddr_nl nladdr;struct msghdr msg;struct iovec iov;iov.iov_base = (void *)nlh;iov.iov_len = MAX_NL_MSG_LEN;msg.msg_name = (void *)&amp;(nladdr);msg.msg_namelen = sizeof(nladdr);msg.msg_iov = &amp;iov;msg.msg_iovlen = 1;recvmsg(fd, &amp;msg, 0); 9.2 内核空间开发 9.2.1 创建新的Netlink协议类型 除非要复用内核既有Netlink协议类型，不然最好定义一个自己用的总线类型 1#define NETLINK_TEST 31 这个定义可以加在netlink.h中，或者放在模块的头文件里。 9.2.2 创建socket 在用户态，我们通过socket()接口来创建socket，而在内核中，我们使用如下的API： 12struct sock *netlink_kernel_create(struct net *net, int unit, struct netlink_kernel_cfg *cfg); net一般固定为全局变量init_net unit即为协议类型，我们在这里填上NETLINK_TEST cfg为Netlink的内核设置 123456789struct netlink_kernel_cfg &#123; unsigned int groups; unsigned int flags; void (*input)(struct sk_buff *skb); struct mutex *cb_mutex; int (*bind)(struct net *net, int group); void (*unbind)(struct net *net, int group); bool (*compare)(struct net *net, struct sock *sk);&#125;; 其中input是必须要设置的，是socket在接收到一个消息后的回调函数。回调函数的一个例子如下： 1234567891011121314151617181920212223242526272829303132333435static void hello_nl_recv_msg(struct sk_buff *skb)&#123; struct nlmsghdr *nlh; int pid; struct sk_buff *skb_out; int msg_size; char *msg = "Hello from kernel"; int res; printk(KERN_INFO "Entering: %s\n", __FUNCTION__); msg_size = strlen(msg); nlh = (struct nlmsghdr *)skb-&gt;data; printk(KERN_INFO "Netlink received msg payload:%s\n", (char *)nlmsg_data(nlh)); pid = nlh-&gt;nlmsg_pid; /*pid of sending process */ skb_out = nlmsg_new(msg_size, 0); if (!skb_out) &#123; printk(KERN_ERR "Failed to allocate new skb\n"); return; &#125; nlh = nlmsg_put(skb_out, 0, 0, NLMSG_DONE, msg_size, 0); NETLINK_CB(skb_out).dst_group = 0; /* not in mcast group */ strncpy(nlmsg_data(nlh), msg, msg_size); res = nlmsg_unicast(nl_sk, skb_out, pid); if (res &lt; 0) printk(KERN_INFO "Error while sending bak to user\n");&#125; 9.2.3 从内核向用户态程序发送消息 正如在用户空间的发送流程那样，发送消息需要先设置一个socket接收地址。设置接收地址需要通过NETLIN_CB宏访问skb从control buffer中存储的netlink参数（struct netlink_skb_parms）。 123456789struct netlink_skb_parms &#123; struct scm_creds creds; /* Skb credentials */ __u32 portid; __u32 dst_group; __u32 flags; struct sock *sk; bool nsid_is_set; int nsid;&#125;; 其中重要的参数时dst_group和flags。 如果要发送的数据包是单播数据包，发送方式为： 12NETLINK_CB(skb_out).dst_group = 0; /* not in mcast group */res = nlmsg_unicast(nl_sk, skb_out, pid); 这里的目标pid可以通过接收到的消息nlh-&gt;nlmsg_pid获取 如果要发送的数据包是多播： 1res = nlmsg_multicast(nl_sk, skbout, own_pid, group, flags); 此处的own_pid是传输自己的pid来纺织消息传递给自己。因此内核态在这里填写0 NETLNK_CB(skb_out).dst_group会在发送函数内设置。 10 Further Reading Kernel Korner - Why and How to Use Netlink Socket https://gist.github.com/arunk-s/c897bb9d75a6c98733d6]]></content>
      <categories>
        <category>kernel</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用iptables和route来建立起Linux的网关设置]]></title>
    <url>%2Fposts%2F32824%2F</url>
    <content type="text"><![CDATA[本文翻译自：Setting Up Gateway Using iptables and route on Linux。 网络资源的分享是非常重要的，而建立起一个网关来进行网络分享是一个比较好的解决方案。在Linux系统中创建和设置网关非常简单，成本低廉，而且性能可靠。 1 Linux网络设置 假定我们要处理的Linux有如下的配置： NIC1: eth0, ip: 192.168.0.1，连接到局域网(LAN) NIC2: eth1, ip: 1.2.3.4, 连接到公网 网络拓扑图 现在我们希望将分享这台机器的网络连接给LAN网络上的其他电脑(ip: 192.168.0.0/16) 2 设置网关 下面提到的所有操作都需要root权限来执行。 2.1 操作IP路由表 1234ip route add 192.168.0.0/16 dev eth0# or# route add -net 192.168.0.0/16 dev eth0 2.2 启用Linux IP 转发(IP Forwarding) 1234sysctl -w net.ipv4.ip.forward=1# or# echo 1 &gt; /proc/sys/net/ipv4/ip_forward 你也可以直接编辑/etc/sysctl.conf来持久化这一设置： 1net.ipv4.ip_forward = 1 2.3 通过iptables设置源地址映射(SNAT) 将（其他电脑发送的）包的源地址修改为网关的源地址。iptables会自动将响应包的目的地址替换成正确的IP地址。 1iptables -t nat -A POSTROUTING ! -d 192.168.0.0/16 -o eth1 -j SNAT --to-source 1.2.3.4 除了使用SNAT，也可以使用MASQUERADE: 1iptables -t nat -A POSTROUTING ! -d 192.168.0.0/16 -o eth1 -j MASQUERADE 注意，对于静态IP而言，SNAT的方式要更好一些。根据iptables man page: This target is only valid in the nat table, in the POSTROUTING chain. It should only be used with dynamically assigned IP (dialup) connections: if you have a static IP address, you should use the SNAT target. Masquerading is equivalent to specifying a mapping to the IP address of the interface the packet is going out, but also has the effect that connections are forgotten when the interface goes down. This is the correct behavior when the next dialup is unlikely to have the same interface address (and hence any established connections are lost anyway). 你还需要确保其他iptables不会阻拦对应的连接。如果你有这方面的问题，可以尝试： 123iptables -Fiptables -t nat -Fiptables -t nat -A POSTROUTING ! -d 192.168.0.0/16 -o eth1 -j SNAT --to-source 1.2.3.4 上面的代码可以允许所有的接入连接。不过这会存在一些安全性问题。 3 客户端配置 客户端配置主要是把网关设置成192.168.0.1。例如如下命令 1234ip route add default via 192.168.0.1 dev eth0# or# route add default gw 192.168.0.1 eth0]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>linux</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派上搭建视频流服务的方法尝试]]></title>
    <url>%2Fposts%2F28769%2F</url>
    <content type="text"><![CDATA[最近实验需要在树莓派上搭建一个简单的视频服务，而且，希望画质一定的情况下，消耗的带宽越少越好。关于带宽的问题，其实开始并没有考虑太多，但是在尝试用uv4l工具创建mpeg流的时候发现，尽管分辨率很低（720p）不到，需要的数据率却达到了大约5MB/s。我们待测试的通信层不具备这样高的传输传输能力。因此需要想办法把数据率降下来。综上，我们需要产生一个编码后的视频流，如H264。 幸运的是我发现了h264-live-player这个项目。这个项目是基于Node.js的工程，利用Websocket传输H264编码数据，在客户端用Broadway解码，而服务端的H264流通过raspivid产生。 在接下来的部分，我先简要介绍一下Raspivid的使用，然后介绍一下h264-live-player的情况。如果只是想上手使用，可以直接拉到最后。 Raspivid raspivid是一个在树莓派上用于捕捉视频数据的命令行工具。在h264-live-player中，lib/raspivid.js文件调用了这个命令来产生H264的视频流。在这个文件中使用的命令是： 1raspivid -t 0 -o - -w WIDTH -h HEIGHT -fps FPS 其中，-t 0表示捕捉的时间不限。-o -表示将H264流输出到stdout。后面的-w, -h, -fps则分别是制定画面的宽高还有帧率。在raspivid命令产生H264流后，h264-live-player会通过一系列的回调函数通过Websocket将H264数据发送给前端。 h264-live-player 关键代码解析。 注意，原作者的工程里面存在一些问题，其中重点是客户端刷新后视频流解析会出现异常。我在我的fork中修复了这些问题，还做了一些其他的改进。因此这里的介绍都以我的fork中的代码为准。 后端 首先还是要看lib/raspivid.js这个文件。RpiServer这个类继承于Server，Server中预留了get_feed给子类实现，器作用是产生视频流。 12345678910111213141516get_feed() &#123; if (this.streamer !== undefined) &#123; this.streamer.kill(); &#125; var msk = "raspivid -t 0 -o - -w %d -h %d -fps %d"; var cmd = util.format(msk, this.options.width, this.options.height, this.options.fps); console.log(cmd); var streamer = spawn('raspivid', ['-t', '0', '-o', '-', '-w', this.options.width, '-h', this.options.height, '-fps', this.options.fps, '-pf', 'baseline']); streamer.on("exit", function(code)&#123; if (code) &#123; console.log("Failure", code); &#125; &#125;); this.streamer = streamer; return streamer.stdout;&#125; 这个函数返回的是raspivid子进程的stdout流，也即H264流。 然后我们来看lib/_server.js文件中_Server的定义。注意start_feed这个函数： 12345678910start_feed() &#123; if (this.readStream) &#123; this.readStream.end(); &#125; var readStream = this.get_feed(); this.readStream = readStream; readStream = readStream.pipe(new Splitter(NALseparator)); readStream.on("data", this.broadcast);&#125; 这个函数在客户端发起播放流的请求后调用。这里Server调用子类实现的get_feed函数获取视频流，然后视频流上注册data事件的回调函数。 这里需要解释一下readStream = readStream.pipe(new Splitter(NALseparator));这行代码。这里我们为视频流增加了一个Splitter，生成Splitter的参数为一个Buffer。 1const NALseparator = new Buffer([0,0,0,1]);//NAL break 在H264规范中，帧中间的会插入00 00 00 01作为帧间隔标识。这里插入的Splitter的作用是，在每次遇到NALseperator形式的字符流时，将之前收到的数据作为一个chunk，调用data事件的回调函数。 再来看看broadcast函数。在视频流收到一定的函数时会调用这个函数： 12345678910111213141516broadcast(data) &#123; this.wss.clients.forEach(function(socket) &#123; if (socket.readyState !== WebSocket.OPEN) &#123; return; &#125; if(socket.buzy) return; socket.buzy = true; socket.buzy = false; socket.send(Buffer.concat([NALseparator, data]), &#123; binary: true&#125;, function ack(error) &#123; socket.buzy = false; &#125;); &#125;);&#125; 这里的代码非常简单，核心就是通过socket.send将数据发送给客户端。注意这里的数据的内容是Buffer.concat([NALseperator, data])。这是因为Splitter会截断分隔符。 前端 前端的代码集中在vendor/wsavc/index.js中。重点是下面这段代码： 12345678910111213141516171819202122232425262728293031323334var framesList = [];this.ws.onmessage = (evt) =&gt; &#123; if(typeof evt.data == "string") return this.cmd(JSON.parse(evt.data)); this.pktnum++; var frame = new Uint8Array(evt.data); //log("[Pkt " + this.pktnum + " (" + evt.data.byteLength + " bytes)]"); //this.decode(frame); framesList.push(frame);&#125;;var shiftFrame = function() &#123; if(!running) return; if(framesList.length &gt; 10) &#123; log("Dropping frames", framesList.length); framesList = []; &#125; var frame = framesList.shift(); if(frame) &#123; this.decode(frame); &#125; requestAnimationFrame(shiftFrame);&#125;.bind(this);shiftFrame(); 在接收到服务器发送的数据时，数据会被转换成Uint8Array，然后压入到一个队列中。而在shiftFrame这个函数会周期性的调用，从队列中取出数据进行解码。解码后会触发Broadway解码器的onPictureDecoded回调，在这个回调中canvas中的图像会被更新。 h264-live-player的部署和使用 安装Node.js到树莓派 SSH登录到树莓派，然后运行 12345sudo apt-get updatesudo apt-get dist-upgradecurl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -sudo apt-get install -y nodejs 使用下面的命令来验证安装成功： 1234$ node -vv8.14.1$ npm -v # npm是Node.js的包管理器6.4.1 安装h264-live-player 123456# 下载仓库git clone git@gitlab.vlionthu.com:tdma-uav/raspberry-pi-video-stream.git playercd player# 安装依赖npm install 运行 12cd playernode server_rpi.js 上面的运行方法会在terminal中启动服务脚本。如果要这个程序常驻后台，可以尝试使用pm2 12345678910sudo npm install -g pm2 # 安装pm2，这里的-g表示安装到全局环境下cd player # cd to player folder# 启动pm2 start ./server-rpi.js \ -i 1 \ --name "video-stream" \ -o "/home/pi/player/stdout.log" \ -e "/home/pi/player/stderr.log" 在网页端访问摄像头 1http://rasp_ip:8080 可以通过添加/?r的query参数来上下翻转画面。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>折腾</tag>
        <tag>树莓派</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dependency Injection in Node.js | 2016]]></title>
    <url>%2Fposts%2F30333%2F</url>
    <content type="text"><![CDATA[在上一篇文章中我们初步讨论的Dependency Injection的一些理念。在这篇文章中，我翻译了awilix模块的作者Jeff Hansen的文章：Dependency Injection in Node.js - 2016 edition。原文包含三个部分，我在这里直接整理成为一篇完整的文章。 在翻译中我以传到核心思想为主，故不会太拘泥于一些细节问题。对于一些插科打诨的话，如果不是特别有意思的话，也许不会翻译。 作者Jeff Hansen Part I 在2015年，RisingStack写了一篇关于Dependency Injection(缩写为DI)的文章，解释了什么是DI，以及如何手动实现。如果你还没有阅读这篇文章，我强烈建议你先阅读以下那篇文章。这样你对于本文的一些概念会有更加清晰的理解。 这里提到的RisingStack的文章的中文版可以在我的博客里找到: Node.js | Dependency Injection。 在这一系列文章中，我会扩展一下手动实现的DI，为什么这种做法是糟糕的，以及我们如何最终能够让DI的现实变得优雅 -- 甚至比require/imports方式要更好。我将要证明Node中使用DI可以不像之前的做法那样沉闷。这都要归功于在ES6中引入的新特性：Proxies（直译就是代理）。 我100%肯定作为一个Node的开发者，你会见过某种形式的DI。借鉴一下RisingStack文章中的例子: 1234567var express = require('express')var app = express()var session = require('express-session')app.use(session(&#123; store: require('connect-session-knex')&#125;)) session needs a store! - 这种存储的具体实现方式是多样的 ：redis，MySQL。Express本身并不关心背后的实现。我们来看下面的这个例子 -- 非DI实现： 1234567import db from '../mydatabase'export default &#123; getToDos: () =&gt; &#123; return db.query('select * from todos') &#125;&#125; 在这个例子中我们直接导入了db模块，因此这个文件就依赖于db模块在磁盘上的具体存储位置，以及依赖于特定的是方式。在大多数场景下这并不算一个大问题。不过这种方式让测试变得更加困难 -- 不至于无法进行测试，但是无论如何都变得更加地困难了。另外，这个模块还假定db模块已经准备好了（例如：数据库连接已经建立起来了）。 如果我们进一步将上面的代码转化成为对于测试友好的DI实现方式： 1234567export default function makeTodosService (&#123; db &#125;) &#123; return &#123; getTodos: () =&gt; &#123; return db.query('select * from todos') &#125; &#125;&#125; 那么上面两个例子有什么区别呢？在下面的DI实现的例子中我们不是export出一个对象，而是export出一个生成这种对象的函数。这个函数同时阐明了为了创建此种对象所需要的依赖。 如果你熟悉在其他语言中的DI实现，如Java, C#，还有PHP。下面这个使用ES6的类实现的例子可能更受你喜欢一些： 12345678export default class TodosService &#123; constructor(&#123; db &#125;) &#123; this.db = db &#125; getTodos() &#123; return this.db.query('select * from todos') &#125;&#125; 不过从个人角度我还是更喜欢函数的方法：不用担心this的上下文的问题。 测试上面这个基于DI的例子非常简单 -- 你不再需要担心对require进行修修补补来替代数据库模块从而连接到测试数据库。 12345678910111213describe('Todo Service', function () &#123; beforeEach(() &#123; subject = makeTodosService(&#123; db: testDatabaseSomehow &#125;) &#125;) it('work', async function() &#123; const todos = await subject.getTodos( expect(todos.length).to.equal(3) ) &#125;)&#125;) Part II 在这个部分我们来构思一个Todo APP。 在我们开始折腾API框架和其他乱七八糟的部分之前，我们来大致搭建一下项目的骨架 -- the service and data access。为了可读性的考虑我在这里使用了ES7的async-await机制。 然我们来开始我们的Todos Service - 这个模块来负责处理所有的业务逻辑。 我会在下面的代码片段那种使用不同的风格（函数式或者是面向对象的）来证明，这些具体的代码风格并不本质，你可以使用任何你喜欢的方式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// todosService.jsimport assert from 'assert'// Using object destructring to make it look goodexport function makeTodosService (&#123; // "repository" is a fancy term to describe an object // that is used to retrieve data from a datasource - the actual // data source does not matter. Could be a database, a REST API, // or some IoT things like sensors or what ever todosRepository, // We also want info about the user that is using the service, // so we can restrict access to only their own todos. currentUser&#125;) &#123; assert(todosRepositry, 'opts.todosRepository is required.') assert(currentUser, 'opts.currentUser is required.') return &#123; // Gets todos for the current user getTodos: async(query) =&gt; &#123; const todos = await todosRepository.find(&#123; // can be ALL, INCOMPLETED, COMPLETED filter: query.filter, userId: currentUser.id &#125;) return todos &#125;, createTodo: async (data) =&gt; &#123; const newTodo = await todosRepository.create(&#123; text: data.text, userId: currentUser.id, completed: false &#125;) return newTodo &#125;, updateTodo: async (todoId, data) =&gt; &#123; const todo = await todosRepository.get(todoId) // verify that we are allowed to modify this todo if (todo.userId !== currentUser.id) &#123; throw new Error('Forbidden') &#125; const updatedTodo = await todosRepository.update(todoId, &#123; text: data.text, completed: data.completed &#125;) return updatedTodo &#125;, deleteTodo: async (todoId) =&gt; &#123; const todo = await (todoId) const todo = await todosRepository.get(todoId); if (todo.userId !== currentUser.id) &#123; throw new Error('Forbidden') &#125; await todoRepository.delete(todoId) &#125; &#125;&#125; 代码有点长，但是并没有什么太fancy的东西。我们并没有依赖于外部库（除了自带的assert模块用于输入检验）。不过，我们导出的函数其实有两个依赖： todosRepository -- 给予todos数据库访问的对象（我们并不关心具体的实现细节）。 currentUser -- 正在使用这个服务的用户。注意我们并不知道这个对象从何处生成，也不关心这些细节。 我们继续往下走，给出todos repository的一个不错的实现方式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// todosRepository.js// Let's do an in-memory implementation for now.const _todos = []export default class TodosRepository &#123; // Making all methods async makes them return promises! async find(query) &#123; const filtered = _todos.filter((todo) =&gt; &#123; // Check the user id if (todo.userId !== query.userId) &#123; return false; &#125; // check the filter if (query.filter === "COMPLETED") &#123; return todo.completed === true &#125; if (query.filter === "INCOMPLETED") &#123; return todo.completed === false &#125; return true &#125;) return filtered &#125; async get(id) &#123; const todo = _todos.find(x =&gt; x.id === id) return todo &#125; async create(data) &#123; const newTodo = &#123; id: Date.now(), text: data.text, userId: data.userId, completed: data.completed &#125; _todos.push(newTodo) return newTodo &#125; async update(id, data) &#123; const todo = await this.get(id) Object.assign(todo, data) return todo &#125; async delete(id) &#123; const todo = await this.get(id) _todos.splice(todo, 1) &#125;&#125; 上面的代码只是todos repository的一个in-memory实现。任何时候我们准备好的时候，可以替换成MySQL，Rethink，MongoDB等存储后端，只要具有同形式的API就可以了。Typescript和Flow在这里可以发挥很大的作用。 把系统粘合起来 在我们进入到RESTful API之前，让我们先把上门两个模块在测试中整合起来。下面的方法被称为“穷人式的DI”，不过别担心，在后面我们会展示更加fancy的做法。 1234567891011121314151617181920212223242526272829303132333435363738394041import makeTodosService from './todosService'import TodosRepository from './todosRepository'describe('Todos System', function () &#123; it('works', async function() &#123; // This is how DI is done manually const todosService = makeTodosService(&#123; todosRepository: new TodosRepository(), // Let's fake it til we make it! currentUser: &#123; id: 123, name: 'Jeff' &#125; &#125;) // Todos Service already knows who's creating it! const created = await todosService.create(&#123; text: 'Write Medium article' &#125;) expect(created.userId).to.equal(123, 'user id should match currentUser') const todos = await todosService.getTodos(&#123; filter: 'ALL' &#125;) expect(todos.length).to.equal(1) await todosService.update(todo.id, &#123; completed: true &#125;) const incompleteTodos = await todosService.getTodos(&#123; filter: 'INCOMPETED' &#125;) expect(incompleteTodos.length).to.equal(0) const completedTodos = await todosService.getTodos&#123; filter: 'COMPLETED' &#125; expect(completedTodos.length).to.equal(1) &#125;)&#125;) 看到上面的代码你可能会想：“这里的代码不是已经知道了两个模块了么？”。没错，在一个真实的APP中（下文中我们会提及），还是需要有一个知道所有使用的模块的单一置信源（source of truth）。在我们倒腾DI黑科技的时候，我们把这个部分的代码称为：组合根（The Composition Root，译者按：这个名字放在中文下太绕口了）。这是在应用中将所有的模块胶合在一起的地方。Composition Root可能长这个样子： 12345678910111213141516cosnt currentUser = &#123; id: 123, name: 'Jeff'&#125;const todoRepository = new TodosRepository()const todosService = makeTodosService(&#123; todosRepository, currentUser&#125;)export default &#123; todosService, todosRepository&#125; 看到这个代码，我知道你一定在想：“我现在还不知道这个currentUser具体是指哪个用户呢！我要构建的是一个Web应用，这种方法根本没用！”。你说的对。有两种方法来手动解决这个问题： 为所有需要currentUser的方法手动传递这个参数 -- 这也太坑了。 将实例化过程推迟到你拥有了所有的数据之后（译者按：即在已知了currentUser之后再调用工厂函数初始化todosService）-- 这种方法也不好，你需要在很多的地方重复地进行实例化。 为了进一步解释以下第二点，下面给出一个例子。例子中使用到了Koa Router 123456789101112131415161718192021const router = new KoaRouter()router.get("/todos", async (ctx) =&gt; &#123; const todosService = makeTodosService(&#123; todosRepository: new TodosRepository(), currentUser: ctx.state.user &#125;) ctx.body = await todosService.getTodos(ctdx.request.query) ctx.status = 200&#125;)router.post("/todos". async (ctx) =&gt; &#123; const todosService = makeTodosService(&#123; todosRepository: new TodosRepository(), currentUser: ctx.state.user &#125;) // ...&#125;)// and so on 这还只是涉及到两个模块。想象一下要是需要处理10个模块（这还只是对于小型的应用）。没错，第二种方法也是很糟糕的。 Part III Angular曾经是在JavaScript世界中第一个引入了DI的大型框架。他们的做法是使用函数的字符串表达来提取使用的模块名称。在当时这是唯一的做法。 有一些人尝试将DI功能从Angular中独立出来做成一个独立模块。但是问题是，大多数DI模块要求你的所有代码都要围绕着特定的DI系统来开发，这位违背了DI设计理念的初衷。 DI的作用是减少程序模块之间的耦合程度，提高代码的可维护性。在这种目标下，DI系统的设计应当尽可能减少对于其它业务代码的影响。如果为了使用DI要对业务代码结构进行大范围的改动的话就得不偿失了。 我们希望能够在不改动我们的service和repository模块的情况下使用DI机制。 关于Awilix - The DI container you deservce 如果你不知道DI容器是什么，下面是一个简短的解释。DI容器的功能是将系统中的模块整合起来，从而让开发者不再需要太关注这些DI的实现细节问题。在前面两个Part中我们给出的示例代码：实例化services和repositories，确保service获取repository对象。这些工作都将由DI容器来完成。 Awilix就是这样的一个容器，其实现是基于ES6 Proxies，这一意味着不再需要对函数的参数进行字符串解析。 现在让我们回到开头的todo应用。让我们使用Awilix来将各个模块整合起来。我们将会使用Koa 2来实现Web API。先让我们来安装这些依赖： 1npm install -S koa@next koa-router@next awilix awilix-koa 这里的awilix-koa模块让Awlix和Koa的搭配更加易用。现在让我们从composition root开始 123456789101112131415161718192021// configureContainer.jsimport &#123; createContainer, asClass, asFunction &#125; from 'awilix'import makeTodosService from './todosService'import TodosRepository from './todosRepository'export default function configureContainer () &#123; const container = createContainer() // Ordering does not matter container.register(&#123; // Notice the scoped() at the end - this signals // Awilix that we gonna want a new instance per "scope" todosService: asFunction(makeTodosService).scoped(), // We only want a single instance of this for the apps // lifetime (it does not deal with user context) // so we can reuse it! todosRepository: asClass(TodosRepository).singliton() &#125;) return container&#125; 这看起来已经非常不错了。不过如果你有超过100个服务需要注册，Awilix提供了自动化的工具。 现在让我们来配置Koa应用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// server.jsimport Koa from 'koa'import KoaRouter from 'koa-router'import &#123; asValue &#125; from 'awilix'import &#123; scopePerRequest, makeInvoker &#125; from 'awilix-koa'import configureContainer from './configureContainer'const app = new Koa()const router = new KoaRouter()const container = configureContainer()// This installs a scoped container into our// context - we will use this to register our current userapp.use(scopePerRequest(container))// Let's do that now!app.use((ctx, next) =&gt; &#123; ctx.state.container.register(Value)(&#123; // Imagine some auth middleware somewhere... // This makes currentUser available to all services currentUser: ctx.state.user &#125;) return next()&#125;)// Now our handlers will be able to resolve a todos service// using DI!// P.S: be a good dev and use multiple files. ;)const todosAPI = (&#123; todosService &#125; =&gt; &#123; return &#123; getTodos: async (ctx) =&gt; &#123; const todos = await todosService.getTodos(ctx.request.query) ctx.body = todos ctx.status = 200 &#125;, createTodos: async (ctx) =&gt; &#123; const todo = await todosService.createTodo(ctx.request.body) ctx.body = todo ctx.status = 201 &#125;, updateTodo: async (ctx) =&gt; &#123; const updated = await todosService.updateTodo( ctx.params.id, ctx.request.body ) ctx.body = updated, ctx.status = 200 &#125;, deleteTodo: async (ctx) =&gt; &#123; await todosService.deleteTodo( ctx.params.id, ctx.request.body ) &#125; &#125;&#125;)// Awilix magic will run the above function// every time a request comes in, so we have// a set of scoped services per requestconst api = makeInvoker(todosAPI)router.get('/todos', api('getTodos'))router.post('/todos', api('createTodos'))router.patch('/todos/:id', api('updateTodo'))router.patch('/todos/:id', api('deleteTodo'))app.use(router.routes())app.listen(1337) 上面的代码还只是一个简单的雏形，不过你现在已经有了构建大规模项目的基础。 结论 DI是一个很有用的东西，不过手动去实现DI是一件糟心的事情。这也是Awilix这种DI容器扮演作用的地方。]]></content>
      <categories>
        <category>形而上</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node.js | Dependency Injection]]></title>
    <url>%2Fposts%2F61013%2F</url>
    <content type="text"><![CDATA[Dependency Injection这个概念是我之前在实习的时候做Java开发的时候接触的。Dependency Injection可以大大降低模块之间的耦合度，提高系统的可扩展性和鲁棒性，不过这个概念对于新人来说理解起来还是存在比较大的障碍。由于当时实习的时间比较短，对于这个概念我并没有吃透。这次学习Node.js的时候，又在awilix这个库里面遇到了这个概念。以此为契机就来好好学习一些Dependency Injection和其后的设计逻辑与方法。 下面的内容翻译自：Dependency Injection in Node.js。这篇文章浅显地介绍了Dependency Injection的基本理念。选择这篇文章是因为我在阅读awilix模块作者关于Dependency Injection的系列文章中时，作者在开篇提议阅读此文。 不过这篇文章毕竟是2015年的文章，在js的一些语法和模块细节上和今时今日的有些不同，但是并不妨碍我们对于其核心理念的理解。 使用Dependency Injection的理由 解耦 (Decoupling) Dependency Injection使你的模块耦合度降低，从而提升代码的可维护性。 更简单的单元测试 比起需要硬编码的依赖关系，你可以将依赖关系传输进入你要用的模块。在大多数场合下使用这种范式你不必要使用proxyquire这样的模块。 这一段作者写的比较含糊。其实意思是在使用Dependency Injection场景下，我们在独立测试一些单元功能的时候，对于其他模块可以通过注入Mock对象，从而将待测试的模块独立出来进行测试。 更快速的开发 在使用了Dependency Injection的场景下，在接口定义好了以后，开发会更加容易，Merge conflict会更少。 如何在Node.js中使用Dependency Injection 下面我们来看看如何在不适用Dependency Injection的前提下开发应用，然后看看如何进行转化。 不使用Dependency Injection的例子 下面是一段简单的没有使用Dependency Injection的代码： 12345678// team.jsvar User = require('./user');function getTeam(teamId) &#123; return User.find(&#123;teamId: teamId&#125;);&#125;module.exports.getTeam = getTeam; 对应的测试可能是： 1234567891011121314151617// team.spec.jsvar Team = require('./team');var User = require('/user');describe('Team', function() &#123; it('#getTeam', function* () &#123; var users = [&#123;id: 1, id: 2&#125;]; this.sandbox.stub(User, find, function() &#123; return Promise.resolve(users); &#125;) var team = yield team.getTeam(); expect(team).to.eql(users); &#125;)&#125;) 在上面的代码中我们做的是创建了一个名为team.js的模块，该模块可以返回属于一个team的用户列表。为了实现这一功能，我们导入User模块，然后我们再调用其find方法返回用户列表。 看起来不错，是吗？但是当我们需要进行测试时，我们必须要使用sinon的test stubs. 在测试文件中，我们需要引入User模块，为其stub一个find方法。注意，我们在这里要使用sandbox功能，这样我们不需在测试完成后回复find的原函数。 注意：如果原始对象使用了Object.freeze，那么stubs将不会起作用。 使用Dependency Injection的例子 123456789101112// team.jsfunction Team(options) &#123; this.options = options;&#125;Team.prototype.getTeam = function(teamId) &#123; return this.options.User.find(&#123;teamId: teamId&#125;);&#125;function create(options) &#123; return new Team(options);&#125; 你可以使用下面的这个文件来进行测试 12345678910111213141516171819202122// team.spec.jsvar Team =- require('./team');describe('Team', function() &#123; it('#getTeam', function* () &#123; var users = [&#123;id: 1, id: 2&#125;]; var fakeUser = &#123; find: function() &#123; return Promise.resolve(users); &#125; &#125; var team = Team.create(&#123; User: fakeUser &#125;) var team = yield team.getTeam(); expect(team).to.eql(users); &#125;);&#125;); 那么，使用了Dependency Injection的版本同之前的版本有什么区别呢？首先你可能注意到的是这里使用了工厂模式：我们使用这种设计模式来将options/dependencies inject到新创建的对象中 - 这里是我们注入User模块的方法。 在测试文件中我们还需要创建一个fake model来代表User模块，然后将这个伪造的模块传递给工厂函数。很简单，不是吗？ Dependency Injection in Real Projects 你可以在非常多的开源项目中发现Dependency Injection的例子。例如，你在日常工作中常常用到的Express/Koa的大部分中间件都使用了这种技术。 Express Middlewares 1234567var express = require('express');var app = express();var session = require('express-session');app.use(session(&#123; store: require('connect-session-knex');&#125;)) 上面的代码片段使用了基于工厂模式的Dependency Injection：对应session中间件我们传递了一个connect-session-knex模块。这个模块需要实现session模块调用需要的借口。 在这个例子中，connect-session-knex模块需要实现下面的方法： store.destroy(sid, callback) store.get(sid, callback) store.set(sid, session, callback) Hapi plugins Dependency Injection的概念还可以在Hapi中找到。下面的例子中，handlebars模块被作为view engine注入给Hapi使用: 1234567server.views(&#123; engines: &#123; html: require('handlebars`) &#125;, relativeTo: __dirname, path: 'templates'&#125;)]]></content>
      <categories>
        <category>形而上</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab|安装-迁移-删除]]></title>
    <url>%2Fposts%2F25664%2F</url>
    <content type="text"><![CDATA[1 安装 1.1 Omnibus package installation 这是Gitlab官网推荐的安装方式。官网文档链接位于Gitlab Installation。不过，现在直接去官网默认给出的是企业版，即gitlab-ee的安装方式（付费的），而个人版其实用gitlab-ce就够了。gitlab-ce安装方式如下 1.1.1 安装并配置依赖 1sudo apt-get install -y curl openssh-server ca-certificates 然后安装Postfix来启动邮件提醒功能。（如果你使用了第三方的邮件服务，可以跳过这一步并且参照配置外部SMTP服务器）。 1sudo apt-get install -y postfix 在接下来的配置过程中，选择'Internet Site'选项。使用你的服务器的域名来作为'mail name'。如果还有后续的选项，输入Enter直至安装完成。 1.1.2 安装Gitlab-EE 添加Gitlab Package仓库： 1curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash 注意这里安装的是CE版本，故是gitlab-ce，企业版对应的是gitlab-ee 接下来安装Gitlab： 1sudo EXTERNAL_URL="http://gitlab.example.com" apt-get install gitlab-ce 这里的EXTERNAL_URL是你的Gitlab服务要使用的域名。如果你只使用http，或者后续要使用已有的Nginx，可以在这里使用http。如果使用https，gitlab会调用Let's encrtpy的服务为你的网站添加ssl证书。 1.1.3 登录Gtilab 进入你在安装阶段的域名，你会被重定向到密码重置界面。在这个页面你要设置管理员账户的密码，然后回到登录界面。在这个登录界面，使用root用户名和上一步设置的密码登录。 1.2 使用已有的Nginx 这个章节我们参考官方文档给出使用已有的Nginx的方法。 1.2.1 禁用Gitlab自带的Nginx 编辑/etc/gitlab/gitlab.rb文件，设置 1nginx['enable'] = false 1.2.2 设置外部服务器的用户 这一步是为了保证外部服务器用户能够访问gitlab。使用Nginx时，可以通过/etc/nginx/nginx.conf文件查看到nginx用户。一般情况下这个用户名是www-data。修改/etc/gitlab/gitlab.rb： 1web_server['external_users'] = ['www-data'] 然后使用sudo gitlab-ctl reconfigure来使得更改生效。 1.2.3 Trusted proxies 如果你的反向代理服务器和gitlab不是在同一台机器上，那么你还需要设置Trusted proxies。 1gitlab_rails['trusted_proxies'] = ['192.168.1.0/24', '192.168.2.1', '2001:0db8::/32'] 1.2.4 Nginx示例配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# gitlab socket 文件地址upstream gitlab &#123; # 7.x 版本在此位置 # server unix:/var/opt/gitlab/gitlab-rails/tmp/sockets/gitlab.socket; # 8.0 位置 server unix:/var/opt/gitlab/gitlab-rails/sockets/gitlab.socket;&#125;server &#123; listen *:80; server_name gitlab.example.com; # 请修改为你的域名 server_tokens off; # don't show the version number, a security best practice root /opt/gitlab/embedded/service/gitlab-rails/public; # Increase this if you want to upload large attachments # Or if you want to accept large git objects over http client_max_body_size 250m; # individual nginx logs for this gitlab vhost access_log /var/log/gitlab/nginx/gitlab_access.log; error_log /var/log/gitlab/nginx/gitlab_error.log; location / &#123; # serve static files from defined root folder;. # @gitlab is a named location for the upstream fallback, see below try_files $uri $uri/index.html $uri.html @gitlab; &#125; # if a file, which is not found in the root folder is requested, # then the proxy pass the request to the upsteam (gitlab unicorn) location @gitlab &#123; # If you use https make sure you disable gzip compression # to be safe against BREACH attack proxy_read_timeout 300; # Some requests take more than 30 seconds. proxy_connect_timeout 300; # Some requests take more than 30 seconds. proxy_redirect off; proxy_set_header X-Forwarded-Proto https; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Frame-Options SAMEORIGIN; proxy_pass http://gitlab; &#125; # Enable gzip compression as per rails guide: http://guides.rubyonrails.org/asset_pipeline.html#gzip-compression # WARNING: If you are using relative urls do remove the block below # See config/application.rb under "Relative url support" for the list of # other files that need to be changed for relative url support location ~ ^/(assets)/ &#123; root /opt/gitlab/embedded/service/gitlab-rails/public; # gzip_static on; # to serve pre-gzipped version expires max; add_header Cache-Control public; &#125; # error_page 502 /502.html;&#125; 2 迁移 2.1 备份 迁移首先要做的是备份。在git学习------&gt; Gitlab如何进行备份恢复与迁移？这篇文章中详细讲述了备份的问题。我们这里介绍的是最为直接和简单的步骤。如果要更加详细的信息请阅读这篇参考。 备份使用如下命令： 1gitlab-rake gitlab:backup:create 备份会生成在/var/opt/gitlab/backups目录下。名称类似于1502357536_2017_08_10_9.4.3_gitlab_backup.tar。下面这些配置信息，没有包含在backup文件里面。需要手动迁移。 /etc/gitlab/gitlab.rb 配置文件须备份 /var/opt/gitlab/nginx/conf nginx配置文件 /etc/postfix/main.cfpostfix 邮件配置备份 备份命令的执行 2.2 在目标机器上安装gitlab 迁移过程中要求源机器和目标机器上安装的gitlab版本是相同的。如果不同，其实最好的做法是先将源机器上的gitlab升级到最新的版本。然后再生成备份。 如何查看Gitlab版本 2.3 上传备份 使用scp命令将备份文件上传到目标机器的/var/opt/gitlab/backups。 如果scp上传目标文件文件夹的权限不够，可以先上传到自己的home目录下，然后ssh登录到服务器使用sudo进行移动。 2.4 应用备份文件 首先为了避免潜在的权限问题，将备份文件的权限设置为777 1chmod 777 1502357536_2017_08_10_9.4.3_gitlab_backup.tar 然后停止gitlab的相关数据连接服务 12gitlab-ctl stop unicorngitlab-ctl stop sidekiq 然后用下面的命令读取备份： 1gitlab-rake gitlab:backup:restore BACKUP=1502357536_2017_08_10_9.4.3 在后续出现的所有询问中输入yes，等待执行完毕，即完成了迁移过程，接下来再次启动gitlab 1sudo gitlab-ctl start 3 删除 下面的删除过程在Ubuntu 16上得到验证： 3.1 移除gitlab服务 1sudo gitlab-ctl uninstall 3.2 清楚Gitlab产生的数据 1sudo gitlab-ctl cleanse 3.3 删除Gitlab生成的系统账户 1sudo gitlab-ctl remove-accounts 3.4 删除gitlab 1sudo dpkg -P gitlab-ce 3.5 其他文件的删除 除了上述操作，Gitlab使用的其他文件夹还需要手动删除，包括： /opt/gitlab: 包含了Gitlab的应用代码和依赖 /var/opt/gitlab: 包含了应用的数据和配置信息(gitlab-ctl reconfigure的写入内容) /etc/gitlab: omnibus gitlab的配置信息。这里的文件是唯一允许你手动编辑的部分 /var/log/gitlab: 日志文件 在你完成了开始的四个步骤后，这里的四个文件夹可以安全地手动删除。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>gitlab</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP:拥堵控制]]></title>
    <url>%2Fposts%2F60823%2F</url>
    <content type="text"><![CDATA[网络数据包如果一次发送太多，就会造成网络拥堵；如果发送太少，就浪费了带宽，延长了通信时间。TCP 协议有一个拥堵窗口机制，负责动态调整每次发送数据包的数量。本文通俗地解释了这种算法的细节。 本文翻译自Intro to Congestion Control 这个夏天，我一直在思考更好地解决网络拥塞问题的方法。在这篇文章中，我将会讨论为什么网络拥塞问题会出现，以及一些传统的解决办法。如果你有更深厚的兴趣，这个Juptier notebook包含了我用来获取相应结果的代码，以及对这些结果的分析。 什么是TCP 在我们开始正文讨论之前，我来先简要介绍一些信息在网络上流通的细节。 TCP协议被用来将信息从一台电脑经过英特网传输给另一台电脑。这个协议也是这篇文章所关注的协议。把TCP协议同其他协议（如UDP）区分开来的特征是，TCP确保了100%的传输成功率。也就是说如果你从一台电脑上发送了100kb的数据，那么你会在接收端准确地收到这100kb的数据。 TCP的这个特性非常强大，而这一特性也是很多网络应用采用TCP协议的原因。现有的Web应用和Email都是构筑于TCP协议之上。 TCP实现所有数据的可靠传输的核心原理是，对于从A端发送到B端的数据，B端会发送回一个ACK(Acknowlegement)信息给A端来告知自己收到了对应的信息。 TCP传输 另外还值得注意的是，TCP工作在IP协议之上，IP协议最多允许在一个包中包含1500个字节的数据，因此要发送100kb的数据，需要拆分成多个分段。根据TCP协议，每个分段都会收到对应的ACK。 如果发送者没有收到一个数据分段的ACK，其会重新发送这个分段。 什么时候会还产生拥塞 拥塞（Congestion）问题是由于网络传输延时导致的。信息传输速率会收到物理信道，如以太网线，蜂窝网络等，的制约。在因特网中，大部分独立设备都连接到这些信道上。 下图是一个典型场景： 拥塞产生的场景 在上面的示意图中，两个发送者要各自要传输1GB的数据。然而这两个发送者最终接入到了一个1GB的链接中。第二个链接的传输能力无法匹配上前两个链接的输入，故而不得不丢弃一部分数据包。如果发送者不主动调整自己的发送速度，那么会产生非常坏的情况。在TCP协议中，如果发送者发现一个数据分段没有送达，会重新发送这个数据包。那么拥塞情况会持续，两个发送者会无法完成发送过程。 为了让两个发送者能够成功传输各自的数据，他们需要共同减少发送数据的速率。如果只有一个发送者减少了发送的数据，而另一个仍然维持1GB的发送量，那么仍然会产生拥塞。在因特网的架构中，不会有一个中央控制系统来协调两者的发送速率。 迂回：什么是链接(link)？ 在我们深入到这个问题的解决方案前，我还想进一步讨论链接（link）的属性。关于网络链接，有下面三个重要的细节问题你需要知道： 延时（毫秒）：一个包从链接的一端发送到另一端需要的时间 带宽（mb/s）：链接每秒能够通过的比特数 队列：在链接正在工作时，等候发送包的队列的长度，以及在队列满时管理队列的策略 如果把链接比喻成水管，那么延时可以理解为管道的长度，带宽就是水管的周长。 链接模型 关于链接还有一个重要的统计参数时带宽延时积（bandwidth-delay product, BDP）。这个参数表现了体现了停留在链接中的数据量，可以理解为管道本身的容量。当链接中传输的数据量达到了BDP时，就可以说链接被充分利用了。如果发送端尝试发送比BDP更多的数据，那么链接的队列将会填满，并最终开始丢包。 方法 在给出方法之前，我们要思考一个问题：发送者如何知道产生了拥塞呢？如同我们之前提到的，因特网是一个分布式的系统，故而并没有一个位于中央的协调者来在下游链接产生拥塞的时候提醒发送者要减慢发送速度。 主要有两个指标：丢包率和传输往返时间。在拥塞发生时，链接的队列逐渐填满，开始发生丢包。如果一个发送者注意到了丢包现象，这就很可能意味着发生了丢包。另一个队列满负荷的现象是数据包在队列中等待的时间增加了，这会导致传输往返时间，即发送包到收到ACK的时间增加。 今天的一些拥塞控制机制考虑了上面两个指标，不过在一些比较早期的设计中，只使用到了丢包率这一个指标。 还需要注意的是，发送者可能并不提前知道传输链接的特性参数。例如，如果你访问&quot;http://www.google.com&quot;，那么你发送的数据包可能要经过很多不同性质的链接才能到达Google的服务器，而你的传输速率是收到其中最慢的链接的制约的。 因此，出了规避网络拥塞的能力，拥塞控制机制还需要能够探索可用带宽的具体大小。 拥塞窗口（Congestion Window） 理解任何拥塞控制机制的关键在于理解拥塞窗口的概念。拥塞窗口指的是在收到一个ACK前发送者能发送的包的数量。如果一个发送者的拥塞窗口被设置为2，这意味着在发送了两个包之后，它必须等到接收端回复的ACK之后才能继续发送。 拥塞窗口越大，发送者就能在相通的时间间隔内向接收端发送更多的数据包。为了更加直观的理解，假设网络传输的延时是88ms，拥塞窗口设置为10，那么在一轮往返传输（88 * 2 = 176ms）时间内可以发送10个数据包。而如果拥塞窗口设置为20，则相同的时间间隔内可以发送20个数据包。 不过当然，提升拥塞窗口的大小，也会提高发生拥塞的概率。拥塞控制算法的目标，就是计算出合适的拥塞窗口大小。 从理论角度来看，拥塞窗口的大小应当就是链接的BDP。 TCP Tahoe TCP Tahoe是在80年代设计出来的拥塞控制算法。那是拥塞问题才刚刚在因特网上出现。算法本身非常简单。增加拥塞窗口分为两个阶段： 第一阶段： Slow Start：算法的开始状态是Slow Start。在这个阶段拥塞窗口在每收到一个ACK就增加1。这种机制有效地在每轮往返传输成功后，将拥塞窗口的大小翻倍。如果拥塞窗口的大小是4，那么在同时会有4个包在传输路途中。当每个包的ACK返回时，拥塞窗口加一，即当这四个包的ACK都收到后，拥塞窗口会翻倍成为8。这个过程会一直持续到拥塞窗口达到阈值，ssthresh。 第二阶段：Congestion Avoidance：当拥塞窗口达到阈值ssthresh时，进入Congestion Avoidance阶段。在这一阶段，每轮往返传输后拥塞窗口加一。也就是说，在上面的例子中，当所有4个包的ACK收到后，拥塞窗口只会加1. 在这个阶段拥塞窗口的大小会大大减小。 当Tahoe检测到丢包后，会把ssthresh设置为当前拥塞窗口的一半，然后将拥塞窗口设置为1，算法重新回到Slow Start阶段。 丢包检测与快速重传 TCP发送端有两种方法来检测丢包现象： 发送端超时。发送端会给每个发送出去的数据包设置一个超时。如果在超时时限达到时尚未收到该包的ACK，则认为发生丢包，并重传改数据包，将拥塞窗口设置为1. 接受者发送回重复的ACK。在TCP中，接收端只会接收按照顺序发送的包。如果收到了不合顺序的包，接收端会返回他收到的最后一个符合顺序的包的ACK。例如，接收端收到了1，2，3，其后又收到了包5，那么接收端会再次回复3的ACK。在Tahoe中，如果发送端检测到重复的ACK，就意味着发生了丢包。这种机制被称为快速重传(Fast Retransmit)，因为这种机制不一定要等待到传输超时。 一些思考 在开头提到的Jupitor Notebook中，我实现了Tahoe，下图是拥塞窗口随着时间变化的曲线： Tahoe的拥塞窗口曲线 注意到上图的中变化曲线存在锯齿形的行为。开始的突增为Slow-Start阶段，后面的平缓部分为Congestion Avoidance阶段。急遽掉落到1则是由于丢包导致的。 为什么Tahoe要如此工作？ Tahoe在工作过程中不断增加拥塞门限的原因是因为网络条件会随着时间不断变化。例如如果另一个发送者开始在同一个信道上发送数据，这会导致可用带宽的降低，其他的发送者需要按照实际情况调整。相反，如果有一个发送者停止发送数据了，可用带宽会增加，这也需要其他发送者根据实际情况来调整。 这种方法其实还是存在很多问题，这也是Tahoe目前已经基本没人使用了。特别的，Tahoe需要很长的时间，尤其是在高带宽网络上，才能全面有效地利用可用带宽。这是因为在拥塞窗口增长到Slow Start门限以后，其增长就变得非常缓慢了。 另外一个问题是，发生丢包并不一定意味着网络发生了拥塞，例如Wifi信道下，本身信道就是可能发送丢失的。对于丢包产生剧烈的将拥塞窗口砍到1并不总是合适的做法。 最后一个问题是，Tahoe使用丢包这个因子来作为判断是否发生丢包的依据。然而由于拥塞发生了丢包，此时调整拥塞窗口已经太晚了。 其他的方法 80年代以后，涌现了不少新的算法来解决上面这些问题。我会在将来的文章中详细讨论这些方法： CUBIC：这个算法在2005年实现，目前是Linux系统的默认拥塞控制算法。如同Tahoe，这个CUBIC也是用丢包作为判断拥塞是否发生的依据。不同的是，CUBIC在高带宽网络下的性能要远高于Tahoe。不同于Tahoe在每一轮往返传输后将拥塞窗口增加1的做法，CUBIC如同其名，使用一个立方函数来确定窗口大小，从而实现拥塞窗口的快速增长。 BBR(Bufferbloat)：这是最近才被Google提出的新的算法。不同于CUBIC和Tahoe，这个算法使用延时来作为判断拥塞是否发生的标识。这背后的思路是延时是拥塞在导致丢包前就能起作用的判断因子。在实际丢包发生前就开始减少发送速率能够带来更高的吞吐率。 公平性 在研究拥塞控制算法时，一个有意思的问题是考虑不同的算法对于同一网络链接上的各个发送者是否公平。如果一个算法在发生拥塞时，没有缩减发送规模，而是按照之前相同的速率继续发送，那么这个算法就是不公平的。在这个结果中，如果同一个链接上 有一个发送者没有采用拥塞窗口控制，而另一个发送者使用Tahoe。从结果可以看到，在一分钟的时间内，Tahoe发送者几乎没法发送任何数据，因为它没有机会增加它的拥塞窗口。而固定窗口的发送者全占了发送信道。 尽管固定窗口发送者是一个不好的情形，这种算法可能具有对其他的算法的不公平地位，从而占据更多带宽。由于缺乏中央控制这，可能有贪婪的发送者蓄意采用固定窗口来谋取更大的带宽。这就是需要从博弈论的角度来研究拥塞控制算法了。 结论 拥塞控制算法是互联网的基础，同时也是在有限信息条件下进行分布式决策的一种迷人的实践。]]></content>
      <categories>
        <category>形而上</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>网络</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Make|自动生成依赖关系]]></title>
    <url>%2Fposts%2F56042%2F</url>
    <content type="text"><![CDATA[Make一般是在Unix环境下使用的自动化编译工具。他本身不是编译器，而是将众多C/C++源文件组织起来，确定其编译方式和编译顺序的工具。一旦我们写好的Makefile配置文件，那么无论多么复杂的工程我们都可以用一条make命令来解决。事实上，尽管通常和C/C++搭配起来使用，make也能应用到其他的编程语言之中。 在使用make过程中的第一个核心问题是处理文件依赖的问题。例如： 12foo.o : foo.c defs.h # foo模块 cc -c -g foo.c 这里foo.o依赖于foo.c和defs.h。当后面两个文件发生变化时，make会自动运行cc -c -g foo.c命令更新foo.o文件。但是，随着项目扩大。这种文件之间的依赖关系会变得非常复杂，一个小的改动可能会涉及到众多依赖关系的修改。因此有必要在项目的开始就引入自动构建依赖关系的工具链。 在跟我一起写Makefile:书写规则这篇教程中，提到了编译器的一个特性：大多数的C/C++编译器都支持一个&quot;-M&quot;的选项，即自动寻找源文件中包含的头文件，并生成一个依赖关系。例如如果我们执行 1cc -M main.c 其输出是： 1main.o: main.c defs.h 注意如果你用的是GNU的C/C++编译器，你得用&quot;-MM&quot;参数，不然，&quot;-M&quot;参数会把一些标准库头文件也引入进来。 这篇教程里面详细阐述了如果在Makefile中使用这一特性的方法，综合而来就是： 123456# 对于每个.c源文件，建立一个描述其依赖关系的.d依赖文件%.d: %.c @set -e; rm -f $@; \ $(CC) -M $(CPPFLAGS) $&lt; &gt; $@.$$$$; \ sed &apos;s,\($*\)\.o[ :]*,\1.o $@ : ,g&apos; &lt; $@.$$$$ &gt; $@; \ rm -f $@.$$$$ 上述命令中sed命令的作用是在依赖关系对中，在左侧加上.d文件本身。即 将 12&gt; main.o: main.c defs.h&gt; 转换成 12&gt; main.o main.d : main.c defs.h&gt; 然后将生成的依赖关系文件include进来 12sources = foo.c bar.cinclude $(sources:.c=.d) 在教程中还提到，这个include要放在默认目标之后，避免include载入的文件的目标替换了默认目标。 走完上面的流程，会得到一个类似的如下内容的文件： 1234567891011121314151617%.d: %.c @set -e; rm -f $@; \ $(CC) -M $(CPPFLAGS) $&lt; &gt; $@.$$$$; \ sed &apos;s,\($*\)\.o[ :]*,\1.o $@ : ,g&apos; &lt; $@.$$$$ &gt; $@; \ rm -f $@.$$$$sources = main.c foo.c bar.cobjs = $(sources:.c=.o)include $(sources:.c=.d)main: $(objs) $(CC) -o main $(objs).PHONY : cleanclean: @rm -f *.d *.o @rm -f ./main 不过按照这个Makefile第一次执行的时候会产生一个问题：第一次执行时，.d文件尚未生成，这里的include导入的文件不存在，会产生如下的错误信息 12Makefile:8: main.d: No such file or directormake: *** No rule to make target 'main.d'. Stop. 最后是通过面向google的debug找到了Autodependencies with GNU make这篇2001年的文章，细致地阐述了这个问题。解决的关键在于在include前面添加一个dash（-），其作用是：如果include的对象不存在，make继续执行，后续make会自动生成.d文件，然后执行include。这篇新的教程提供的完整Makefile示例如下（和前面的形式有不同，但是思路是一致的）： 1234567891011121314151617OBJS := foo.o bar.o# linkproggie: $(OBJS) gcc $(OBJS) -o proggie# pull in dependency info for *existing* .o files-include $(OBJS:.o=.d)# compile and generate dependency info%.o: %.c gcc -c $(CFLAGS) $*.c -o $*.o gcc -MM $(CFLAGS) $*.c &gt; $*.d# remove compilation productsclean: rm -f proggie *.o *.d]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>make</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于无神论者的笑话两则]]></title>
    <url>%2Fposts%2F39480%2F</url>
    <content type="text"><![CDATA[## 一 一个坚定的无神论者去世了，突然发现自己在一个昏暗的过道里。过道里有一个牌子，上写“通向地狱”。没办法，那就进地狱吧。他开门进去，几乎不敢相信自己的眼睛：阳光明媚，暖风宜人，白沙滩，棕榈树，每一百米一个酒吧，到处都是欢快的人们。他沿着沙滩漫步，突然发现一个长着马脚和尾巴的家伙坐在一个沙滩躺椅里。他走上前去问，你是魔鬼吗？魔鬼回答说是，并热烈欢迎新人到地狱。不久，想了解一下地狱的无神论者，两个沙包之间看到一个很大很深的坑，便好奇地往里看，结果吓坏了：坑底烧着熊熊大火，到处是哭天喊地的人，撒了疯的怪物披头盖脸地往人身上打。 无神论者疑惑地跑回魔鬼身边，痛心地问：后边沙包那里那个坑是怎么回事？魔鬼说：噢，他们哪，都是基督徒。他们非要这样，我也没什么办法…… 二 一个忠诚的共产党员死了，上帝不愿意在天堂接受无神论者的灵魂，于是把他送到地狱。一个月后，魔鬼大汗淋漓跑来说“你赶紧把那人带走吧，他差不多把我所有小鬼都发展成了少先队员！” 上帝就接受了。 又过了一月，魔鬼幸灾乐祸地问上帝“那共产党员怎样了？”上帝说：“首先请叫我同志” 非常惭愧，只讲了两个微小的笑话，谢谢大家 来源：https://www.zhihu.com/question/27030419/answer/121040045 续 宗教逻辑]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
        <tag>宗教</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[酵素]]></title>
    <url>%2Fposts%2F25658%2F</url>
    <content type="text"><![CDATA[今天在朋友们的群里又看到有朋友在谈论吃酵素的事情。这让我想到了2017年二月，我去东京交流访问，参观了日本最大的酵素生产商之一：中原株式会社。有意思的是，这家公司虽然是日本的公司，却是中国人创立的。之所以公司的名字叫做中原，是因为创始人是郑州人。当时接待我们的人中，有一个负责做产品研发的生物博士，筑波大学毕业，也是中国人。他带我们参观了公司总部顶楼的一个小型的检测间。有一个随行的朋友很实诚地问道：“酵素这个东西到底有没有用。”那名生物学博士倒也没直接回答，而是笑着说：”大家都是学工科的，都懂“。 酵素这个东西，其实就是酶的另一种说法。吃酵素的风气，也是从日本舶来的。不过在日本那边，酵素是作为”保健食品的“，因此，在酵素包装上面，是不能声称任何疗效的。日本的酵素从业者，不得不利用各种渠道在宣传刊物上宣传酵素成分的一些益处（还不能直接说产品），然后在包装上注明这些成分，以此来吸引消费者购买。不过在中国，法规不是这么健全，因此中国的酵素商家，宣传起酵素功效来，宛如过去街头卖大力丸一般，怎么牛逼怎么来。 某厂商的酵素宣传 其实，酵素就是酶，也就是蛋白质，进入到肠胃，也都被分解成氨基酸，和鸡蛋，肉类无异。故，吃酵素还不如吃鸡蛋，同等营养的情况下，鸡蛋更便宜。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
        <tag>智商税</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS绕过SIP安全机制限制的一种办法]]></title>
    <url>%2Fposts%2F36948%2F</url>
    <content type="text"><![CDATA[SIP(System Security Protection)是苹果在OSX EI Capitan及其后版本的操作系统中引入了一种新的安全机制。望文生义就可以看出，这个安全机制是用来维持系统的完整性，保护系统免收恶意软件的篡改。具体来说，SIP限制了root账户的权限范围，限制了root用户在对一些系统保护目录即其中文件的操作能力。 SIP的保护范围包括下列路径： /System /usr /bin /sbin OSX的预装应用 第三方应用可以继续操作的目录包括： /Applications /Library /usr/local 但是任何对于安全性加强都意味着对灵活性的削弱。例如，在SIP保护下，类似proxychains-ng的程序无法再给受保护的目录下的程序添加网络钩子(hook)。 proxychains ng (new generation) - a preloader which hooks calls to sockets in dynamically linked programs and redirects it through one or more socks/http proxies. 一般来说，很多解决方案都建议关闭SIP功能（例如proxychains-ng的issue中给出的方法：# issue78）。不过这样也意味着丧失了SIP提供的保护功能。这篇文章给出了一个妥协的做法。在保留SIP的保护的同时，为保护目录下的程序应用proxychains-ng（其他类似的应用场景也可以使用这个办法）。这个解决方案的思路其实很简单：既然保护目录下的程序我们不能动，那么我们把保护目录下的程序复制一份到其他目录下运行就可以。 首先创建一个新的文件夹： 1mkdir ~/.unprotected_apps 然后将这个路径添加到PATH环境变量的头部： 12# 可以添加到shell的配置文件中，如~/.bashrc或者~/.zshrcexport PATH="~/.unprotected_apps:$PATH" 然后将需要添加钩子的应用复制到这个目录下就可以了，例如： 12cp $(which ssh) ~/usr/bin/sshcp $(which curl) ~/usr/bin/curl]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks上手配置]]></title>
    <url>%2Fposts%2F37347%2F</url>
    <content type="text"><![CDATA[Shadowsocks配置的一个非常便利之处在于，Shadowsocks支持将配置信息导出成二维码再在其他机器上导入。这节约了很多沟通成本。所以在开始这篇教程之前，你需要有一个Shadowsocks的配置信息。可以是具体参数，或者是一个配置二维码。 1. 客户端准备 Shadowsocks提供了绝大多数平台的客户端支持，甚至包括智能路由器。我们这里介绍最为常见桌面端的平台上的配置。 这里我提供了mac和win这两个主要平台截止到目前为止最新版本的客户端下载： macOS客户端下载; win客户端下载. 其中，mac文件下载下来解压缩后，直接拖拽进入Application文件夹（应用文件夹），然后双击打开使用就可以了。win端的文件解压缩后是一个可以直接运行的绿色版（不需要安装）。将解压缩文件移动到一个稳妥的位置，然后双击打开Shadowsocks.exe文件就可以了（此时右下角会出现一个小飞机图标） 更加丰富的客户端下载：https://shadowsocks.org/en/download/clients.html 2. 导入配置 写这篇文章的时候我使用的是mac，因此后面的配置方法过程都以mac为例。mac和win上客户端的使用都是相通的。不同的是小飞机图标在mac中位于顶部，而在win中位于底部。 ShadowsocksX-NG右键菜单截图 右键点击小飞机图标可以看到如上图所示的菜单。其中 第一个section中，负责控制Shadowsock的开启和关闭，我这里显示的是已经开启了Shadowsocks，如果你的客户端代理还没有启动，点击一下&quot;打开 Shadowsocks&quot; 第二个section中，可以设置Shadowsocks的代理模式。其中PAC模式是最为常用模式。在这种模式下，Shadowsocks会根据一张预先订好的表，来判断你当前访问的网址是否被墙了。如果是就会通过代理访问这个网站，否则照常直接连接网站就可以了。与之相对的，全局模式是让所有的网站都通过代理进行访问。 第三个section中，可以进行服务器的配置。 如果你是使用二维码进行配置，那么，将二维码用预览打开，确保这个预览窗口位于最上层可见，然后点击菜单中的“扫描屏幕上的二维码”就可以导入服务器配置了。 如果你是使用详细配置信息进行配置，那么需要进入服务器 -&gt; 服务器设置，手动填写各个参数进行添加。 第四个section是用来配置本地代理和PAC的，对于这部分的详细讨论超出了这篇文章的范畴，我们会在后续的文章中进行讨论。 3. 手机端配置 由于政策原因，手机端APP，尤其是iOS的手机端APP的审查情况非常严重，基本上很少有APP能够长期屹立不倒。因此手机端APP的选择要实时来看。我自己使用的SuperWingy这个应用已经下架了（不过从已购里面还是可以下载的）。因此，大家发现还有什么可以用的手机端应用，就更新在评论里把。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开源对象存储服务(OSS) Minio 及其在Hexo中的使用]]></title>
    <url>%2Fposts%2F5440%2F</url>
    <content type="text"><![CDATA[研究对象存储服务(OSS)是因为考虑到将来可能会有在博客上放出一些可供分享的文件下载的服务需求，直接使用现有图床，容易混杂乱。因此我考虑重新建立一个独立OSS存储服务。直接Google搜到了Minio这个框架，10k+的Star，就决定选择这个了。Minio框架有如下几个优势： 可以Docker部署，非常省事 文档完善 全面的平台支持 多种客户端语言支持（有完善的JS SDK） ## 1. Minio部署 使用Docker部署可以说是非常方便省事了。我的部署命令如下： 1234567docker create -p 9000:9000 \-e "MINIO_ACCESS_KEY=your-access-key" \-e "MINIO_SECRET_KEY=your-secret-key" \--name=minio \-v /path/to/minio/data:/data \-v /path/to/minio/config:/root/.minio \minio/minio server /data 其中的访问秘钥对需要替换成你自己设置的值。这一对值稍后会用于网页端的登录。然后用 1docker container start minio 来启动镜像。完成后就可以在http://domain.com:9000中访问到了，输入docker命令中的秘钥对来登录。 登录界面 而后你可以按照Lychee图床教程中的做法，添加Nginx反向代理和HTTPS支持。 2. Hexo中使用 部署完成后我才发现一个问题，那就是Minio生成的外链是强制有过期时间的，而且长度最多只七天。那我就不能像直接复制粘贴外链来使用了，同时，手动来每七天更新一次链接也是不可接受的。因此用Hexo脚本来自动实现了利用Minio的API接口来更新下载链接。脚本内容如下： 1234567891011121314151617181920212223'use strict';const Minio = require('minio');var hexo = hexo || &#123;&#125;;var fs = fs || require('fs');var yaml = yaml || require('js-yaml');var minio_client = minio_client || new Minio.Client(yaml.safeLoad(fs.readFileSync(__dirname + "/minio_key.yml", 'utf8')));hexo.extend.tag.register('minio', async (args, content) =&gt; &#123; var bucket = 'default', resource_name = ''; if (args.length == 1) &#123; resource_name = args[0]; &#125; else &#123; resource_name = args[1]; bucket = args[0]; &#125; var file_url = await minio_client.presignedGetObject(bucket, resource_name); return `&lt;a target="_blank" href="$&#123;file_url&#125;"&gt;$&#123;content&#125;&lt;/a&gt;`;&#125;, &#123;async: true, ends:true&#125;); 在博客工程的根目录下创建一个文件夹scripts,在其中创建一个js文件，如index.js，然后将上述脚本内容粘贴进去。然后在这个目录下创建设置文件，minio_key.yml，文件中需要包含如下信息： 1234endPoint: 'minio.domain.com'accessKey: 'your-access-key'secretKey: 'your-secret-key'useSSL: true # 是否使用https 然后还需要安装依赖 1npm install --save minio 至此我们完成了脚本的安装。脚本为我们提供了一个标签插件，其使用范例如下： 123&#123;% minio 'bucket_name' 'resource_name' %&#125;下载链接&#123;% endminio %&#125; 在使用Hexo进行静态页面渲染时，这部分内容会被自动渲染成下载链接： 1&lt;a target=&quot;_blank&quot; href=&quot;download_url&quot;&gt;下载链接&lt;/a&gt; 不过这种方法还是有一个显而易见的缺点：你需要是一个非常勤奋的作者，每周都来发布一次文章，不然旧文章的链接还是会失效。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Hexo</tag>
        <tag>Minio</tag>
        <tag>OSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks持续优化]]></title>
    <url>%2Fposts%2F35429%2F</url>
    <content type="text"><![CDATA[## Fast TCP开启 如果双端都支持FastTCP，那么可以通过开启FastTCP来降低延时。服务端设置方法有两种，要门在config.json中添加fast_open为true，要么在执行ssserver带上--fast-open。然后在命令行中运行 1echo 3 &gt; /proc/sys/net/ipv4/tcp_fastopen 进一步优化 这个优化方法适合所有的shadowsocks版本，具体方法如下。创建文件/etc/sysctl.d/local.conf，并在文件中添加如下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# max open filesfs.file-max = 51200# max read buffernet.core.rmem_max = 67108864# max write buffernet.core.wmem_max = 67108864# default read buffernet.core.rmem_default = 65536# default write buffernet.core.wmem_default = 65536# max processor input queuenet.core.netdev_max_backlog = 4096# max backlognet.core.somaxconn = 4096# resist SYN flood attacksnet.ipv4.tcp_syncookies = 1# reuse timewait sockets when safenet.ipv4.tcp_tw_reuse = 1# turn off fast timewait sockets recyclingnet.ipv4.tcp_tw_recycle = 0# short FIN timeoutnet.ipv4.tcp_fin_timeout = 30# short keepalive timenet.ipv4.tcp_keepalive_time = 1200# outbound port rangenet.ipv4.ip_local_port_range = 10000 65000# max SYN backlognet.ipv4.tcp_max_syn_backlog = 4096# max timewait sockets held by system simultaneouslynet.ipv4.tcp_max_tw_buckets = 5000# turn on TCP Fast Open on both client and server sidenet.ipv4.tcp_fastopen = 3# TCP receive buffernet.ipv4.tcp_rmem = 4096 87380 67108864# TCP write buffernet.ipv4.tcp_wmem = 4096 65536 67108864# turn on path MTU discoverynet.ipv4.tcp_mtu_probing = 1# for high-latency networknet.ipv4.tcp_congestion_control = hybla# for low-latency network, use cubic instead# net.ipv4.tcp_congestion_control = cubic 然后运行 1sysctl --system 应用上述设置。最后在启动脚本中，于ssserver前添加 12ulimit -n 51200 这个设置方法，会消耗比较多的内存，但是会换来速度的大幅上升。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks：多用户账号独立，并限制用户连接数]]></title>
    <url>%2Fposts%2F7835%2F</url>
    <content type="text"><![CDATA[自己搭建了一个SS服务器以后，自然而然的会同身边的朋友共享。自然，身边的朋友一起用，大部分服务器配置都可以毫无压力的支撑。但倘若一传十十传百，最后成百上千的人一起用一个服务器，那就撑不住了。 当然你可以隔一段时间换一次密码，但是后面的麻烦事也不少（要同步更新不同设备上的设置，身边的朋友来问你新设置）。 几天我研究了一下，为ss服务器增加了多用户即为每个用户设置独立的连接数限制的方法，这样能够比较完美的解决同朋友共享服务器的问题了。 这里默认你已经知道怎么按照通常的方法安装和配置SS了。如果你不了解的话，网络上的文章很多的。 1. 多用户的实现 多用户的实现比较简单，Python和Go实现的服务器自带多用户支持。通常的配置我们一般是这么写 123456&#123; "server": "::", "server_port": "8888", "password": "yourpassword" // Other configs&#125; 只需要将配置文件按照下面的方式进行修改就可以实现多用户了。 123456789&#123; "server": "::", "port_password": &#123; "8881": "password1", "8882": "password2", "8883": "password3" &#125; // other configs&#125; 就可以了。之后不同的用户可以通过不同的端口访问，而每个端口都有独立的密码。 Further Reading: Reference 2. 限制用户连接 我在网上调查了一下实现限制用户连接的方法，很多都提到了通过iptables来进行设置。但是这种方法太过复杂，很容易出问题。后来我找到一个ss的补丁，可以比较好的解决这个问题。补丁地址是falssen/PySocket。 这个工程提供了一些其他的功能，但是我们这里只关注Limit_Clients文件夹下的socket.py这个文件。这个文件的原理是利用Python包导入的机制，用自定义的socket.py来替换默认的socket包，并在socket接口中植入一些新的功能。 按照READMe.md的提示安装好socket.py文件 &gt; 有很多朋友不知道这里要怎么处理socket.py文件。其实并不复杂。用which命令查看一下ss脚本安装的位置，一般情况下是/usr/local/bin/，那么你只需要把socket.py文件放到/usr/local/bin下面就行。这一操作的原理是，python在导入包时总是先检查当前目录。注意，如果修改了socket.py文件，需要重启进程才能生效。 然后修改文件中white_list和black_list两个变量。例如我自己使用的1017端口，我不希望添加限制，则将white_list设置为 1white_list = [1017] 我给朋友们用的是[1018]端口，我希望这个端口的连接数不要超过40个，则将black_list设置为 1black_list = &#123;1018:40&#125; 3. 注意 注意方法的实质是限制接入的客户端IP数量，因此，处在同一路由器下面的多台设备也会被识别为一台。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自建图床: Lychee]]></title>
    <url>%2Fposts%2F65048%2F</url>
    <content type="text"><![CDATA[之前用的图床sm.ms的图片突然挂了。不知道为何，图片还是能够上传，但是访问图片的链接会出ERR_SPDY_PROTOCOL_ERROR的错误。 ERR_SPDY_PROTOCOL_ERROR错误示意图 正好我自己的翻墙服务器的硬盘长期富余。虽然只有十几个G，搭建一个自己图床还是够用的。更重要的是，Dogital Ocean的服务器的流量非常多（我买的$5的服务器的流量有一个T）。我选择的开源图床框架是Lychee。这个框架支持Docker安装，可以省很多事情。 1. Docker安装Lychee 常规的安装方法可以参考官方文档。我这里只介绍Docker方式。如果你没有什么特别的需求，Docker方式应该是非常适合你的。 注：这篇教程只是对于我的操作过程的一个记录，因此对于一些依赖环境的安装没有面面俱到。这些问题，都可以面向google进行解决。 1.1 Docker环境准备 首先你要安装一个Docker环境。在Ubuntu上，安装非常简单： 12$ sudo apt update$ sudo apt install docker-io 有时还需要将你当前用户加入到docker组中，这样每次执行docker命令不需要加sudo了。这个操作可能在安装过程中自动完成了，如果你发现docker命令执行时提示有权限相关的问题，可以运行 1$ sudo adduser user docker 注意确保一下docker-compose也安装完毕了。我们需要通过docker-compose来将Lychee和数据库组装在一起。 12$ docker-compose -vdocker-compose version 1.17.1, build 6d101fb 1.2 安装Lychee 首先创建好目录树： 12345lychee|-- config|-- db|-- pictures|-- docker-compose.yml 其中，config和pictures分别用来存储Lychee的设置和图片文件。db文件夹则是用于数据库，这三个文件夹需要你手动创建。docker-compose.yml文件内容如下： 123456789101112131415161718192021version: '1'services: lychee: image: linuxserver/lychee links: - lychee-db:lychee-db volumes: - /path/to/lychee/config:/config - /path/to/lychee/pictures:/pictures ports: - 8000:80 lychee-db: image: mariadb:10 volumes: - /path/to/lychee/db:/var/lib/mysql environment: - MYSQL_ROOT_PASSWORD=&lt;choose root password&gt; - MYSQL_DATABASE=&lt;db name&gt; - MYSQL_USER=&lt;username&gt; - MYSQL_PASSWORD=&lt;username&gt; 目前我没发现lychee的这个镜像支持用环境变量来配置数据库信息。所以上面对应的数据库信息后续需要在网页端手动输入。 然后在这个文件夹下运行 1$ docker-compose up -d 然后访问http://yourdoman.com:8000就可以访问了。 1.3 Lychee配置 在访问上述网页之后，Lychee会提示我们输入数据库信息。 Lychee 配置 注意这里的Database Host要填写lychee-db。其他的设置与上面的docker-compose.yml文件中的一致即可。 而后按照提示创建登录账户： 创建账户 2. Lychee Advanced 2.1 使用Nginx进行反向代理 Nginx配置文件如下： 12345678910111213server &#123; server_name imgs.codewoody.com; client_max_body_size 50M; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:8000; &#125;&#125; 2.2 启用HTTPS 目前来看，Let's encrypt仍然是个人建站启用HTTPS的不二之选。其使用教程可以说是非常简明了，具体参考certbot。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>折腾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这个博客是如何建立起来的]]></title>
    <url>%2Fposts%2F53793%2F</url>
    <content type="text"><![CDATA[在博客问题上我可是折腾了很多回了，先是尝试了wordpress（来来回回很多次），不过wordpress使用起来，感觉还是太“重”，很多东西配置起来非常麻烦(包括主题设置，甚至是Markdown支持)。后来迁移到简书上面，被国家政策教做人(一篇关于Shadowsocks的文章被屏蔽了，有种吃苍蝇的感觉)。思前想后，还是自己host自己的博客好。最终我是选择了Hexo + Github的方案，好处如下： 对Markdown支持比较好 不需要自己折腾服务器 用Git管理非常方便 在这篇文章里，我整理一下整个博客的搭建过程。 1. Hexo Setup Hexo是一款基于Node.js的静态博客框架，可以生成静态页面部署在Github和Heroku上面。Hexo的搭建过程如下： 申请域名 创建Github仓库 安装Hexo及其依赖 绑定域名 1.1 申请域名 虽然部署在Github上Github会提供一个免费的域名，但是如果有自己的独立域名的话，网站会更像&quot;博客&quot;一点。申请域名的地方有很多，我的域名是选用的阿里云的。传送门：阿里云-为了无法计算的价值。 1.2 创建Github仓库 在Github中创建一个名字为username.github.io的仓库，注意这里的username需要替换为你自己的用户名。例如我的仓库名字为huangy10.github.io。 &gt; 你可以尝试在这个仓库中添加一个名为index.html的文件，在其中接入hello world。然后访问http://username.github.io 就可以看到这个页面了。 &gt; 不过注意尝试之后删除这个仓库重新创建。后面我们在部署Hexo的时候最好让这个仓库是空的。 &gt; 1.3 安装Hexo及其依赖 1.3.1 安装Git，并配置好SSH秘钥 这里Github有全面的教程，传送门：https://try.github.io/ 1.3.2 安装Node.js Mac平台下面安装Node.js非常简单，可以通过Homebrew进行安装: 1brew install node 如果没有安装Homebrew，可以在Terminal中输入下面这个命令快速安装： /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 安装完成后可以通过node -v来验证安装是否成功，并查看安装版本。进一步通npm -v来检查npm也正确安装了。 1.3.3 安装Hexo 使用npm来安装Hexo： 1npm install -g hexo-cli 完成安装以后，挑选一个合适的路径，然后运行 1hexo init blog 这个命令会在当前文件夹中创建一个名为blog的文件夹。博客相关的文件都会存储在这个文件夹中。cd进入这个文件夹，然后运行 1234# 生成静态文件hexo g# 在本地运行一个测试服务器来伺服静态文件hexo s 然后在浏览器中访问http://localhost:4000 就可以访问自己的网站了。 博客初始页面 我们来看一下Hexo博客项目下的目录结构： Hexo目录结构 其中比较重要的是： _config.yml是整个项目的配置文件，YAML格式； public是发布的静态文件内容。注意这个文件会在hexo g命令后重新生成，其中内容会被重置； source是工程源文件，其中的_posts文件夹存储了博文的Markdown文件。其中的其他文件，则会在hexo g命令的作用下发布到public文件夹中； themes存储了博客的主题。在各个主题自己内部也有自己的_config.yml文件，用来定制化模板的参数。 1.4 Hexo部署 我们选择将Hexo部署到Github上。打开博客项目根目录下的_config.yml文件，跳到最后，修改 1234deploy: type: git repo: git-repo-path(ssh方式，不要用https) branch: master(不出意外就填写master) 保存退出。 然后我们需要安装一个git部署的工具: 1npm install hexo-deployer-git --save 然后运行 123hexo cleanhexo ghexo d 三个命令，就可以逐步完成清理之前的生成，重新生成静态文件，将静态文件部署到Github上。全部完成后访问username.github.io 。就可以看到站点了。 2. Hexo Advanced 2.1 自定义域名 使用github提供的免费域名还是不够fancy，我还是希望使用自己的域名。首先进入域名管理后台，添加两条记录。分别是 yourdomain.com 添加一条A记录，指向username.github.io对应的ip地址。（这个ip地址可以通过ping命令看到） www.yourdomain.com 添加一条CNAME记录，指向username.github.io 然后在本地博客工程中的public文件夹下，添加一个CNAME文件，文件中写入自定义的域名www.yourdomain.com。重新三连： 1hexo clean; hexo g; hexo d 这是输入https://www.yourdomain.com就可以访问自己的网站了（可能需要等一段时间让dns刷新） 2.2 更换主题 自己搭建博客的乐趣之一就是各种更换主题。Hexo有自己的主题市场：Themes。我选择的主题是laughing。这个主题比较简洁，而且支持响应式布局。不过，这个主题支持的多说这个评论平台已经关闭了。其安装过程如下（其他的主题的安装方式大同小异）： 首先安装主题依赖的pug模板引擎: 1npm install hexo-renderer-pug --save 然后将主题文件夹下载到themes目录： 12cd themesgit clone git@github.com:BoizZ/hexo-theme-laughing.git 最后修改博客项目根目录下的_config.yml文件： 1theme: hexo-theme-laughing 主题的配置方式可以参考主题的Github文档。需要注意的是，文档中所说的_config.yml文件是指的主题文件夹中的配置文件，而非博客项目根目录下的配置文件。 2.3 插件 Hexo提供了很多插件来增强博客的功能。这个部分我也正在研究。这里我列出一下目前我安装了的插件： hexo-addlink: 在文章末尾中添加本文的链接 hexo-generator-feed: 生成rss订阅 hexo-generator-sitemap: 生成站点地图]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Hexo</tag>
        <tag>Github</tag>
      </tags>
  </entry>
</search>
