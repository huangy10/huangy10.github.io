<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Struct in Vector: 进一步讨论]]></title>
    <url>%2Fposts%2F62430%2F</url>
    <content type="text"><![CDATA[之前我们讨论了C++中将结构体放置在std::vector容器内的操作风险。这里我们来进一步讨论如何处理在容器中存储的结构体数据。 前文中提到，如果我们尝试获取容器中的结构体时，我们直接拿到的是该结构体的拷贝，如果要对结构体成员修改，我们需要整体进行两次复制： 12345678910111213141516std::vector&lt;struct A&gt; data;// ...struct A val = data.at (0);val.b = c;data[0] = val;``这种操作显然是不经济。一种『粗暴』的方法是使用`std::vector::data`函数获取底层数据的指针，然后操作这个指针。但是这种方法不太优雅，也不安全。合适的做法是使用引用```cppstd::vector&lt;struct A&gt; data;// ...struct A &amp; val = data[0];val.b = c; 放在遍历的场景中，可以使用如下的形式： 1234std::vector&lt;struct A&gt; data;// ...for (auto&amp; val : data) &#123;...&#125;]]></content>
      <categories>
        <category>编程研究</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CPP: STL map的用法]]></title>
    <url>%2Fposts%2F3626%2F</url>
    <content type="text"><![CDATA[抛开具体的编程语言场景，map是一类非常基本的数据组织形式，其作用是将一个可Hash的值，映射到另一个值，而且一般来讲是一对一的（存在一对多的情况）。map内部使用了红黑树，这棵树具有对数据自动排序的功能，使得对map的检索意义达到非常高的效率。基于键值的查找的复杂度是Log(N)。 这里讲讲C++标准库里面map的用法。 使用map 头文件： 1#include &lt;map&gt; 声明时需要指明键与值的类型： 1std::map&lt;int, string&gt; persons; 数据插入 数据插入有三种方法： 使用insert函数插入pair数据，例如： 123std::map&lt;int, string&gt; students;students.insert (std::pair&lt;int, string&gt; (1, "Student A")); 用insert函数插入value_type的数据，例如： 123std::map&lt;int, string&gt; students;students.insert (std::map&lt;int, string&gt;::value_type (1, "Student A")); 用Subscript方式插入数据，例如： 123std::map&lt;int, string&gt; students;students[1] = "Student A" 上面三种插入方式的区别在于，第三种默认会覆盖已经存在的映射，而前两个不会。前两个插入方式等价，在插入的键已经存在于映射中时，当前的插入语句会被忽略。那么如何知道插入是否成功呢？可以通过insert函数的返回值来判断。 123456789101112std::map&lt;int, string&gt; students;// res为pair&lt;map&lt;int, string&gt;::iterator, bool&gt;乐行auto res = students.insert (pair&lt;int, string&gt; (1, "Student A"));if (res.second == true) &#123; std::cout &lt;&lt; "Insert successfully" &lt;&lt; std::endl; &#125;else &#123; std::cout &lt;&lt; "Insert fail" &lt;&lt; std::endl; &#125; 数据的遍历 使用迭代器： 12345for (auto iter = students.begin (); iter != students.end (); iter ++ ) &#123; // first为key，second为value cout&lt;&lt;iter-&gt;first&lt;&lt;' '&lt;&lt;iter-&gt;second&lt;&lt;endl; &#125; 查找并获取map中的元素 查找是map的核心功能。我们可以使用find函数来进行查找。当找到目标时，返回一个迭代器，否则返回end。 123456789101112std::map&lt;int, string&gt; students;// ...auto iter = students.find (1);if (iter == students.end ()) &#123; std::cout &lt;&lt; "not found " &lt;&lt; std::endl; &#125;else &#123; string studentName = iter.second; &#125; 删除元素 123456789std::map&lt;int, string&gt; students;// ...auto iter = students.find (1);student.erase (iter);student.erase (1);// 这会清空整个mapstudent.erase (students.begin (), students.end ()); Further Reading C++中的STL中map用法详解 std::map::map]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Weekly - 2]]></title>
    <url>%2Fposts%2F60429%2F</url>
    <content type="text"><![CDATA[新闻 Rick and Morty 第四季将会在11月上映 Rick and Morty · Season 4 华为禁令「取消」 6月29日，为期3天（6月27日至29日）的二十国集团领导人第十四次峰会刚刚在日本大阪落下帷幕。29日上午，中、美两国元首举行了约80分钟的会晤，此后两国共同宣布了两大成果：1）中美双方同意在平等和相互尊重的基础上重启经贸磋商。2）美方表示不再对中国出口产品加征新的关税。 在两国元首会谈之后，美国总统特朗普在记者会上表示，同意让美国公司继续销售产品给华为。 特朗普解释称，这些卖给华为的产品都是美国公司制造的，是很复杂很科学的产品，是只有美国拥有技术和在制造的产品。“实际上我们在硅谷做的事情令人难以执行，没有人能和我们竞争，所以我同意 -- 我很容易地就同意允许他们继续出售这些产品”，特朗普说，“我们让他们继续卖给华为。” 据华尔街日报报道，特朗普称将允许美企向华为供货，中国则将开始购买大量美国农产品。他强调了中国大宗采购美国农产品的意愿，将其归为允许向华为出售美国产品和推迟新关税的一大理由。据美国农业部，周五会谈前，中国采购了54.4万吨大豆。？ 美国家经济委员会主席拉里·库德洛在电视采访中更加详细地解释了解禁一事。他表示解禁即将生效，美国商务部可能会考虑“授予一些临时许可证”，让美国公司与华为恢复业务。对于解禁范围，他强调华为仅可以购买“其它国家同样广泛销售的美国芯片产品”，否认这是“特赦”，表示国家安全仍然是最重要的考虑因素，只要不构成国家安全问题，华为可以恢复从美国企业采购产品。 Fuchsia官方开发者网站上线 Fuchsia 是 Google 打造的下一代操作系统，它不基于 Linux 内核，运行方式也和 Android 完全不同，但可以通过相关工具让 Android 应用可以移植到新系统中。近日 Google 也正式上线了 Fuchsia 的 开发者网站，从这个网站中开发者可以了解到 Fuchsia 的系统开发进展及其采用的技术，为后续开发做好准备。 ps: Android的生态其实有点太过恶劣了： 安卓碎片化严重到什么地步？安卓本身有12个版本，如果每个版本有12个厂商，每个厂商有12个手机型号，因此安卓生态至少包含1,728种&quot;版本- 品牌 - 设备&quot;的组合。 大兴机场竣工 大兴机场 时 4 年半，北京大兴国际机场于 6 月 30 日正式竣工，9 月底将投入运营，各家航空公司也陆续公布了在新机场的航线投入计划。 各家航司的转场投运情况如下： 国航系（国航、国货航、深航、山航、昆明航、国航内蒙、北京航、大连航）留守首都机场，但国航在大兴有 10% 航班时刻； 东航系（东航、上航、中联航、东航江苏、东航云南、东航武汉）转场大兴，但东航的京沪快线留守首都机场； 南航系（南航、厦航、河北航、江西航、重庆航、汕头航、珠海航、贵州航、南航河南）转场大兴； 海航、大新华航等留守首都机场； 首都航空转场大兴； 其他国内航司可选择首都机场或大兴机场任一机场运行，但不得两场运行； 允许外航及港澳台地区航空公司自行选择运行机场包括两场运行。 李彦宏演讲被砸场子 只是为了这张图载一下这个新闻： 宏颜获水 7月3日，在2019年百度AI开发者大会上发生突发状况，百度董事长、CEO董事长李彦宏在展示完小度最新功能后，被台下观众泼水。由于事发突然，现场一度陷入沉默。面对这样的突发状态，现场观众集体给李彦宏加油打气，李彦宏也很快调整状态，并调侃道：发展AI的路上就是会遇到这种挫折。 事件现场 北京石景山发生枪战 应该与扫黑行动有关，据说肇事者已经被抓走了。具体情况不明，舆论被管控了。 软件推荐 Mathpix: 将图片转化成Latex公式，重点是这款软件是免费的！ 文章与言论 Why defensive programming is the best way for robust coding 原生动物是如何演化成后生动物的？ 日常劝退：It's ok to quit your Ph.D，中文:Science「劝退文」：读博压力山大，是时候退学了 读博无疑是一个痛苦的过程。甚至有人说，如今，读博已经变成了“赌博”。面对学业压力，很多博士生选择延期毕业。近日，《科学》杂志发表长文，提供了另一种选择：退学。美国研究生院理事会（Council of Graduate School）公布的数据显示，约1/4的美国科学与工程专业博士生在入学的头3年选择退学。《科学》杂志此次采访了9位博士阶段退学者，并总结了退学的3点理由：对研究失去兴趣，开始追寻其他事业，或是因在学术界的遭遇而心灰意冷。 如何更快地读一本书 呼吸读书法 为什么供给能创造自己的需求呢？实际上，当生产者还没有生产或提供某种新的商品或消费品时，人们不能真正地看到或意识到这种东西带来的用处，因此很难想到对它的实际需求。就像是地铁，为什么10年前没有四通八达的地铁线路，人们也能按部就班地过日子，没有哭着喊着说没有地铁就不能活呢？这是因为当时人们还没有体会过地铁给他们带来的便捷，生活也并不依赖于它，因此并没有对于它有过于迫切的需求。相反，如果换成现在的我们失去了地铁，整个城市或许都会因此而崩溃。 -- 地铁越修越多，交通反而拥挤 经济权力就是权力本身。-- 知乎 - 罗一觉]]></content>
      <categories>
        <category>weekly</category>
      </categories>
      <tags>
        <tag>科技新闻</tag>
        <tag>weekly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo启用Han支持过程中发现的问题]]></title>
    <url>%2Fposts%2F36496%2F</url>
    <content type="text"><![CDATA[汉字标准格式 Han指的是「汉字标准格式」。 「汉字标准格式」是一个集合了「语意样式标准化」「文字设计」「高级排版功能」等三大概念的网页排版框架，使用Sass及JavaScript构架而成。其专为汉字网页提供的美观而标准化的环境，不仅符合传统阅读习惯、更为萤幕阅读提供了既成标准，得以完整解决现今汉字网页设计的排版需求。 总而言之，使用Han这个框架可以让排版更好看。按道理，启用Han应该在NexT主题中的选项即可 1han: true 不过这么设置之后还是不行。原因是启用之后只会引入CSS，而没有引入js渲染，导致一些比较高级的排版效果，如标点调整无法使用。因此，还需要手动调整一下。于themes/next/layout/_layout.swig的body标签底部加入如下内容： 1234567891011121314&lt;script src="https://ethantw.github.io/Han/latest/han.min.js"&gt;&lt;/script&gt; &lt;script&gt; void function()&#123; window.hinst = Han().setRoutine([ 'initCond', 'renderElem', 'renderJiya', 'renderHanging', 'renderHWS', 'correctBasicBD', 'substCombLigaWithPUA' ]).render() &#125;() &lt;/script&gt; 注：使用文档中给的cloudflare CDN地址里面的js文件渲染有问题，会导致标点不可见，使用github.io这个版本提供的文件就没有问题。另外，如果本地的han.min.css有问题，也可以切换成github.io版本。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Debug</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中将结构体放置在std::vector容器内的操作风险]]></title>
    <url>%2Fposts%2F35148%2F</url>
    <content type="text"><![CDATA[有一组长度不固定的参数需要传输，且参数形式为结构体，那么一个比较简单的方法是将这些参数作为一个std::vector。例如 1void f(std::vector&lt;struct ExampleStruct&gt; data); 由于C++是采用值传递的方式，每次对std::vector进行元素的存取操作时，都会对涉及的结构体进行复制。如果结构体的数量比较多，或者结构体的体积比加大，那么这种方式对于计算和内存资源的浪费就比较大了。 那么，折中的办法是在std::vector中存放指针。例如 1void f(std::vector&lt;struct ExampleStruct *&gt; data); 不过，这就给指针的生命周期管理带来了很大的挑战，而且可能会引入非常多耦合性很强的代码。如果函数是state-less，即只对输入参数进行计算，而不更改其他的状态变量，问题倒不是很严重。反之，就会存在很多比较大的漏洞。 由于局部变量存在作用范围的限制 1234567&#123; struct ExampleStruct a; // ... data.push_back (&amp;a); // ... f (data);&#125; 当离开调用f的函数的作用域时，a就会被释放，后续在其他地方访问data时，对应的指针指向的内存区域已经被释放掉了，对其进行访问会导致错误。使用new来讲结构体创建在堆内存上可以解决这个问题，但是这意味着后续这一数据已经利用完之后，要确保此处申请的内存被恰当地释放掉。随着业务逻辑的复杂化，要准确做到这一点会非常困难，强行实现也会带来很多强耦合的代码，扩大引入bug的风险。 我们剩下的选择，就是使用智能指针std::shared_ptr自动管理堆内存的声明周期。就是形式有点复杂了： 1void f(std::vector&lt;std::share_ptr&lt;struct ExampleStruct&gt;&gt; data);]]></content>
      <categories>
        <category>编程研究</category>
      </categories>
      <tags>
        <tag>Debug</tag>
        <tag>ns3</tag>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何自己搭建一个Time Machine服务器]]></title>
    <url>%2Fposts%2F14680%2F</url>
    <content type="text"><![CDATA[如何在Ubuntu上搭建一个简洁的Time Machine服务器呢？网上找到的教程说的都比较杂，这里整理一个刚刚经过实践检验的方法来供大家参考。目标系统是Ubuntu 16.04 LTS。 1. 安装需要的工具 1sudo apt-get install netatalk avahi-daemon 2. 创建一个用于专门用来运行Time Machine进程的用户 1useradd -c "Time machine" -m -s /bin/bash tm 我这里命名为tm，你可以替换为任何你定的名字，但是最好不要使用root用户。 接下来给新用户设定密码 1sudo passwd tm 3. 准备文件夹 12mkdir -R /home/tm/TimeMachineFoldersudo chown -R tm /home/tm/TimeMachineFolder 4. 设置netatalk 首先我们将原有的配置文件备份 1sudo mv /etc/netatalk/AppleVolumes.default /etc/netatalk/AppleVolumes.default.old 然后创建一个新的配置文件 1sudo touch /etc/netatalk/AppleVolumes.default 使用你偏好的编辑器（vim，nano之类）向这个配置文件中加入如下内容 12:DEFAULT: options:upriv,usedots/home/tm/TimeMachineFolder "My Time Machine" options:tm volsizelimit:500000 allow:tm 注意将第二行的文件夹路径设定为你再第三步中创建的文件夹的路径。另外，第二行中的volsizelimit设定了Time Machine将会使用的最大硬盘空间，单位是MB。 5. 重启netatalk服务来应用更改 1sudo service netatalk restart 6. 在Mac上连接到Time Machine 首先直接尝试在Time Machine中选择这个服务器（会显示在可用磁盘下面，名字显示为第四步中你netatalk设置文件中指定的名字）。 如果你无法找到，那么打开Finder并按下⌘+K，在弹出来的窗口中，于服务器地址一栏输入afp://IP.of.your.server/，然后点连接。如果提示需要输入用户名和密码来登录，那就输入第二步中你设定的用户名密码即可。 示意图 ref：Concisest guide to setting up Time Machine server on Ubuntu Server 12.04, 14.04 &amp; Debian | Dae’s blog]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>macOS</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[键盘上的符号的英文读法]]></title>
    <url>%2Fposts%2F20487%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930! 叹号 exclamation mark/bang ? 问号 question mark , 逗号 comma . 点号 dot/period/point : 冒号 colon ; 分号 semicolon ” 双引号 quotation marks/double quote ‘ 单引号/撇号 apostrophe/single quote ` 重音号 backquote/grave accent * 星号 asterisk/star + 加号 plus sign - 减号/横线 hyphen/dash/minus sign/ = 等号 equal sign / 斜线 slash \ 反斜线 backslash/escape | 竖线 bar/pipe/vertical bar _ 下划线 underline/underscore $ 美元符号 dollar sign @ at at sign # 井号 crosshatch/sharp/hash % 百分号 percent sign/mod &amp; and/和/兼 and/ampersand ^ 折音号 circumflex/caret ~ 波浪号 tilde &#123;&#125; （左右）花括号/大括号 (left/right|open/close) braces [] （左右）方括号/中括号 (left/right|open/close) brackets () （左右）圆括号/小括号 (left/right|open/close) parentheses &lt;&gt; 尖括号 angle brackets &lt; 大于号 less than &gt; 小于号 greater than]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAC: @rpath的坑]]></title>
    <url>%2Fposts%2F21028%2F</url>
    <content type="text"><![CDATA[Problem 这篇文章的缘由是我在尝试使用ns3带的NetAnim程序时，显示了下面这个错误： 1234dyld: Library not loaded: @rpath/QtGui.framework/Versions/4/QtGui Referenced from: /path/to/ns-allinone-3.28/netanim-3.108/./NetAnim Reason: image not found[1] 86663 abort ./NetAnim 这是一个动态链接的错误，所以没法通过编译的时候添加LDFLAGS来解决。不过错误里面的@rpath这个东西倒是挺有意思，显然并不是环境变量。我在网上查了很多，但是大多数是围绕xcode讨论的，不太适用于我面临的场景（命令行）。不过这些文章（如这篇)能够大致阐明@rpath的用途。简而言之，@rpath是一个类似Shell中的PATH的变量，程序在执行时会从@rpath指定的路径中寻找动态链接库文件。那么剩下的问题就是我们如何操作这个变量了。 Solution 通过otool我们可以查看一个程序的动态链接文件搜索地址，例如我要用的NetAnim： 123456$ otool -L ./NetAnim./NetAnim: @rpath/QtGui.framework/Versions/4/QtGui (compatibility version 4.8.0, current version 4.8.7) @rpath/QtCore.framework/Versions/4/QtCore (compatibility version 4.8.0, current version 4.8.7) /usr/lib/libc++.1.dylib (compatibility version 1.0.0, current version 400.9.0) /usr/lib/libSystem.B.dylib (compatibility version 1.0.0, current version 1252.50.4) 而我们可以通过install_name_tool来对这些地址进行操作。 12$ install_name_tool -hUsage: /Library/Developer/CommandLineTools/usr/bin/install_name_tool [-change old new] ... [-rpath old new] ... [-add_rpath new] ... [-delete_rpath old] ... [-id name] input 对我而言，我需要将Qt4的动态链接库添加到NetAdmin的搜索路径中去，可以使用如下的命令： 1install_name_tool -add_rpath /usr/local/Cellar/qt@4/4.8.7_3/lib ./NetAnim 大功告成。]]></content>
      <categories>
        <category>Debug</category>
      </categories>
      <tags>
        <tag>macOS</tag>
        <tag>Debug</tag>
        <tag>ns3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo文章置顶/置底方法研究]]></title>
    <url>%2Fposts%2F42846%2F</url>
    <content type="text"><![CDATA[这篇文章讨论如何在Hexo中方便地实现文章置顶功能。 最初我采用了Hexo文章置顶的方法。这个方法还是非常简单有效，不过存在一个问题：即不支持使用负数的top值将文章放在末尾。因此我做了 一点修改。 原始方法 原始方法的核心思想是在Front-Matter中添加一个自定义的top字段，然后在hexo-generator-index中使用这一字段来实现排序。具体操作为，修改文件node_modules/hexo-generator-index/lib/generator.js，添加 如下代码： 1234567891011posts.data = posts.data.sort(function(first, second) &#123; if (first.top &amp;&amp; second.top) &#123; // 两篇文章top都有定义 return first.top == second.top ? second.date - first.date : second.top - first.top //若top值一样则按照文章日期降序排, 否则按照top值降序排 &#125; else if (first.top &amp;&amp; !second.top) &#123; // 以下是只有一篇文章top有定义，将有top的排在前面 return -1; &#125; else if (!first.top &amp;&amp; second.top) &#123; return 1; &#125; else &#123; return second.date - first.date; // 都没定义top，按照文章日期降序排 &#125;&#125;); 更改后的完整代码如下： 123456789101112131415161718192021222324252627'use strict';var pagination = require('hexo-pagination');module.exports = function(locals) &#123; var config = this.config; var posts = locals.posts.sort(config.index_generator.order_by); posts.data = posts.data.sort(function(first, second) &#123; if (first.top &amp;&amp; second.top) &#123; // 两篇文章top都有定义 return first.top == second.top ? second.date - first.date : second.top - first.top //若top值一样则按照文章日期降序排, 否则按照top值降序排 &#125; else if (first.top &amp;&amp; !second.top) &#123; // 以下是只有一篇文章top有定义，将有top的排在前面 return -1; &#125; else if (!first.top &amp;&amp; second.top) &#123; return 1; &#125; else &#123; return second.date - first.date; // 都没定义top，按照文章日期降序排 &#125; &#125;); var paginationDir = config.pagination_dir || 'page'; var path = config.index_generator.path || ''; return pagination(path, posts, &#123; perPage: config.index_generator.per_page, layout: ['index', 'archive'], format: paginationDir + '/%d/', data: &#123; __index: true &#125; &#125;);&#125;; 然后在需要置顶的文章的front-matter中添加top字段。top值越大，则文章越靠前。top值一样的文章则根据日期排序。front-matter设置的一个例子如下： 1234567891011title: Hexo文章置顶方法研究date: 2019-06-26 22:51:15tags: - 教程 - hexoauthor: MinHowtags: - 博客 - 开源项目cover_picture: https://cloud.minhow.com/images/miho/theme/github-second.jpgtop: 1 解决“置底”的问题 无法置底的原因很简单，即在上面的js代码修改中，没有设置top值的文章的top变量是未定义的，且规定未定义top的文章总是比定义了top值的文章要靠后。我们赋予未定义top值的文章一个默认的0值，即可解决这个问题的。具体的操作是将修改代码内容替换成 123456789posts.data = posts.data.sort(function(first, second) &#123; var a = first.top || 0 var b = second.top || 0 if (a != b) &#123; return b - a &#125; else &#123; return second.date - first.date &#125;&#125;]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Weekly - 1]]></title>
    <url>%2Fposts%2F25582%2F</url>
    <content type="text"><![CDATA[So what's this 每周我都会读阮一峰的每周分享，有时候也会在其他的博客平台上看见别的博主整理的这些每周资源分享文章，觉得比较有用，我也打算整理一下自己的List。 最近一年多以来，我尝试尽可能将自己的思考过程以文字的方式记录下来，这样过几天回头来看，便于我整理思路。更重要的是，这种累积会给自己带来沉甸甸的“积累感”，给自己一个强大正反馈。 这篇是这一系类的每周分享的第一篇，贵在坚持！ 新闻 树莓派4发布 树莓派4 树莓派性能对比 位于英国的教育慈善组织「Raspberry Pi 基金会」推出了它们的新一代产品：树莓派 4（Raspberry Pi 4），性能表现又上升了一个台阶，官方甚至称它「足以媲美一台入门级 x86 电脑」。树莓派的主要性能升级为： 搭载了A72架构的BCM2711芯片，主频为1.5GHz 两个micro-HDMI 支持最高4GB LPDDR4内存 802.11ac 双频Wifi 千兆以太网 蓝牙5.0 5V/3A 的USB-C供电 USB2.0及USB3.0接口 官方还承诺，会持续生产树莓派 4 至 2026 年 1 月. B站三体动画化 B站正式宣布《三体》动画化启动: 作为重磅彩蛋，刘慈欣现身B站十周年活动现场。动画由B站出品、三体宇宙和制作方艺画开天联合出品。活动现场首播的概念版PV淋漓尽致地展现三体宇宙的宏大和黑暗森林法则的残酷。 之前在B站上自己组团队做了三体动画（Minecraft版）的神游八方，也加入了动画化的主创团队。 专题页面 《游戏适龄提示倡议》 6月26日，人民网联合腾讯、网易、完美世界等10家头部游戏公司发起《游戏适龄提示倡议》，把游戏玩家分成4个年龄层级，并提出了相应的提示体系，包括游戏内容、类型和运营等方面的标准。年龄分层方面，此次倡议把游戏玩家分为18+、16+、12+、6+四级。例如6+多是休闲益智类，18+则有大量竞技、策略、棋牌类游戏。 分级标准 之前听老梁说的好，文化审查领域重要的是“自由裁量权”，而并不是挂在口头上的细枝末节的审查细节。没有分级制度，那么我想让你过你就能过，不让你过，你就不能过，随心所欲，岂不快哉？ &quot;在国民党统治时期，制定了一个新闻法，我们共产党人仔细研究它的字句，抓它的辫子，钻它的空子。现在我们当权，我看还是不要新闻法好，免得人家钻我们空子。没有法，我们主动，想怎样控制就怎样控制。&quot; -- 陈云 （孙旭培教授曾在《新闻立法之路》一文中引述） Further Reading：为什么中国没有新闻法(Backup Link) 联邦快递起诉美国政府 6月24日，联邦快递在官网发布声明称，已向哥伦比亚地区的美国地区法院提起诉讼，要求禁止美国商务部对联邦快递执行“出口管理条例”中的禁令。联邦快递认为，《出口管制条例》违反公共承运人在美国宪法第五修正案下的正当权利，因为他们不合理地要求承运人为可能违反《出口管制条例》的运品承担严格责任。 魔幻现实主义 苹果首席设计官Jonathan Ive将离职 苹果首席设计官 Jonathan Ive 将于今年后期正式离开苹果，创立独立的设计公司 LoveFrom，其好友兼著名设计师 Marc Newson 将加入。届时，苹果将成为该设计公司其中一位主要客户。 Ive 在苹果的代表作包括 iMac、iPod、iPhone 等系列产品，参与设计了苹果的「飞船」总部 Apple Park。他在新闻稿中说：「在将近 30 年和无数项目后，让我最自豪的项目是我们持续投入精力创造了同行无法比拟的苹果设计团队，流程和文化。」 上面视频里的iOS 7即是Jonathan主导的，其革命性的变化在于用扁平化的设计取代拟物化的设计 全电动飞机 Alice 在 6 月 17 日到 23 日举行的巴黎航空展上，以色列航空公司 Eviation 推出了自家首款全电动飞机 Alice。 这款用「爱丽丝」这个充满诗意的名字来命名的飞机，是全球首款全电动通勤飞机。 Eviation Alice 内部搭载了功率能达到 功率能够达到 900kW 的三台电机，以及一块可提供 900 千瓦时能量的锂电池。飞机充满一次电可以发行 1037 公里，巡航速度为每小时 407 公里。运载能力方面，Alice 飞机上有 9 个独立座位，同样也需要两名驾驶员才能驾驶。谈到 Alice 的机舱设计时，Eviation 官方表示飞机机舱做了一定的设计优化，自身能为乘客带来更好的降噪。售价方面，Alice 的定价为 400 万美元，折合约 2750 万人民币，每小时的飞行成本为 200 美元，折合约 1372 元。 巴黎航展 · Alice 华为 P30 发货量破千万 6月27日，华为消费者业务手机产品线总裁何刚在MCW2019大会上公布了一系列数据，其中华为P30系列手机仅上市85天全球发货量就达到1000万台，比P20系列提前了62天。截止今年5月31日，华为手机整体出货量实现149天破亿。 华为 P30 发货量破千万 果粉表示真香，想买。以及，辣鸡KOL 典故与梗 不作安安饿殍，效尤奋臂螳螂 这句话，我一直理解反了意思。开始我以为是指不愿意做饿死鬼，即便是螳臂当车也要起来反抗的意思。结果，其原意是完全相反的。 这句话出自顾诚的《明末农民战争史》的注释中: 【22】谈迁：《北游录》，《纪闻上》，《榜购一词》条。按：此条首云“总督杨文岳嗣昌出师，榜辑剧寇张献忠”，杨嗣昌字文弱，谈迁误为文岳，又称之为总督，遂与明保定总督杨文岳混为一人。杨复吉《梦阑琐笔》载此事时更写成“保督杨文岳出师榜缉张献忠”，均误。又杨氏所载词中“兴安、平利走四方”一句作“兴安、平利走东乡”。李馥荣：《滟滪囊》卷一所载杨嗣昌榜刊《西江月》词句为：“不作安安饿殍，效尤奋臂螳螂。往来楚蜀肆猖狂，弄兵潢池无状。云屯雨骤师集，蛇豕奔突奚藏？许尔军民绑来降，爵赏酬功上上。”或系杨嗣昌所刊另一榜文。 这句话的意思是，尔等不安安静静地做一个饿死鬼，却效仿螳臂当车，自不量力（抵抗朝廷的剿灭大军）。当然，这句话可能并非杨总督本人所说，只是文人调侃他所做。不过，这句话透出的想法，杨总督脑子里大抵是有的，只不过要脸，不好说出来。对于这些统治者来捉，有这样的想法，其实不足为奇。但是，偏偏就有一些明明遇到乱世就会沦为“饿殍”的人，摆不正自己的位置。 历代造反的贫民，从陈胜吴广，到李自成，洪秀全，诚然造成了巨大的破坏，但若是不造反，又有什么活路呢？难道，做安安饿殍么？ 情绪 Youtube博主Etika自杀 Etika 2019年6月19日，Etika上传了一段疑似自杀宣言的视频，他背起书包，离开了家门。至此以后，没有人再看到Etika的任何踪迹。 6月22日，警方发现了Etika被遗弃的个人物品，在高达340英尺的大桥之上。 6月25日，纽约警方在布鲁克林大桥水域发现一具未明身份的男性遗体。今日，警方发布正式公告，遗体确为Etika本人，死因是自杀。 网友在Etika自杀地的悼念 有很多极度抑郁的人以至于要自杀的人，有时候看起来会很开心的样子。永远不要以为自己有多么了解一个人，尤其是一个你没有那么熟悉，甚至是陌生的人。 文章与言论 Oh shit, git!：作者针对一些在使用git过程中的痛点给出了解决方法 How To: Automatically Backup a Linux VPS to a Separate Cloud Storage Service：如何将VPS备份到一个云存储平台 安卓碎片化严重到什么地步？安卓本身有12个版本，如果每个版本有12个厂商，每个厂商有12个手机型号，因此安卓生态至少包含1,728种&quot;版本- 品牌 - 设备&quot;的组合。 ProSe (Proximity Services) for LTE &amp; 5G Networks: 2017-2030 - Opportunities, Challenges, Strategies &amp; Forecasts: 5G是近年来的热词了，也是这次美国对华为发难的一个重要因素。不过舆论对于5G的认识，一般是一个加强版的4G蜂窝网。其实5G中引入的Promxity Service技术，将为传统蜂窝网引入D2D的能力，这可能带来深远的影响。]]></content>
      <categories>
        <category>weekly</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
        <tag>科技新闻</tag>
        <tag>转载</tag>
        <tag>树莓派</tag>
        <tag>weekly</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python下的音频处理库librosa打开文件是显示NoBackendError的解决]]></title>
    <url>%2Fposts%2F40199%2F</url>
    <content type="text"><![CDATA[近日在django项目中采用了librosa来分析用户上传的音频，主要是对其做一定间隔的采样用于绘制波形图。在本地(MacOS)上工作正常，部署到Ubuntu服务器后，自己手动用python方式运行django的server时，工作都是正常的，然而当我用superviosr挂起之后就一直报NoBackendError的错误，反复检查了FFmpeg的安装，应该是没有问题的。网上搜了一下没有看到比较合适的解决办法，故不得不自己读源码来调试了。 由于我的程序中只采用了librosa.load这个命令，通过源代码可以发现librosa实际上是用audioread这个库的audioread.audio_open来读取音频文件的。这个函数的源代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344def audio_open(path): """Open an audio file using a library that is available on this system. """ # Standard-library WAV and AIFF readers. from . import rawread try: return rawread.RawAudioFile(path) except DecodeError: pass # Core Audio. if _ca_available(): from . import macca try: return macca.ExtAudioFile(path) except DecodeError: pass # GStreamer. if _gst_available(): from . import gstdec try: return gstdec.GstAudioFile(path) except DecodeError: pass # MAD. if _mad_available(): from . import maddec try: return maddec.MadAudioFile(path) except DecodeError: pass # FFmpeg. from . import ffdec try: return ffdec.FFmpegAudioFile(path) except DecodeError: pass # All backends failed! raise NoBackendError() 可见之前我们遇到的NoBackendError就是这里的最后一行抛出的了，由于我安装的FFmpeg，进一步进入ffdec.py这个文件中。不难发现实际打开文件的是下面这个函数： 1234567891011121314151617def popen_multiple(commands, command_args, *args, **kwargs): """Like `subprocess.Popen`, but can try multiple commands in case some are not available. `commands` is an iterable of command names and `command_args` are the rest of the arguments that, when appended to the command name, make up the full first argument to `subprocess.Popen`. The other positional and keyword arguments are passed through. """ for i, command in enumerate(commands): cmd = [command] + command_args try: return subprocess.Popen(cmd, *args, **kwargs) except OSError: if i == len(commands) - 1: # No more commands to try. raise 这里的commands是直接传入的第33行的COMMANDS变量 1COMMANDS = ('ffmpeg', 'avconv') 我这里倒腾了好几下，最终发现实际是错误的原因是没有找到ffmpeg这个命令。我们在这里将ffmpeg替换成ffmpeg的绝对路径。你可以通过下面这行命令找到。 1which ffmpeg 最终我改成了 1COMMANDS = ('/usr/bin/ffmpeg', 'avconv') Boom！一切就工作正常了。这么想起来应该是安装ffmpeg的时候的环境变量有问题，导致在command line方式下调用ffmpeg命令出错吧。]]></content>
      <categories>
        <category>Debug</category>
      </categories>
      <tags>
        <tag>Debug</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Latex中各种各样的箭头]]></title>
    <url>%2Fposts%2F13297%2F</url>
    <content type="text"><![CDATA[Latex中提供了各种“稀奇古怪的箭头形状”。一般箭头使用在公式环境下面。 默认箭头 这里的默认指你不需要任何额外的usepackage就可以使用： 默认箭头 amssymb提供的箭头 需要\usepackage{amssymb} amssymb箭头 Further Reading LaTeX arrows]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>latex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署Pritunl来使用OpenVPN]]></title>
    <url>%2Fposts%2F23676%2F</url>
    <content type="text"><![CDATA[Why VPN 为什么要使用VPN？尤其是，为什么个人用户需要使用VPN呢？其实如果你只有一台电脑，其实一般用不上VPN（当然，用VPN来翻墙另说），如果你有多个电脑，甚至是服务器，这些服务器的网络情况还比较复杂，而你希望随时随地方便地访问这些机器，那么建立VPN虚拟网络将这些机器连接起来就能极大的方便访问过程。例如，如果一台服务器是在路由器后面，没有公网IP，与其在路由器上配置复杂的端口映射表，不如通过VPN网络自由地访问各个端口。又例如在一些特定的场景下，一些服务器的低位（1024以下）端口的访问会收到限制，这个也可以同VPN来解决。 当然，还有可能，你处于校园网中，而你通过种种途径有了一个无限流量服务器，通过VPN，可以让你在校园网场景下能够随时通过这台服务器上网，从而免去流量费用。另外，将这一宝贵资源分享给同学使用，用VPN也非常方便。 Why Pritunl 我试过很多VPN方案，例如PPTP，OpenVPN，IPSec等等。其实使用VPN过程中的一个痛点在于用户管理要尽可能方便，虽然我也比较多的在用命令行工具，但是使用命令行工具去管理用户体验还是非常差。Pritunl提供了OpenVPN的网页GUI管理界面。这也是我为什么推荐使用Priunl的原因。而且，Pritunl中免费用户就可以使用无数量限制的账户和设备，这对于个人用户来说足够了。 另一方面，Pritunl的客户端支持也非常全面 How to deploy Installation 官方文档在这里: Installation。事实上按照官方文档的推荐，Pritunl最好部署在企业级的Linux OS上，如Red Hat, Oracle Linux, CentOS等。不过对于个人用户，对于性能，稳定性和安全性要求没有那么严格的情况下，用Debian系的系统也未尝不可。我的Pritunl服务器就是部署在Ubuntu上的，几个月使用下来，性能和稳定性都非常好。 对于不同版本的系统，安装脚本不同。例如，Ubuntu 16.04，安装脚本如下： 1234567891011121314sudo tee /etc/apt/sources.list.d/mongodb-org-4.0.list &lt;&lt; EOFdeb https://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/4.0 multiverseEOFsudo tee /etc/apt/sources.list.d/pritunl.list &lt;&lt; EOFdeb http://repo.pritunl.com/stable/apt xenial mainEOFsudo apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv 9DA31620334BD75D9DCB49F368818C72E52529D4sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com --recv 7568D9BB55FF9E5287D586017AE645C0CF8E292Asudo apt-get updatesudo apt-get --assume-yes install pritunl mongodb-orgsudo systemctl start pritunl mongodsudo systemctl enable pritunl mongod Configuration 在安装完Pritunl之后，访问服务器的443端口，即可以看到配置引导界面。 配置界面 其中需要输入的主要是第一项Setup Key。数据库部分，如果你是使用上面的脚本安装的话，那么Pritunl服务本机上就已经安装运行了MongoDB，这里第二个配置MongoDB URI就不需要变动。要获取Setup Key，ssh进入部署服务器，运行pritunl setup-key即可. 完成这一步设置以后就来到管理员登录界面： 管理员登录界面 初始时用户名和密码都是pritunl，在完成第一次登录之后会被要求修改管理员的用户名和密码： 修改密码 Further Reading Pritunl的使用方法非常直观，文档可以参见Connecting.]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下OpenVPN客户端配置]]></title>
    <url>%2Fposts%2F38823%2F</url>
    <content type="text"><![CDATA[环境配置 安装OpenVPN的方法很简单： 12sudo apt-get updatesudo apt-get install openvpn 使用方法 首先你需要从OpenVPN服务提供商那里得到*.ovpn配置文件，然后在服务器上运行 1sudo openvpn --config your.ovpn 不过这个命令会在前台运行，当我们退出SSH之后就会终止。为了让OpenVPN能够在后台运行，且能够自动开机启动，我们需要借助于Systemctl的帮助。首先我们将ovpn文件复制到/etc/openvpn/client/下，将后缀直接修改为.conf。如果配置文件需要我们手动输入密码，我们需要将密码以配置文件的形式固定下来，不然自动启动会失败。在/etc/openvpn/client/新建一个account.txt文件，在其中输入： 12usernamepassword 有些OpenVPN服务端工具只会生成密码（例如Pritunl），在这里username可以随意输入一个，然后在下面一行添加密码。 然后进入配置文件，找到auth-user-pass。默认情况下这个配置条目后面是空的，我们将其修改为： 1auth-user-pass /etc/openvpn/client/account.txt 假设前面我们复制过来的配置文件的名字为default.conf。输入下面的命令以启用这个vpn： 1sudo systemctl enable openvpn-client@default 要启动这个vpn，使用下面的命令： 1systemctl start openvpn-client@default]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>linux</tag>
        <tag>vpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Matplotlib in Virtualenv]]></title>
    <url>%2Fposts%2F30912%2F</url>
    <content type="text"><![CDATA[我使用的是macOS系统。当在虚拟环境中尝试使用matplotlib时，会出现如下的报错： 1ImportError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are using (Ana)Conda please install python.app and replace the use of &apos;python&apos; with &apos;pythonw&apos;. See &apos;Working with Matplotlib on OSX&apos; in the Matplotlib FAQ for more informatio 根据错误信息，要么我们使用Python as Framework，要么我们更换使用的后端（backend）。Matplot专门就matplotlib的后端问题有一个网页：Working with Matplotlib in Virtual environments。文章中提到，Tk这个框架（即TkAgg后端）一般来说总是可用的，不需要额外的外部依赖。（不过在特定的Linux发行版本中可能需要安装python-tk）。要使用Tk需要做如下配置过程： 123import matplotlibmatplotlib.use("TkAgg")import matplotlib.pylab as plt 每次这么配置比较麻烦，我们可以通过~/.matplotlib/matplitlibrc文件来固化配置（如果这个文件不存在可以手动创建），文件中添加如下内容： 1backend: TkAgg 不过我在使用过程中发现使用TkAgg时会出现系统级的错误，抛出了Terminating app due to uncaught exception的错误。因此我尝试替换成其他后端。我主要选择包括： Matplotlib可用后端类型 而又因为PySide只支持比较早的python版本，因此我选择了Qt5作为后端。在这之前，我们需要安装下面的依赖 12brew install qtpip install PySide2 安装完成后配置过程和TkAgg的类似，后端的名字为QT5Agg。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Debug</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ns3 在模块中使用第三方库]]></title>
    <url>%2Fposts%2F53831%2F</url>
    <content type="text"><![CDATA[ns3使用了waf编译系统，因此在ns3中尝试引入第三方模块时，就没有make那么直接了。 其实思路的核心还是想办法最终为编译器提供-L和-I的设置。这个过程我们通过wscript中的configure函数来实现。这里我们假设模块使用的库的位置放在模块源码目录下的libs子目录。库的名字为example-lib。目录结构如下: 1234libs└── example-lib ├── include └── libexample-lib.a 其中，include文件夹内为头文件，libexample-lib.a为静态库文件。 修改wscript文件中的configure函数，如下 12345678def configure(conf): root_dir = conf.path.abspath() example_lib_dir = os.path.join(root_dir, "libs/example-lib") conf.env.append_value("LINKFLAGS", ["-L%s/" % example_lib_dir]) conf.env.append_value("LIB", ["example-lib"]) conf.env.append_value("CPPFLAGS", ["-I%s/include" % example_lib_dir, ]) 修改configure函数之后要重新运行./waf configure命令来让设置生效。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>ns3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ns3 wscript: 自动寻找需编译的源文件]]></title>
    <url>%2Fposts%2F3426%2F</url>
    <content type="text"><![CDATA[在ns3的编译体系中，每个module会包含一个名为wscript的python脚本来提供编译信息。例如，一个通过create-module.py创建的module中的wscript为 12345678910111213141516171819202122232425262728293031# -*- Mode: python; py-indent-offset: 4; indent-tabs-mode: nil; coding: utf-8; -*-# def options(opt):# pass# def configure(conf):# conf.check_nonfatal(header_name='stdint.h', define_name='HAVE_STDINT_H')def build(bld): module = bld.create_ns3_module('example-module', ['core']) module.source = [ 'model/example-module.cc', 'helper/example-module-helper.cc', ] module_test = bld.create_ns3_module_test_library('example-module') module_test.source = [ 'test/example-module-test-suite.cc', ] headers = bld(features='ns3header') headers.module = 'example-module' headers.source = [ 'model/example-module.h', 'helper/example-module-helper.h', ] if bld.env.ENABLE_EXAMPLES: bld.recurse('examples') # bld.ns3_python_bindings() 其中，module.source中包含需要编译的.cc源文件，而headers.source中包含对应的头文件。每次新建C++源代码文件时，都需要手动添加到这里的列表中。下面我给出一个自动从module的model, helper目录下搜索源文件的方法： 123456789101112131415161718192021222324252627282930313233343536373839404142# -*- Mode: python; py-indent-offset: 4; indent-tabs-mode: nil; coding: utf-8; -*-import os# def options(opt):# pass# def configure(conf):# conf.check_nonfatal(header_name='stdint.h', define_name='HAVE_STDINT_H')def _list_sources(bld, suffix): root_dir = bld.path.abspath() res = [ x for x in [os.path.join("model", y) for y in os.listdir(os.path.join(root_dir, "model"))] if x.endswith(suffix) ] res += [ x for x in [os.path.join("helper", y) for y in os.listdir(os.path.join(root_dir, "helper"))] if x.endswith(suffix) ] return resdef build(bld): module = bld.create_ns3_module('example-module', ["core"]) module.source = _list_sources(bld, ".cc") module_test = bld.create_ns3_module_test_library('example-module') module_test.source = [ 'test/mix-autonomy-test-suite.cc', ] headers = bld(features='ns3header') headers.module = 'example-module' headers.source = _list_sources(bld, ".h") if bld.env.ENABLE_EXAMPLES: bld.recurse('examples') # bld.ns3_python_bindings() 注意不要直接套用上面的范例文件，需要将&quot;example-module&quot;的名字改为你的module的名字]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>ns3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[贝塞尔曲线原理]]></title>
    <url>%2Fposts%2F50553%2F</url>
    <content type="text"><![CDATA[这是一篇转载文章。Bézier curve(贝塞尔曲线)是应用于二维图形应用程序的数学曲线。 曲线定义：起始点、终止点（也称锚点）、控制点。通过调整控制点，贝塞尔曲线的形状会发生变化。 1962年，法国数学家Pierre Bézier第一个研究了这种矢量绘制曲线的方法，并给出了详细的计算公式，因此按照这样的公式绘制出来的曲线就用他的姓氏来命名，称为贝塞尔曲线。 抛物线三切线定理 设\(P_0\)，\(P_0^2\)，\(P_2\)是一跳抛物线上顺序不同的三个点。过\(P_0\)和\(P2\)的切线交于\(P_1\)。过\(P_0^2\)的切线交\(P_0 P_1\)和\(P_2 P_1\)相交于\(P_0^1\)和\(P_1^1\)，则有如下比例成立： \[\begin{equation} \frac{P_{0} P_{0}^{1}}{P_{0}^{1} P_{1}}=\frac{P_{1} P_{1}^{1}}{P_{1}^{1} P_{2}}=\frac{P_{0}^{1} P_{0}^{2}}{P_{0}^{2} P_{1}^{1}} \end{equation}\] 抛物线三切线定理示意图 此即为抛物线的三切线定理。 二次贝塞尔曲线 当\(P_0\)，\(P_2\)固定时，引入参数\(t\)，令上述比例值为\(t:(1-t)\)，即有： \[\begin{equation} \begin{array}{l}{P_{0}^{1}=(1-t) P_{0}+t P_{1}} \\ {P_{1}^{1}=(1-t) P_{1}+t P_{2}} \\ {P_{0}^{2}=(1-t) P_{0}^{1}+t P_{1}^{1}}\end{array} \end{equation}\] 将第一，二个式子代入第三个有： \[\begin{equation} P_{0}^{2}=(1-t)^{2} P_{0}+2 t(1-t) P_{1}+t^{2} P_{2} \end{equation}\] 当\(t\)从0变到1时，\(P_0^2\)点经过的轨迹即为上图中的抛物线，也即为由三顶点\(P_0\), \(P_1\), \(P_2\)决定的一条二次贝塞尔曲线。也可以认为这条二次贝塞尔曲线是由两个前顶点\((P_0, P_1)\)以及两个后顶点\((P_1, P_2)\)决定的。 更高阶的贝塞尔曲线 类似于二次贝塞尔曲线的推导过程，我们可以推广到更高阶的贝塞尔曲线。 由四个控制点定义的三次Bezier曲线\(P_0^3\)可被定义为分别由\((P_0,P_1,P_2)\)和\((P_1,P_2,P_3)\)确定的二条二次Bezier曲线的线性组合，由\((n+1)\)个控制点\(P_i(i=0,1,...,n)\)定义的n次Bezier曲线\(P_0^n\)可被定义为分别由前、后\(n\)个控制点定义的两条\((n-1)\)次Bezier曲线\(P_0^{n-1}\)与\(P+0^{n-1}\)的线性组合： \[\begin{equation} P_{0}^{n}=(1-t) P_{0}^{n-1}+t P_{1}^{n-1} \quad t \in[0,1] \end{equation}\] 由此可以得到Bezier曲线的踢腿计算公式 \[\begin{equation} P_{i}^{k}=\left\{\begin{array}{c}{P_{i}} &amp; {k=0} \\ {(1-t) P_{i}^{k-1}+t P_{i+1}^{k-1}} &amp; {k=1,2, \cdots, n, i=0,1, \cdots, n-k}\end{array}\right. \end{equation}\] 这就是de Castelijau算法。 贝塞尔曲线原理动图 一阶贝塞尔曲线 二阶贝塞尔曲线 三阶贝塞尔曲线 四阶贝塞尔曲线 五阶贝塞尔曲线]]></content>
      <categories>
        <category>数学</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>processing</tag>
        <tag>数学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker Volume的权限问题]]></title>
    <url>%2Fposts%2F25188%2F</url>
    <content type="text"><![CDATA[这里我们要解决的是使用Docker过程中常见的Volume权限问题。具体而言，当我们用-v将宿主机的路径绑定到Docker镜像的内部路径时，有时候会导致Docker镜像缺少对这个目录的访问权限，从而导致进程出错。 Why 当我们绑定宿主目录到镜像时，如果该目录不存在，Docker也会自动创建该目录。这种方式创建出来的目录的拥有者是root用户。如果该目录已经存在，那么其拥有者就取决于宿主配置的情况了。 由于Docker内部的用户空间和宿主的用户空间是独立的，如果镜像内运行进程的用户和宿主目录的拥有者不符合，就会出现权限问题。 How to solve it 由于镜像内和宿主的用户名空间是不同的，所以通过用户名的方式来变更宿主目录的所有权会失效。然而，事实上用户系统是通过uid来标识不同的用户的，我们只需要将宿主的路径的拥护者改为镜像内用户相通的uid即可。镜像内用户的uid可以通过如下方式查看，例如： 12jovyan@8fed6b266a3c:~$ iduid=1000(jovyan) gid=100(users) groups=100(users) 继而再修改宿主机上对应目录的拥有者： 1sudo chown -R 1000 /path/to/volume Further Research 上面的方法可以解决Volume访问权限的问题，不过会产生潜在的漏洞。从镜像内获得的uid在宿主上可能表示的是不同的用户，在宿主机上修改目录的拥有者会导致数据被同一服务器上的其他用户访问，带来安全性上的问题。 另一方面，如果有多个镜像需要共享一个Volume，而他们内部的运行用户的uid不同的话，就需要在宿主上进行更加复杂的用户以及组的配置。 更优雅的执行方法有下面两种： Use Named Volume Named Volumes 由容器自行配置权限问题 Reference 谈谈 Docker Volume 之权限管理（一） What is the (best) way to manage permissions for Docker shared volumes? Why Docker Data Containers (Volumes!) are Good Use volumes Different Types of Volumes]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Debug</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[读书破万卷,下笔如有神]]></title>
    <url>%2Fposts%2F60435%2F</url>
    <content type="text"><![CDATA[能够获得暴利的职业，都有一个共同特点：可扩展性（scaling），一次劳动可以服务成千上万的人。 软件、电影、游戏行业都具有可扩展性，作品的生产成本是固定的，但可以被消费无数次，所以有巨大的获利空间，创造出许许多多的富豪。另一方面，理发师、厨师、出租车司机一次劳动，只能服务少数几个人，就不具有可扩展性，很难获得暴利，生存得很辛苦。 最近，我读到美国一个风险投资家的文章。他说了一句发人深思的话： &quot;写作是最具可扩展性的活动。你呆在家里，不去参加活动/会议，只是在网上写下自己的想法，然后你就具有了最好的可扩展性。&quot; 我想了一下，还真是这样。你写了一篇文章，想让其他人看到，只要到处张贴就行了。每次转贴，就是扩展了一次。这比其他产品的扩展容易多了。面包师傅想要更多的人尝到自己的面包，只能多开面包店；网站要扩展，只能购买更多的服务器。相比之下，文字的扩展简直是零成本。 大公司每年花费数十亿美元用于广告，以求人们关注他们的产品。但是，一个好的作家可以免费获得这种扩展性。这就是为什么你应该把自己的想法写下来的原因，这么好的免费传播渠道，为什么不用呢？你以为，写下来不会有人看。错，其实是有人会看到的，如果他们觉得有价值，就会帮你传播出去。 这篇文章转载自阮一峰的博客。这篇文章其实说了一个非常简洁明了却价值巨大的道理，也给我们启示：我们应该如何规划自己的职业道路。只是靠出售自己的时间，即便是清北的同学，也只是能做到一个尚算富裕，但是辛苦中产阶级。要更上一层楼，还是需要手握资本。而怎么获得资本呢？其实就是靠文章里说的“可扩展性的工作”。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandoc渲染引擎导致Hexo Tag渲染失败的临时解决办法]]></title>
    <url>%2Fposts%2F62502%2F</url>
    <content type="text"><![CDATA[在Hexo+Next: 使用Latex公式这篇文章中我发现在使用Pandoc作为Hexo的渲染引擎时，Hexo的标签功能会有问题，具体表现为Hexo的标签内部的内容会输出markdown源码，而非渲染后的html。 问题研究 经过我的研究，这是因为hexo-render-pandoc在注册自己的renderer时，只注册了异步渲染的renderer，而没有注册同步渲染的renderer，而Hexo的标签中主要是用同步renderer。以当时我使用的NexT的note标签为例。其实现代码为： 12345678910'use strict';function postNote(args, content) &#123; return `&lt;div class="note $&#123;args.join(' ')&#125;"&gt; $&#123;hexo.render.renderSync(&#123;text: content, engine: 'markdown'&#125;).split('\n').join('')&#125; &lt;/div&gt;`;&#125;hexo.extend.tag.register('note', postNote, &#123;ends: true, async: true&#125;);hexo.extend.tag.register('subnote', postNote, &#123;ends: true, async: true&#125;); 由于没有注册同步渲染器，这里的hexo.render.renderSync渲染会失败，从而返回的是content中的原本内容，也即Markdown形式的源码。 解决办法 彻底的解决办法，自然是在hexo-render-pandoc中同时注册同步渲染器。不过我自己尝试之后发现作为同步渲染器，pandoc和Hexo使用模板引擎貌似有冲突。更细致深入的修改最好还是由原作者来进行（我已经提交了Issue）。 这里我给出一个临时的解决办法：既然hexo-render-pandoc只注册了异步渲染代码，那么我们在Tag的实现代码中调用异步渲染的接口就可以了。仍然以NexT主题的note标签为例，可以将代码修改成： 12345678910111213141516'use strict';function postNote(args, content) &#123; return hexo.render.render(&#123;text: content, engine: 'markdown'&#125;) .then(function (res) &#123; return `&lt;div class="note $&#123;args.join(' ')&#125;"&gt; $&#123;res.split('\n').join('')&#125; &lt;/div&gt;` &#125;) // return `&lt;div class="note $&#123;args.join(' ')&#125;"&gt; // $&#123;hexo.render.renderSync(&#123;text: content, engine: 'markdown'&#125;).split('\n').join('')&#125; // &lt;/div&gt;`;&#125;hexo.extend.tag.register('note', postNote, &#123;ends: true, async: true&#125;);hexo.extend.tag.register('subnote', postNote, &#123;ends: true, async: true&#125;); 经过这样修改就可以了。不过这种方法仍然只是权宜之计，要是去修改每个Tag的实现，就太繁琐了。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+Next: 使用Latex公式]]></title>
    <url>%2Fposts%2F20215%2F</url>
    <content type="text"><![CDATA[这次更换主题的很大一个动因就是因为在NexT这个主题上，开启Latex的支持很方便。网上关于这方面的文章其实不少，但是大部分都不全面，照本宣科下来，很可能不能用。这些教程一般就给了_config.yml文件的配置以及pandoc依赖安装，但是一些关键细节缺失了。这篇文章里我梳理了一下整个流程。 0. Reference 英语好的话，其实可以尝试直接阅读官方文档。 1. Install Dependencies Next支持mathjax和katex两种渲染方式，其中katex的速度更快，但是对于Latex的支持有一定的限制。所以除非你的博客数量实在是过于庞大，不然就可以直接使用mathjax。 mathjax可以选用下面两种渲染引擎的中的任一一种 hexo-renderer-kramed hexo-render-pandoc 使用hexo-render-pandoc还需要安装pandoc渲染引擎。其安装方法可以参考 pandoc官网。如果在macOS上可以使用 Homebrew安装. 这里以pandoc为例： 123# 需要先卸载默认的渲染引擎npm un hexo-renderer-marked --savenpm i hexo-renderer-pandoc --save 替换渲染器之后会导致NexT note功能出现问题，note内的元素内容无法渲染，会输出markdown源代码。 这个问题我在hexo-render-pandoc上提了一个Issue，看原作者什么时候能够更新解决吧。 2. Configuration 配置NexT主题的_config.yml文件 12345math: enable: true ... engine: mathjax #engine: katex 很多文章都漏掉了在配置中一个重要的信息：在主题配置math下有一个名为per_page的选项，其值为true或者false。这个选项用来控制是否对每个篇文章都渲染数学公式。默认情况下是true，这意味只对Front Matter中含有mathjax: true的文章进行公式渲染。将per_page设置为false，则会对每一篇文章都尝试进行公式渲染。 由于公式渲染时一个很费时的操作，因此还是保持默认配置，通过Front Matter进行渲染控制. 3. How to use 3.1 行内嵌套公式 如：质能方程\(e=mc^2\) 1如：质能方程$e=mc^2$ 3.2 独占一行的公式 如： \[ 1=\sum_{i=0}^{m}\sum_{k=0}^{W_i-1}b_{i,k}=\sum_{i=0}^{m}b_{i,0}\sum_{k=0}^{W_i-1}\frac{W_i-k}{W_i}=\sum_{i=0}^{m}b_{i,0}\frac{W_i+1}{2}\\ =\frac{b_{0,0}}{2}\left[W\left(\sum_{i=0}^{m-1}(2p)^i+\frac{(2p)^m}{1-p}\right) + \frac{1}{1-p}\right] \] 12345如：$$1=\sum_&#123;i=0&#125;^&#123;m&#125;\sum_&#123;k=0&#125;^&#123;W_i-1&#125;b_&#123;i,k&#125;=\sum_&#123;i=0&#125;^&#123;m&#125;b_&#123;i,0&#125;\sum_&#123;k=0&#125;^&#123;W_i-1&#125;\frac&#123;W_i-k&#125;&#123;W_i&#125;=\sum_&#123;i=0&#125;^&#123;m&#125;b_&#123;i,0&#125;\frac&#123;W_i+1&#125;&#123;2&#125;\\=\frac&#123;b_&#123;0,0&#125;&#125;&#123;2&#125;\left[W\left(\sum_&#123;i=0&#125;^&#123;m-1&#125;(2p)^i+\frac&#123;(2p)^m&#125;&#123;1-p&#125;\right) + \frac&#123;1&#125;&#123;1-p&#125;\right]$$ 更多latex的使用方法，请参考官方文档]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清华GPA事件备份:2019.04.16]]></title>
    <url>%2Fposts%2F34235%2F</url>
    <content type="text"><![CDATA[大图预警]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haproxy支持Ipv6]]></title>
    <url>%2Fposts%2F12489%2F</url>
    <content type="text"><![CDATA[Haproxy Haproxy is a reliable, high performance TCP/HTTP Load Balancer 这是官网对于Haproxy的介绍，其作用的类似于Nginx，是一个均衡负载的服务器。其相比于Nginx的好处是其代理TCP流量的功能配置起来非常的简单。我这里主要拿Haproxy来配置Shadowsocks的跳板机。 前一段时间，GFW的墙好像又加高了，很多时候在教育网外连接服务器不是很可靠。所以我考虑干脆在教育网环境下做一个跳板服务器，这样在外面可以先跳到教育网，然后再从教育网过墙。 教育网的另一个好处是有IPv6。貌似IPv6上面的拦截比较弱，而且，绝大多数的高校对于IPv6都是免流量费的。因此，我们可以从IPv4公口进，然后走IPv6出。 How to 不过，问题是通过apt安装的haproxy是不支持IPv6的！ 我们只能自己动手从源码编译了： 12345wget http://www.haproxy.org/download/1.7/src/haproxy-1.7.2.tar.gztar -xzf haproxy-1.7.2.tar.gzcd haproxy-1.7.2make TARGET=linux2626 USE_GETADDRINFO=1sudo make install]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[政史:珍珠港事件前日方决策过程梳理]]></title>
    <url>%2Fposts%2F10462%2F</url>
    <content type="text"><![CDATA[在知乎上看到的比较好的回答，作为备份放在这里： 原文链接：https://www.zhihu.com/question/306368870/answer/639051842 archive.is上的备份网页：http://archive.is/4dOL3 珍珠港俯视图（1941年10月30日） 以下是原文内容： 因为再不突袭，日本人这大东亚战争就算是白打了。 咱们这里需要补充一个小知识，在20世纪30年代末，日本的能源结构是这样的：80%的石油来自美国，10%的石油来自东印度群岛，只有7%左右的石油可以自给。那么问题来了，日本从918开始折腾到40年，找到能替代美国的石油生产地了么？ 没有。不仅石油高度依赖美国，铁和各种军需物资都严重依赖美国，甚至可以这么说，要是没有美国人提供的这些物资，日本这侵华战争就根本打不起来。 1937年美国对日出口总值为2.89亿美元,其中石油、精炼油、废钢铁、原棉这四项战略物资就达1,42亿美元,约占二分之一。以石油一项而论,日本所需石油来自美国的份额,1937年占80%,1939年占85%。——齐世荣.绥靖政策研究.,北京：首都师范大学出版社,1998：413 据统计，1937－1938年，日本从美国进口的军需品占其军需品总进口额的55%。1937年，美对日废钢铁的出口量是1931年的40倍之多。——杨玉圣.中国人的美国观.上海: 复旦大学出版社，1997：152 （1937、1938年日本）从美国输入铁合金为77.53%和82.71%,铜的比例高达95.18%和90.89%,煤油及其产品为6.271%和65.57%,汽车及零件为9.241%和64%,飞机及零件为70.19%和7.692%,金属工作母机为69.53%和67.09%。——沈庆林.中国抗战时期的国际援助.上海人民出版社,2000：53 这就是二战中最讽刺的地方，美国人是日本人在二战前期最主要石油来源国，而且没有之一。日本人觉得不能任由老美这么掐着自己的脖子，于是1934年出台了《石油工业法》表示要加强本国石油产业建设，效果……一般吧；然后37年又搞了个《合成油法案》，表示要开动大日本帝国先进之科技手段以煤改油，效果……更一般。 考虑到1937年日本的财政收入才47亿日元，而以当时的汇率来看大概3日元可以折合1美元，大家可以感受一下每年日美之间几亿美元的进口额意味着什么。而更倒霉的是虽然侵华战争开始以后日军进展极其顺利，然而中国是个贫穷的农业国，重工业基础极其薄弱，而工业建设又是个耗时巨大、烧钱极多的活儿……所以日本人十分郁闷地发现自己这仗是越打越大，然而钱却都进了美国人的兜。 这就是为什么37年日本人在扬子江上炸了美国船，罗斯福把这事按下去的原因之一——顺便一提，日本人为了平事掏出来了2214007.36刀，1937年的两百万美元啊……日本人在占领区甚至搞了一次“抵制美货”的闹剧，然而美国人对此并不在意：有本事你抵制我的石油啊？ 美国国内群众此时对日本人的反感情绪已经是十分强烈了，甚至有几百名学生代表参与了焚烧日本丝绸的行动。等到了1938年美国政府觉得实在不能再这么容忍日本人了！必须上点手段了！于是政府向上百家工厂写信：建议不要跟日本人做生意。 这就是赫赫有名的“道义禁运” 6月11日,赫尔在记者招待上公开谴贵对和平居民的空袭轰炸,随后他写给美国148家注册出口飞机和飞机部件的厂家,表示:政府强烈反对把飞机和航空设备出售给世界上任何对和平居民进行轰炸的国家——赫尔回忆录·第一卷：569 道义禁运的效果极其明显，立竿见影，日本人37年从美国进口的飞机及部件达到248.4万美元，38年为1745.4万美元，增长了7倍。 这么拖拖拖一直拖到39年重庆轰炸，美国人民一看艾玛这太惨了，咱们真的不能再卖给日本人石油了，罗斯福表示那不成啊，你不卖给他石油了他狗急跳墙去打英荷东印度群岛怎么办？为了避免战争扩大咱们还是继续做生意吧…… 对日本人来讲，事情非常尴尬——你要是想继续从美国人手里拿到物资，就必须按照美国人的意思，控制战争规模；而你想控制战争规模又控制不下来，TG在敌后遍地开花，老蒋死活就不投降，你占领的地方地大物博可就是没有好用的石油，重工业基础又弱到不行。所以日本人思前想后，最后还是向东南亚伸出了魔爪。 1939年2月，日本占领海南岛；3月，日本人又搞定了距马尼拉700英里的南沙群岛；6月，派兵封锁天津英租界，7月强迫英国人跟自己一起建设“东亚新秩序”，正在欧洲被希特勒搞得焦头烂额的英国人几乎没怎么犹豫，就在7月24号跟日本人签订了“有田——克莱琪协定”，承认了日本在中国有“特殊需要”。 这下美国人终于坐不住了，7月26号美国政府正式通知日本没，咱们那个美日商约即将在六个月后废止——半年时间，你自己想想清楚，到底还要不要铁和石油了。日本人终于发现这自己扛不住啊！赶紧还是跟美国人谈谈吧，于是9月25日，海军稳健派、熟悉米英鬼畜内部动向之大将野村吉三郎任专职外相，开始跟美国进行谈判，美国人说这事好办，你们开放长江下游、尊重我们在华权利，有钱大伙一起赚嘛！只要你们肯把中国的利益让出来一点，咱们这个商约还是可以再签的。 未果。 这期间的态势十分有趣，日本人在诺门坎吃了大败仗，彻底打消了北进的念头；敌后大规模扫荡、扫荡、再扫荡，八路就是扫不干净；正面战场进入相持状态，长沙会战、随枣会战都没能达成预定的战略目标，日本国内的经济开始遭不住了。 美国人此时反而比较克制，由于罗斯福担心“再进一步就会激怒日本”，所以1940年1月日美商约失效之后两国的贸易竟然还在诡异的继续着，然而谁也不知道这样的日子会持续多久。 对日本来说，他们必须做出选择了。 1940年3月，日本拟定了军需物资自给自足计划，将更多的精力投入到了东南亚 日本政府深切关怀足以改变荷属东印度群岛现状的任何事态——1940年4月15日,外相有田八郎讲话,太平洋战争史·第二卷：21 日本人在东南亚的脚步越来越快，而美国人则在抓紧时间，卖出自己的最后一份石油。所以一方面是日趋紧张的局势，而另一方面则是不断攀升的石油贸易，美孚石油在7月18日向国务院报告，说日本人提出要买下他们的全部产量！美国政府内部已经吵到不可开交，罗斯福接到的报告说假如我们再不限制日本人购买航空汽油，我们自己军队就可能出现6到9个月的汽油供应不足！ 在巨大的压力面前罗斯福终于决定对日本进行禁运，经过漫长的扯皮与大撕逼之后，政府官员们最终达成了一致，在7月26日宣布对航空发动机燃料及润滑油和第一号高熔度的废钢铁实行出口管制。先总统 蒋公激动地浑身颤抖，跟美国大使表示艾玛你们太够意思了！ 总统和国务卿的伟大而辉煌的举动，减轻了中国自卷入冲突以来面临的极严峻的危机。——先总统 蒋公 在这个后来被无数人称颂的禁运限制里，国务院表示辛烷值87以上的航空汽油都必须禁运！ &gt; 日本人：解释解释，什么叫“辛烷值87以上的航空汽油都必须禁运”？ &gt; 国务院：难道你不懂什么叫禁运？ &gt; 日本人：我要你解释解释，什么叫他妈的“辛烷值87以上的航空汽油都必须禁运”？ &gt; 石油公司：87号以上禁运的意思，就是他妈的87号以下不！禁！运！，还有，往86号航空汽油里加铅可以他妈的提高辛烷值！你懂了没有！？ &gt; 日本人：哦大哥，原来这就是他妈的禁运啊！小弟明白了！ 于是1940年7月到12月，日本从美国进口的86号航空汽油同比增加了550%。 此时日本的经济已经开始在崩溃的边缘上晃悠了，国家总动员法的条款几乎已经全都实施了，结果40年日本西部和朝鲜还遭遇了旱灾，粮食收成不好，好多人连吃大米都成了问题。关键是此时日本的外汇储备也接近枯竭，再这么拖下去用不了多久你想买都买不成了！最后高层达成一致，再不对东南亚下手咱们就得先完蛋了。于是1941年7月2日，御前会议最终制定了《适应形势变化的帝国国策纲要》，表示就算是跟米英鬼畜开战，咱们也得南进！7月24日，日本出兵印度支那南部。 然后罗斯福炸了：老子不禁运你石油就是为了不让你打那边，你自己心里没点数么？于是26号冻结了日本在美的全部资产；英国人表示弟儿你说的对，我们也禁运，然后切断了日本在婆罗洲的石油供给。27号荷兰人跟进，冻结日本资产。这下子事情再也没有回转的余地了。 日本人的精神一下子紧张了起来（……为什么才紧张！？），军方此前一直认为我把印度支那南部这么一占，你们这些米英鬼畜还不得乖乖坐下来跟我和谈么？咱们这和平近在眼前啊！ ……以此确保东亚的战略要地。由此或可使英美荷死心不再压迫日本,并给重庆政府以打击,以找到解决日中战争的突破口,进而或许有助于打开日荷谈判。所以只有尽快抓住时机实行“战略上先发制人之措施”,才能避免同英美作战,此即不战而胜之上策——信天清三郎,日本外交史·下册：668 1941年11月，两艘日本油轮自洛杉矶附近海域空载而归。大怒的日本人……切断了英美使馆的取暖油供应。（……我是一直没搞懂日本人的脑回路）而在此之前，8月份美国人已经提出了自己的条件：日本从中国撤军、各国在中国机会均等以及日本改变三国同盟，这个条件被日本人毫不犹豫地拒绝了。9月6日，日本御前会议批准了《帝国国策施行要点》，指出10月上旬外交依然没有进展，则准备开战。 日本人最开始的计划是咱们先赶紧在东南亚占地盘，然后建立个防御圈——考虑到东南亚还有个美属菲律宾，那美国人妥妥是要来跟咱们打的，到时候咱们舰队决战，拼个你死我活！ 然后联合舰队的指挥官山本五十六对此表示了不同意见——美国人啥工业能力？你什么工业能力？心里没点数么？既然已经料到要打，那为什么不趁着美国人还没有完全动员的时候直接先下手为强？要知道，海军要想重建，那难度可比陆军难多了。咱们一鼓作气消灭美国的太平洋海上力量，然后趁着美国人重建海军无暇的关口逼他就范，承认咱们大日本帝国在亚洲的霸权那是十分合理的！ 11月20日，日本向美国提出最后一个谈判方案，日本人表示这绝对是自己最后的底线了 1.日本政府和美国政府都保证,除了目前己驻有日军的法属印度支那以外,不向东南亚和南太平洋地区的任何地方进行任何武装进军。 2.一俟日本和中国之间恢复和平,或在太平洋地区建立了公正的和平,日本政府保证撤走目前驻扎在法属印度支那的军队。同时,日本政府宣布在本协议(以后将包含在最后协议中)订立时,准备把现驻法属印支南部的军队移驻该地区北部. 3.日美两国政府将进行合作,以保证两国在荷属东印度群岛取得所需要的货物和商品。 4.日本政府和美国相互保证把通商关系恢复到日方资金被冻结前的状态.美国政府将按日本所需的数量供应石油。 5.美国政府保证不采取任何措施和行动,不利于日本和中国之间为谋求全面和平所作的努力。——United States Department of State.Papers relating to the foreign relations of the United States, Japan, 1931–1941, Volume II 美国人对此表示难以置信，并回复了一份由国务卿起草的备忘录，基本上重申了自己在8月份提出的要求。美国人所不知道的，是在自己做出这个回复以前，一支规模空前的舰队已经在单冠湾集结完毕了，那上面的飞行员此前曾反复地练习过如何低空投放鱼雷和炸弹。罗斯福此时还在犹豫要不要向日本示好，以挽回两国之间的关系，11月22日美国国务院远东司甚至接到命令，起草一份新的草案，有限度地恢复对日本的石油、食品及药物供应。然而由于中国及英国的强烈反对，这份草案最终也没能实施。 1941年12月1日，日本御前会议做出了决定：与美国开战。 1941年12月7日，珍珠港事件爆发，美国太平洋舰队遭到重创。 1942年，日本军队逼近东印度群岛的巴厘巴板炼油厂，1943年第一季度，日本的石油危机大大缓和。 石油问题已经基本得到解决——东条英机·1943 以上。 后记：这篇文章的作者设置了禁止转载，不过我这博客也没什么人看，我放在这里也是为了备份，也许将来某天知乎挂了或者作者决定退出知乎了删除了这篇问答？另外，作者的这篇文章里面还是有一些戏谑口吻的地方，我打算围绕着作者写的主干，做一做考据，让这篇文章能够成为之后“键政”的有力资料。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
        <tag>政治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[996 License 1.0]]></title>
    <url>%2Fposts%2F12613%2F</url>
    <content type="text"><![CDATA[Copyright (c) 996 License Version 1.0 (Draft) Permission is hereby granted to any individual or legal entity obtaining a copy of this licensed work (including the source code, documentation and/or related items, hereinafter collectively referred to as the &quot;licensed work&quot;), free of charge, to deal with the licensed work for any purpose, including without limitation, the rights to use, reproduce, modify, prepare derivative works of, publish, distribute and sublicense the licensed work, subject to the following conditions: The individual or the legal entity must conspicuously display, without modification, this License on each redistributed or derivative copy of the Licensed Work. The individual or the legal entity must strictly comply with all applicable laws, regulations, rules and standards of the jurisdiction relating to labor and employment where the individual is physically located or where the individual was born or naturalized; or where the legal entity is registered or is operating (whichever is stricter). In case that the jurisdiction has no such laws, regulations, rules and standards or its laws, regulations, rules and standards are unenforceable, the individual or the legal entity are required to comply with Core International Labor Standards. The individual or the legal entity shall not induce or force its employee(s), whether full-time or part-time, or its independent contractor(s), in any methods, to agree in oral or written form, to directly or indirectly restrict, weaken or relinquish his or her rights or remedies under such laws, regulations, rules and standards relating to labor and employment as mentioned above, no matter whether such written or oral agreement are enforceable under the laws of the said jurisdiction, nor shall such individual or the legal entity limit, in any methods, the rights of its employee(s) or independent contractor(s) from reporting or complaining to the copyright holder or relevant authorities monitoring the compliance of the license about its violation(s) of the said license. THE LICENSED WORK IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE COPYRIGHT HOLDER BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN ANY WAY CONNECTION WITH THE LICENSED WORK OR THE USE OR OTHER DEALINGS IN THE LICENSED WORK. 版权所有（c） 反996许可证版本1.0 在符合下列条件的情况下，特此免费向任何得到本授权作品的副本（包括源代码、文件和/或相关内容，以下统称为“授权作品”）的个人和法人实体授权：被授权个人或法人实体有权以任何目的处置授权作品，包括但不限于使用、复制，修改，衍生利用、散布，发布和再许可： 个人或法人实体必须在许可作品的每个再散布或衍生副本上包含以上版权声明和本许可证，不得自行修改。 个人或法人实体必须严格遵守与个人实际所在地或个人出生地或归化地、或法人实体注册地或经营地（以较严格者为准）的司法管辖区所有适用的与劳动和就业相关法律、法规、规则和标准。如果该司法管辖区没有此类法律、法规、规章和标准或其法律、法规、规章和标准不可执行，则个人或法人实体必须遵守国际劳工标准的核心公约。 个人或法人不得以任何方式诱导或强迫其全职或兼职员工或其独立承包人以口头或书面形式同意直接或间接限制、削弱或放弃其所拥有的，受相关与劳动和就业有关的法律、法规、规则和标准保护的权利或补救措施，无论该等书面或口头协议是否被该司法管辖区的法律所承认，该等个人或法人实体也不得以任何方法限制其雇员或独立承包人向版权持有人或监督许可证合规情况的有关当局报告或投诉上述违反许可证的行为的权利。 该授权作品是&quot;按原样&quot;提供，不做任何明示或暗示的保证，包括但不限于对适销性、特定用途适用性和非侵权性的保证。在任何情况下，无论是在合同诉讼、侵权诉讼或其他诉讼中，版权持有人均不承担因本软件或本软件的使用或其他交易而产生、引起或与之相关的任何索赔、损害或其他责任。 https://link.zhihu.com/?target=https%3A//github.com/kattgu7/996-License-Draft/]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OC和Swift混编Frameowork优雅指南]]></title>
    <url>%2Fposts%2F56606%2F</url>
    <content type="text"><![CDATA[本文主要参考了优雅地开发Swift和Object C混编的Framework。不过实际发现，完全按照文章里面”优雅的解决方案“里面的说法操作，还是没法成功。我这里根据实际情况作出了调整。 参考的文章中在“优雅的解决方案”这个section之前的内容都是好用的，你可以用用来创建一个兼容OC和Swift的Cooca Touch Framework。 这里说的“优雅”，指的是控制OC部分接口保留的问题（详情可以参考原文部分） 原文里面只说了具体的操作步骤，没有高屋建瓴地说出这种方法的实际思路：事实上，采用module.modulemap的方法是将OC部分打包成一个可以使用Swfit语句进行导入(import)的模块。以这个视角，我们再来梳理一下操作步骤： 新建一个module.modulemap文件 文件里的内容如下： 12345module OCSource [system] &#123; //由于module.modulemap和OCSource.h是在同一个文件夹的，如果不是同一个，路径要写全 header &quot;OCSource.h&quot; export *&#125; 有一个容易犯错的问题是将这里的模块名字, OCSource命名为了Cocoa Touch Framework的名字。这样会导致编译出错，错误信息会提示你Module名字重复定义。这里的名字要区别的Framework的名字，具体是什么可以自己自由选择。不过推荐和头文件的名字一致 后一步操作是把module.modulemap的路径添加到Build Settings的Import Paths中，这是为了让我们在Swift里面import这个module的时候能够找到目标. Import Paths in Build Settings 那么，这里的$(SRCROOT)/MixFramework其实就是指的module.modulemap的路径。 将OCSouce.h文件的权限改为project Header Visibility Settings 这可以让OCSource.h不再对外可见。 然后，删除MixFramework.h(umbrella header)中#import 的OC header。 原文的内容到此结束，但是其实还是不够的。这时候如果编译，会发现你在Framework内部的Swift使用OCSource的地方都会报错说OCSource不存在。因为将OCSource.h从umbrella header中删除之后Swift就无法看到这个文件了。然而，通过module.modulemap文件我们将OCSource.h及相关的OC文件打包成了了一个Swift模块，因此我们可以在Swift代码中import进来： 1import OCSource 在报错的Swift文件中添加这个导入，就可以解决这个问题了.]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>ios</tag>
        <tag>swift</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Universal(Fat) Framework for Swift Projects]]></title>
    <url>%2Fposts%2F28461%2F</url>
    <content type="text"><![CDATA[Cocoa Touch Framework 最近在给朋友做一个项目，要求将涉及到的算法内容整理成一个单独的framework，这样可以隐藏算法细节，方便交付。这个需求可以很容易地通过Cocoa Touch Framework实现。不过在交付的时候存在一个头疼的问题：默认情况下，Xcode在编译Cocoa Touch Framework时只会编译出支持模拟器或者真机的Framework，而无法编译出同时支持模拟器和真机的Framework，即Universal(Fat) Framework。这一需求还需要进一步地利用一些系统脚本来实现。 这里假设你已经有了一个能够正常工作，编译的包含Cocoa Touch Framework的工程。我这里实现时使用的是Xcode10.2。 事实上我在调研中发现了很多不同的实现编译Universal Framework的教程，但是他们并不总是有用，我这里只遴选了我自己测试通过没有问题的思路。这一思路通过Archive过程来打包输出framework 首先从Xcode左上角选择Cocoa Touch Framework的默认scheme，然后点击Edit Scheme Edit Scheme 在Archive的post-action中添加一个运行脚本(New Run Script Action) New Run Script Action 脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748exec &gt; /tmp/$&#123;PROJECT_NAME&#125;_archive.log 2&gt;&amp;1UNIVERSAL_OUTPUTFOLDER=$&#123;BUILD_DIR&#125;/$&#123;CONFIGURATION&#125;-universalif [ "true" == $&#123;ALREADYINVOKED:-false&#125; ]thenecho "RECURSION: Detected, stopping"elseexport ALREADYINVOKED="true"# make sure the output directory existsmkdir -p "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;"echo "Building for iPhoneSimulator"xcodebuild -workspace "$&#123;WORKSPACE_PATH&#125;" -scheme "$&#123;TARGET_NAME&#125;" -configuration $&#123;CONFIGURATION&#125; -sdk iphonesimulator -destination 'platform=iOS Simulator,name=iPhone 6' ONLY_ACTIVE_ARCH=NO ARCHS='i386 x86_64' BUILD_DIR="$&#123;BUILD_DIR&#125;" BUILD_ROOT="$&#123;BUILD_ROOT&#125;" ENABLE_BITCODE=YES OTHER_CFLAGS="-fembed-bitcode" BITCODE_GENERATION_MODE=bitcode clean build# Step 1. Copy the framework structure (from iphoneos build) to the universal folderecho "Copying to output folder"# 这行是在我参考的脚本的基础上添加进去的。脚本在运行过程中有一个问题：在试图将# archive过程中生成的device framework拷贝进来时，总是拷贝的framework文件夹# 的内容，而非整个文件夹，所以我们这里手动创建这个文件夹mkdir -p "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;FULL_PRODUCT_NAME&#125;"cp -R "$&#123;ARCHIVE_PRODUCTS_PATH&#125;$&#123;INSTALL_PATH&#125;/$&#123;FULL_PRODUCT_NAME&#125;" "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;FULL_PRODUCT_NAME&#125;"# Step 2. Copy Swift modules from iphonesimulator build (if it exists) to the copied framework directorySIMULATOR_SWIFT_MODULES_DIR="$&#123;BUILD_DIR&#125;/$&#123;CONFIGURATION&#125;-iphonesimulator/$&#123;TARGET_NAME&#125;.framework/Modules/$&#123;TARGET_NAME&#125;.swiftmodule/."echo "SIMULATOR_SWIFT_MODULES_DIR: $&#123;SIMULATOR_SWIFT_MODULES_DIR&#125;"if [ -d "$&#123;SIMULATOR_SWIFT_MODULES_DIR&#125;" ]; thencp -R "$&#123;SIMULATOR_SWIFT_MODULES_DIR&#125;" "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;TARGET_NAME&#125;.framework/Modules/$&#123;TARGET_NAME&#125;.swiftmodule"fi# Step 3. Create universal binary file using lipo and place the combined executable in the copied framework directoryecho "Combining executables"lipo -create -output "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;FULL_PRODUCT_NAME&#125;/$&#123;EXECUTABLE_PATH&#125;" "$&#123;BUILD_DIR&#125;/$&#123;CONFIGURATION&#125;-iphonesimulator/$&#123;EXECUTABLE_PATH&#125;" "$&#123;ARCHIVE_PRODUCTS_PATH&#125;$&#123;INSTALL_PATH&#125;/$&#123;EXECUTABLE_PATH&#125;"# Step 4. Create universal binaries for embedded frameworks#for SUB_FRAMEWORK in $( ls "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;TARGET_NAME&#125;.framework/Frameworks" ); do#BINARY_NAME="$&#123;SUB_FRAMEWORK%.*&#125;"#lipo -create -output "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;TARGET_NAME&#125;.framework/Frameworks/$&#123;SUB_FRAMEWORK&#125;/$&#123;BINARY_NAME&#125;" "$&#123;BUILD_DIR&#125;/$&#123;CONFIGURATION&#125;-iphonesimulator/$&#123;SUB_FRAMEWORK&#125;/$&#123;BINARY_NAME&#125;" "$&#123;ARCHIVE_PRODUCTS_PATH&#125;$&#123;INSTALL_PATH&#125;/$&#123;TARGET_NAME&#125;.framework/Frameworks/$&#123;SUB_FRAMEWORK&#125;/$&#123;BINARY_NAME&#125;"#done# Step 5. Convenience step to copy the framework to the project's directoryecho "Copying to project dir"yes | cp -Rf "$&#123;UNIVERSAL_OUTPUTFOLDER&#125;/$&#123;FULL_PRODUCT_NAME&#125;" "$&#123;PROJECT_DIR&#125;"open "$&#123;PROJECT_DIR&#125;"fi 上述脚本的内容主要来自于export-fat-swift-dynamic-framework，我在这里根据实际情况进行了更改 此时执行archive操作(Product-&gt;Archive)完成后会自动弹出Finder窗口显示新生成的framework的位置（应当就是位于项目根目录下）。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>ios</tag>
        <tag>swift</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时局图：论扛着红旗反红旗]]></title>
    <url>%2Fposts%2F8446%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
        <tag>政治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS:图像截取部分(Image Cropping)]]></title>
    <url>%2Fposts%2F2543%2F</url>
    <content type="text"><![CDATA[Cover 这里我们讨论的图像截取部分是指从一个完整的大图中截取一小部分出来。当然，使用js实现。 这边文章基本整理自Cropping images with Javascript， 添加了一些我的评论 例如，我们要从这样的大图中： 大图 截取出 小图 使用H5中的canvas可以简单地解决这个问题。 1. 载入原图像 1234567891011121314var loadTimer;var imgObject = new Image();imgObject.src = 'images/fozzie.jpg';imgObject.onLoad = onImgLoaded();function onImgLoaded() &#123; if (loadTimer != null) clearTimeout(loadTimer); if (!imgObject.complete) &#123; loadTimer = setTimeout(function() &#123; onImgLoaded(); &#125;, 3); &#125; else &#123; onPreloadComplete(); &#125;&#125; 注意这里我们为了演示是读取的图片文件内容，实际上除了图像文件，这里的“图像”还可以是其他形式，例如video元素，别的canvas等。 2. 当图片完成载入以后，重新绘制你要截取的那一部分 123456function onPreloadComplete()&#123; //call the methods that will create a 64-bit version of thumbnail here. var newImg = getImagePortion(imgObject, 120, 150, 150, 80, 2); //place image in appropriate div document.getElementById("images").innerHTML = "&lt;img alt="" src=""+newImg+"" /&gt;";&#125; 这个onPreloadComplete函数会在图像载入完成以后调用。在这个函数中我们会调用实际完成图片截取的函数getImagePortion 3. 图像截取 123456789101112131415161718getImagePortion(imgObj, newWidth, newHeight, startX, startY, ratio)&#123; /* the parameters: - the image element - the new width - the new height - the x point we start taking pixels - the y point we start taking pixels - the ratio */ //set up canvas for thumbnail var tnCanvas = document.createElement('canvas'); var tnCanvasContext = canvas.getContext('2d'); tnCanvas.width = newWidth; tnCanvas.height = newHeight; /* use the sourceCanvas to duplicate the entire image. This step was crucial for iOS4 and under devices. Follow the link at the end of this post to see what happens when you don’t do this */ var bufferCanvas = document.createElement('canvas'); var bufferContext = bufferCanvas.getContext('2d'); bufferCanvas.width = imgObj.width; bufferCanvas.height = imgObj.height; bufferContext.drawImage(imgObj, 0, 0); /* now we use the drawImage method to take the pixels from our bufferCanvas and draw them into our thumbnail canvas */ tnCanvasContext.drawImage(bufferCanvas, startX,startY,newWidth * ratio, newHeight * ratio,0,0,newWidth,newHeight); return tnCanvas.toDataURL();&#125; 上面的函数时原作者给出的方法，他先将图像完整地画到一个canvas(bufferCanvas)上，再将这个canvas对应的目标区域画到tnCanvas上，根据注释来看，似乎是出于性能或者适配方面的考虑。不过就我在开发桌面端网页时，可以直接将imgObj画到tnCanvas上。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】IOS的一些设计规范]]></title>
    <url>%2Fposts%2F23804%2F</url>
    <content type="text"><![CDATA[转载自BIGD团队。]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>ios</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac: 将APP打包成dmg]]></title>
    <url>%2Fposts%2F62609%2F</url>
    <content type="text"><![CDATA[创建一个新的文件夹，将APP放到这个新文件夹中 打开Disk Utility &gt; File &gt; New Image &gt; Image from Folder.（中文的话，是磁盘工具 &gt; 文件 &gt; 新建映像 &gt; 来自文件夹的映像...） 在弹出的窗口中，选择在第一步中新建的文件夹 选择输出dmg文件的存储位置，然后点击保存按钮]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】在小米电视和小米盒子上看YOUTUBE]]></title>
    <url>%2Fposts%2F5827%2F</url>
    <content type="text"><![CDATA[使用小米电视和小米盒子看YouTube上的视频，是很多中国电视用户很想做的事情，下面，我就介绍一种很简单的方法，不用ROOT小米电视或小米盒子，不用重装系统，几分钟的设置就可以在小米电视和小米盒子上看YouTube的方法。 首先需要下载两个APK应用，第一个是SmartYouTubeTV，点击这里下载最新版SmartYouTubeTV，将其复制到U盘。第二个是Shadowsocks，访问apkmirror网站，搜索Shadowsocks，找到最新版后，下载universal的apk到U盘即可。 之后，打开小米电视或小米盒子，在“设置-账户与安全”里，选择“允许安装未知来源的应用”。插入U盘，将上述两个apk文件安装到电视上。 最后，在Shadowsocks上设置好服务器地址，打开SmartYouTubeTV，选择第一个，然后可以选择登陆Google账号，登陆的时候，会让用户在手机上访问 youtube.com/activate 来登陆激活，登陆好了后，电视即可和电脑浏览器的YouTube同步了。 Smart YouTube TV里登陆Google账号后，你会发现，YouTube里的订阅、上传、历史什么的功能全部可以正常使用了，完美支持小米遥控器控制，观看视频体验极佳，完全不亚于官方的应用。 当然，用户也可以选择安装官方的YouTube应用，但必须安装Google框架等一堆东西，使用体验可能还未必好。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>转载</tag>
        <tag>翻墙</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在普通网络环境下上北邮人]]></title>
    <url>%2Fposts%2F54288%2F</url>
    <content type="text"><![CDATA[在学校里看剧、电影，下载破解游戏基本都靠北邮人。一方面资源比较全，另一方面是走IPv6，不需要走计费的校园网IPv4流量。不过由于北邮人只支持IPv6，而国内IPv6基本只有校园网有。问题来了，怎么在校外的纯IPv4环境下使用IPv6 Only的北邮人呢？ 从IPv4到IPv6 这是最重要的一步。你首先需要一个支持IPv6的VPS。国内目前支持IPv6的好像只有阿里云？，即便支持，国内的IPv6 VPS又贵又难用（需要申请）。因此最好的方案是采用海外的VPS。听起来用海外的VPS会很慢？其实海外的VPS主要是延时高，其实速度还是挺快的，而且P2P传输业务受到延时的影响挺小的，实测利用我的VPS可以达到5MB/s的P2P下载速度（在服务器上看上下行都是5MB/s，基本跑满了100M的带宽）。我用的VPS是Digital Ocean的旧金山节点。价格是$5一个月。平均下来每天一块钱吧。注意创建Droplet的时候要自己勾选IPv6（添加IPv6是免费的）。 选择IPv6 在服务器上我部署了Shadowsocks服务。SS服务器可以直接无痛支持IPv4到IPv6的转换。关于如何部署Shadowsocks，这方面的教程文章网上汗牛充栋，我这里就不提供了。 设置 首先需要将北邮人的网址bt.byr.cn添加到Shadowsocks客户端的代理列表。 Shadowsocks选项 点击Shadowsocks小飞机，选择“编辑PAC用户自定规则”。在弹出的框中输入||bt.byr.cn： 编辑PAC用户自定规则 然后你就能在IPv4网络环境下打开北邮人的网页啦。 接下来是设置下载客户端uTorrent的网络设置。打开uTorrent的设置(Preferences)，进入到Network。进行如下设置： uTorrent设置 注意：上面的Socks5设置中，端口会与你的Shadowsocks设置有关。如果你没有动过相关设置的话，应该就是1086端口。 查看你的Shadowsocks客户端Sock5代理端口设置的方式是单击Shadowsocks小飞机，选择偏好设置，在弹出的窗口中点击“高级”，其中“本地Socks5监听端口”即为应该填写到uTorrent设置中的代理端口。 大功告成！_(:з」∠)_]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SimpleOpenNI在Processing导出应用中的库引用问题]]></title>
    <url>%2Fposts%2F65501%2F</url>
    <content type="text"><![CDATA[在Processing中使用SimpleOpenNI时，如果尝试将本来能够正常运行的pde文件导出成应用，那么在运行时会出现java.lang.UnsatisfiedLinkError这个错误。详细信息如下： 1234567891011121314Can&apos;t load SimpleOpenNI library (libSimpleOpenNI.jnilib) : java.lang.UnsatisfiedLinkError: Can&apos;t load library: /SimpleOpenNI/library/libSimpleOpenNI.jnilibVerify if you installed SimpleOpenNI correctly.http://code.google.com/p/simple-openni/wiki/Installationjava.lang.UnsatisfiedLinkError: SimpleOpenNI.SimpleOpenNIJNI.swig_module_init()V at SimpleOpenNI.SimpleOpenNIJNI.swig_module_init(Native Method) at SimpleOpenNI.SimpleOpenNIJNI.&lt;clinit&gt;(SimpleOpenNIJNI.java:290) at SimpleOpenNI.ContextWrapper.&lt;init&gt;(ContextWrapper.java:54) at SimpleOpenNI.SimpleOpenNI.&lt;init&gt;(SimpleOpenNI.java:253) at Sketch.settings(Sketch.java:28) at processing.core.PApplet.handleSettings(PApplet.java:954) at processing.core.PApplet.runSketch(PApplet.java:10786) at processing.core.PApplet.main(PApplet.java:10511) at Main.main(Main.java:7) 根据错误信息，是在读取libSimpleOpenNI.jnilib这个库文件时失败导致的。奇怪的是，程序尝试读取的路径是：/SimpleOpenNI/library/libSimpleOpenNI.jnilib。这是一个很奇怪的绝对路径。也有人尝试直接将库文件复制到这个全局路径的位置，可以让程序运行起来。可是这种方法也太不优雅了。 为什么会出现这种现象？ 通过IntelliJ可以打开SimpleOpenNI.jar查看代码细节。可以看到SimpleOpenNI.class中确定载入库文件路径的方式如下： 1234567891011121314151617181920212223242526272829303132static &#123; String var0 = System.getProperty("os.name").toLowerCase(); String var1 = "SimpleOpenNI"; String var2 = System.getProperty("os.arch").toLowerCase(); if (var0.indexOf("win") &gt;= 0) &#123; // ... &#125; else if (var0.indexOf("nix") &lt; 0 &amp;&amp; var0.indexOf("linux") &lt; 0) &#123; if (var0.indexOf("mac") &gt;= 0) &#123; var1 = "lib" + var1 + ".jnilib"; nativLibPath = getLibraryPathLinux() + "/SimpleOpenNI/library/"; nativDepLibPath = nativLibPath + "osx/"; &#125; &#125; else &#123; nativLibPath = "/SimpleOpenNI/library/linux"; if (var2.indexOf("86") &gt;= 0) &#123; var1 = var1 + "32"; &#125; else if (var2.indexOf("64") &gt;= 0) &#123; var1 = "lib" + var1 + "64.so"; nativLibPath = getLibraryPathLinux() + "/SimpleOpenNI/library/"; nativDepLibPath = nativLibPath + "linux64/"; &#125; &#125; try &#123; System.load(nativLibPath + var1); &#125; catch (UnsatisfiedLinkError var5) &#123; System.out.println("Can't load SimpleOpenNI library (" + var1 + ") : " + var5); System.out.println("Verify if you installed SimpleOpenNI correctly.\nhttp://code.google.com/p/simple-openni/wiki/Installation"); &#125; _initFlag = false; &#125; 注意到在生成库文件路径时，/SimpleOpenNI/library/libSimpleOpenNI.jnilib，前面应该会添加getLibraryPathLinux()的结果。 123456789101112public static String getLibraryPathLinux() &#123; URL var0 = SimpleOpenNI.class.getResource("SimpleOpenNI.class"); if (var0 != null) &#123; String var1 = var0.toString().replace("%20", " "); int var2 = var1.indexOf(47); boolean var3 = true; int var4 = var1.indexOf("/SimpleOpenNI/library"); return -1 &lt; var2 &amp;&amp; -1 &lt; var4 ? var1.substring(var2, var4) : ""; &#125; else &#123; return ""; &#125; &#125; 我尝试了在不同环境下,SimpleOpenNI.class.getResource(&quot;SimpleOpenNI.class&quot;)下运行的结果。发现： 在pde运行时，获取到的是独立的SimpleOpenNI.jar下的路径，例如：/Users/lena/Documents/Processing/libraries/SimpleOpenNI/library/SimpleOpenNI.jar!/SimpleOpenNI/SimpleOpenNI.class 在导出应用中运行时，获取到的是打包后应用内的，例如.../MySketch/application.macosx/MySketch.app/Contents/Java/SimpleOpenNI.jar!/SimpleOpenNI/SimpleOpenNI.class 在函数getLibraryPathLinux中，程序会定位/SimpleOpenNI/library这个字符串，然后取出这个子字符串前的内容构成的路径。上述第二种情形内，SimpleOpenNI.jar被打包到应用内后，不在处于/SimpleOpenNI/library这个前缀目录下，所以导致定位失败。 如何解决这个问题。 在无法直接修改SimpleOpenNI的源代码的情况下，要修复这个问题，就要想办法把SimpleOpenNI.jar放到SimpleOpenNI/library目录下。我使用的macOS系统，下面的方法都是在Mac下测试。不过基本思路可以迁移到Windows上。 在生成的App上右键选择显示包内容。可以查看其内部结构： 123456789101112131415161718192021222324252627282930.├── Info.plist├── Java│ ├── Sketch.jar│ ├── NiTE2│ ├── SimpleOpenNI.jar│ ├── SimpleOpenNI32.dll│ ├── SimpleOpenNI64.dll│ ├── core.jar│ ├── data│ ├── gluegen-rt-natives-macosx-universal.jar│ ├── gluegen-rt.jar│ ├── javamp3-1.0.3.jar│ ├── jogl-all-natives-macosx-universal.jar│ ├── jogl-all.jar│ ├── jsyn-20171016.jar│ ├── libSimpleOpenNI.jnilib│ ├── libSimpleOpenNI64.so│ ├── osx│ ├── sound.jar│ ├── win32│ └── win64├── MacOS│ └── Sketch├── PkgInfo├── PlugIns│ └── jdk1.8.0_181.jdk└── Resources ├── en.lproj └── sketch.icns 可以看到SimpleOpenNI.jar位于Java目录下。我尝试过直接在此处创建目录SimpleOpenNI/library并把SimpleOpenNI.jar放进去。但是运行提示无法找到SimpleOpenNI.jar。这需要在APP运行时进一步指定CLASSPATH。有一种方法是直接在Info.plist文件里面添加-Djava.class.path运行属性，或者添加ClASSPATH环境变量，但是这种方法会要求你手动填写所有需要使用的jar依赖，甚至是包括processing的jar文件。这对于后续维护和修改很不利。所以这里我采取了另一种取巧的办法。 进入Contents/MacOS目录，删除原来的Sketch文件(你看到的应该是和你的Processing程序同名的文件，我这里用Sketch来代替)。新建一个同名的空白的文本文件，然后在文件中添加如下内容： 1234567891011121314151617181920212223242526#!/bin/bashcd "$(dirname $&#123;BASH_SOURCE&#125;)"cd ../..APP_ROOT=$(pwd)cd Contents/JavaJAR_LIBS=$(ls *.jar | tr "\n" ":")# 添加SimpleOpenNI.jarJAR_LIBS=$&#123;JAR_LIBS&#125;./SimpleOpenNI/library/SimpleOpenNI.jarAPP_NAME=$(basename "$&#123;BASH_SOURCE&#125;")# 注意：如果你内嵌的jdk的版本不同，要把jdk1.8.0_181.jdk替换成对应的版本# 如果你没有在app内部内嵌jdk，这里修改成JAVA_BIN=java，使用系统全局的java即可JAVA_BIN=$&#123;APP_ROOT&#125;/Contents/PlugIns/jdk1.8.0_181.jdk/Contents/Home/jre/bin/java$&#123;JAVA_BIN&#125; \-Djna.nosys=true \-Djava.ext.dirs=$APP_ROOT/Contents/PlugIns/jdk1.8.0_181.jdk/Contents/Home/jre/lib/ext \-Xdock:icon=$APP_ROOT/Contents/Resources/sketch.icns \-Djava.library.path=$APP_ROOT/Contents/Java \-Dapple.laf.useScreenMenuBar=true \-Dcom.apple.macos.use-file-dialog-packages=true \-Dcom.apple.macos.useScreenMenuBar=true \-Dcom.apple.mrj.application.apple.menu.about.name=$&#123;APP_NAME&#125; \-classpath $&#123;JAR_LIBS&#125; $&#123;APP_NAME&#125; 为这个文件添加可执行权限 1chmod +x ./Sketch 将~/Documents/Processing/libraries/SimpleOpenNI整个文件夹拷贝进导出APP的Contents/Java目录下。然后就可以运行了。]]></content>
      <categories>
        <category>processing</category>
      </categories>
      <tags>
        <tag>processing</tag>
        <tag>Debug</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks中继:从IPv4到IPv6]]></title>
    <url>%2Fposts%2F6289%2F</url>
    <content type="text"><![CDATA[最近墙又双叒叕加高了。在春节前就发现自己的VPS无法连接，后来发现还好只是端口被封禁，换成其他的端口就能使用了。不过这才撑了半个月新的端口访问又不太稳定了。如果再换端口，或许也可以。但是不是长久之计。不过我的VPS是支持IPv6的，一般来说，墙对于IPv6流量的拦截比较弱。或许可以想办法先把自己的流量转换成IPv6然后再出去。 我也设想过要不要给代理添加混淆的功能，处于以下几方面的考虑，还是选择了流量转换的方案： 1. 手机端部分ss应用不支持混淆； 2. 未来混淆还是可能被针对性的拦截。但是IPv6则不会。GFW拦截还是拦截大鱼不拦截小鱼的。国内目前IPv6的使用范围仍然非常小，而且基本只限于教育网。因此IPv6在未来的很长一段时间内不会成为GFW的针对目标 我们这里使用HAProxiy来完成这一功能。 安装HAProxy 1234wget http://www.haproxy.org/download/1.7/src/haproxy-1.7.2.tar.gztar -xzf haproxy-1.7.2.tar.gzmake TARGET=linux2826 USE_GETADDRINFO=1sudo make install 注意，在倒数第二行的make命令中，TARGET需要根据你的内核版本来选择。USE_GETADDRINFO的作用是使得HAProxy可以对域名采用DNS查询来获取IP。使用包管理器安装的HAProxy是不带这个功能的。 设置 123456789101112131415161718global ulimit-n 51200 daemon # run as daemondefaults log global mode tcp option dontlognull timeout connect 1000 timeout client 150000 timeout server 150000frontend ss-in bind *:port # 跳板机监听端口 default_backend ss-outbackend ss-out server server1 vps_host:vps_ss_port maxconn 20480 设置文件位于/etc/haproxy/haproxy.cfg。在完成设置后，使用sudo haproxy -f /etc/haproxy/haproxy.cfg来运行。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转载】无人机击落客机只是时间问题]]></title>
    <url>%2Fposts%2F48586%2F</url>
    <content type="text"><![CDATA[我是一个无人机集群技术的研究者，从最近开始我打算集中整理发布一些无人机，尤其是无人机集群技术的新进展以及评论文章。 原文链接：It’s only a matter of time before a drone takes down a passenger plane Cover 2018年12月，英国第二大机场盖特威克机场，发现有一架无人机飞过机场，不得不关闭一天，几十万旅客受到影响。目前还不知道这架无人机是谁操作，为什么要飞入机场。 这个事件表明，无人机对商业航空已经构成威胁。更严重的是，&quot;反无人机&quot;技术起不了多大作用。无人机已经变得太便宜，太强大，客机将不可避免地受到影响。无论是开枪、无线电干扰、或者其他措施，都无法可靠地保护客机。这可能听起来危言耸听，但我们对无人机真的缺乏办法。 现在，消费者可以买到的最便宜无人机，只需要25美元。这些产品接受遥控器的无线信号，相对容易防范，只要干扰它们的无线电信号，就可以了。稍微昂贵的无人机有 GPS 芯片，这种无人机可以编程设置一个&quot;地理围栏&quot;，防止它们飞入指定的地理坐标范围内。 但是，上面的这些措施，只能防住普通消费者从正规渠道买到的无人机。对于具有中等技术水平的人来说，制造一架无人机很容易，自制无人机也不需要 GPS 芯片。它们也不一定需要与操作员通信，才能保持飞行，这使得无线电干扰无效。而且，强度太大的干扰信号，反而可能会影响到本来要保护的客机。 可以肯定的是，一架无人机攻击一架客机，成功机会不大。这是因为在起飞和着陆时（最容易遭遇无人机的阶段），客机的移动速度非常快，通常在每小时150到200英里之间，很少有无人机能够以50~70英里/小时的速度飞行，所以客机应该可以避开无人机。此外，飞机的设计可以承受鸟撞，如果一架无人机意外撞到客机，客机可能只会受到轻微损坏，很可能还是能够安全降落。 但是，如果无人机成群飞行，事情就会发生变化。虽然单个无人机很难攻击飞机，但是在客机的飞行路径上放置30架无人机，就可能会发生变化。考虑到无人机的价格，多架无人机群体攻击是很容易的。如果通过编程，找出客机的引擎（通过红外传感或通过图像），然后无人机携带少量爆炸物，撞击可能会致命。 总之，对于那些蓄意攻击客机的半自动或全自动无人机集群，根本就没有好的技术对策。]]></content>
      <categories>
        <category>科技新闻</category>
      </categories>
      <tags>
        <tag>无人机</tag>
        <tag>科技新闻</tag>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netlink:用户空间与内核空间交互]]></title>
    <url>%2Fposts%2F2348%2F</url>
    <content type="text"><![CDATA[Reference 1 什么是Netlink Netlink is a socket family that supplies a messaging facility based on the ++BSD socket interface++ to send and retrieve kernel-space information from user-space. Netlink is portable, highly extensible and it supports ++event-based notifications++. 从这段描述来看Netlink可以提供类似socket接口，这意味着我们能够传输比较大量的，结构化的数据。另外，Netlink还提供了基于时间通知的功能，也适合我们时刻监控系统动态。 Netlink是一种面向数据表(datagram-oriented)的连通用户空间和内核空间的__++消息系统++__。同时，Netlink也可以用于进程间通信(InterProcess Communication, IPC)。我们这里只关注前者。Netlink构筑与通用的BSD scoket基础设施之上，因此支持使用socket(), bind(), sendmsg(), recvmsg()和其他通常的socket polling操作。 一般的BSD socket使用的是固定格式的数据结构(如AF_INET或者AF_RAW)。Netlink则提供更加可扩展的数据格式。 2 Netlink的典型应用场景 当前Netlink主要应用场景是网络相关应用，包括： advanced routing IPsec key management tools firewall state synchronization uesr-space packet enqueuing border gateway routing protocols wireless mesh routing protocols 这个应用场景与我们的需要时契合的 3 Netlink总线 Netlink允许最多32条内核空间总线。一般来说每个总线都关联到一个内核子系统中（多个子系统也可以共享一个总线）。总线共享的例子包括： nfnetlink：所有防火墙相关子系统共享 rtnetlink：网络设备管理，路由和队列管理 关于Netlink总线，我发现了一个内核的patch，其中提到，&quot;This patchset aims to improve this situation by add ing a new NETLINK_DESC bus with two commands...&quot; 4 Netlink通信类型 Netlink支持两种通信类型： Unicast：一对一通信，即一个内核子系统对应一个用户空间程序。这种通信模式一般用来发送命令，或者获取命令执行的结果。 Multicast：一对多通信。通常的场景是一个内核态模块向多个用户态监听者发送消息。这种监听者被划分为多个不同的组。一条Netlink总线可以提供多个组，用户空间可以订阅到一个或者多个组来获取对应的信息。最多可以创建 个组。 Example scenario of unicast and multicast Netlink sockets 上图给出了Unicast和Multicast的图示。注意这里unicast是同步的，multicast是异步的。 5 Netlink消息格式 一般来说，Netlink消息对齐到32bit，其内部数据是host-byte order. 一个Netlink消息总由一段16bytes的header组成，header的格式为struct nlmsghdr（定义在&lt;include/linux/netlink.h&gt;中） Layout of a Netlink message header header包含如下字段： 消息长度（32bits, 包含header的长度） 消息类型（16bits）。消息类型的划分有两大类别：数据消息和控制消息。其中数据消息的类型取决于内核模块所允许的取值。控制消息类型则对所有Netlink子系统是一致的。控制消息的类型目前一共有四种。 NLMSG_NOOP: 不对对应任何实质操作，只用来检测Netlink总线是否可用 NLMSG_ERROR：该消息包含了错误信息 NLMSG_DONE：this is the trailing message that is part of a multi-part message. A multi-part message is composed of a set of messages all with the NLM_F_MULTI flag set. NLMSG_OVERRUN：没有使用 消息标识(16bits)。一些例子如下： NLM_F_REQUEST: 如果这个标识被设置了，表明这个消息代表了一个请求。从用户空间发往内核空间的请求必须要设置这个标识，否则内核子系统必须要回复一个invalid argument(EINVAL)的错误信息。 NLM_F_CREATE: 用户空间想要发布一个命令，或者创建一个新的配置。 NLM_F_EXCL: 通常和NLM_F_CREATE一起使用，用来出发配置已经存在的错误信息。 NLM_F_REPLACE: 用户空间想要替换现有配置。 NLM_F_APPEND: 想现有配置添加配置。这种操作一般针对的是有序的数据，如路由表。 NLM_F_DUMP: 用户应用想要和内核应用进行全面重新同步。这中消息的结果是一系列的multipart message。 NLM_F_MULTI: this is a multi-part message. A Netlink subsystem replies with a multi-part message if it has previously received a request from user-space with the NLM F DUMP flag set. NLM_F_ACK: 设置了这个标识后，内核会返回一个确认信息表明一个请求已经执行。如果这个flag没有返回，那么错误信息会作为sendmsg()函数的返回值同步返回。 NLM_F_ECHO: if this flag is set, the user-space application wants to get a report back via unicast of the request that it has send. 注意通过这种方式获取信息后，这个程序不会再通过事件通知系统获取同样的信息。 Sequence Number (32bits): The sequence number is used as a tracking cookie since the kernel does not change the sequence number value at all 可以和NLM_F_ACK一起使用，用户空间用来确认一个请求被正确地发出了。 Netlink uses the same sequence number in the messages that are sent as reply to a given request For event-based notifications from kernel-space, this is always zero. Port-ID (32bits): 包含了Netlink分配的一个数字ID。Netlink使用不同的port ID来确定同一个用户态进程打开的不同socket通道。第一个socket的默认port ID是这个进程的PID(Process ID)。在下面这些场景下，port ID为0： 消息来自内核空间 消息发送自用户空间，我们希望Netlink能够自动根据socket通道的port ID自动设置消息的port ID 以上是通用Netlink header格式。一些内核子系统会进一步定义自己的header格式，这样不同的子系统可以共享同一个Netlink socket总线。这种情形成为GetNetlink。 6 Netlink负载 6.1 Type-Length-Value(TLV)格式 An example of a hypothetical Netlink payload in TLV format Netlink的消息格式由TLV格式的属性组成。TLV属性分为Length, Type和Payload三部分。这种格式具有很强的可扩展性。在内核中，TLV属性的header定义如下: 12345678910111213/* * &lt;------- NLA_HDRLEN ------&gt; &lt;-- NLA_ALIGN(payload)--&gt; * +---------------------+- - -+- - - - - - - - - -+- - -+ * | Header | Pad | Payload | Pad | * | (struct nlattr) | ing | | ing | * +---------------------+- - -+- - - - - - - - - -+- - -+ * &lt;-------------- nlattr-&gt;nla_len --------------&gt; */struct nlattr &#123; __u16 nla_len; __u16 nla_type;&#125;; nla_type：属性的取值很大程度上取决于内核空间子系统定义。不过Netlink预先定了两个重要的比特位： NLA_F_NETSTED: 是否是嵌套属性。即在payload部分，以TLV的格式存储了更多的属性。 NLA_F_NET_BYTEORDER: payload内容的字节顺序（是否是network byte order(1)) nla_len: 注意，尽管payload部分会按照32bit进行对齐，这里的长度内容是不包含对齐补全的bit的。另外，这里的长度值包含了header。 7 Netlink错误消息 Layout of a Netlink error message Netlink提供了一种包含了Netlink error header的消息类型，其格式如上图所示。这个header定义为struct nlmsgerr (&lt;include/linux/netlink.h&gt;) 12345678910111213struct nlmsgerr &#123; int error; struct nlmsghdr msg; /* * followed by the message contents unless NETLINK_CAP_ACK was set * or the ACK indicates success (error == 0) * message length is aligned with NLMSG_ALIGN() */ /* * followed by TLVs defined in enum nlmsgerr_attrs * if NETLINK_EXT_ACK was set */&#125;; error: 错误类型。定义在error.h中，可以用perror()解析。 Netlink消息，为触发此错误的消息内容。 &gt; With regards to message integrity, the kernel subsystems that support Netlink usually report invalid argument (EINVAL) via recvmsg() if user-space sends a malformed message 8 GeNetlink 前文我们提到过GetNetlink了。这一技术是为了缓解Netlink总线数量过少的问题。GeNetlink allows to register up to 65520 families that share a single Netlink bus. Each family is intended to be equivalent to a virtual bus。其中，每个family通过一个唯一的string name and ID number来注册。其中string name作为主键，而ID number在不同的系统中可能不同。 9 Netlink开发 Netlink开发涉及到内核空间和用户空间双边的开发。Linux提供了很多帮助函数来见过Netlink开发中重复性的解析，验证，消息构建的操作。 9.1 用户空间开发 从用户空间这一侧来看，Netlink sockets实现在通用的BSD socket接口之上。因此，在用户空间开发Netlink和开发TCP/IP socket应用是很类似的。不过，同其他典型的BSD socket应用相比，Netlink存在以下的不同之处： Netlink sockets do not hide protocol details to user-space as other protocols to. 即，Netlink会直接处理原始数据本身，用户空间的开发也要直接处理原始数据格式的负载。 Errors that comes from Netlink and kernel subsystems are not returned by recvmsg() as an integer. Instead, errors are encapsulated in the Netlink error message. 唯一的例外是No buffer space error (ENOBUFS)，这个错误是表明无法将Netlink消息放入队列。标准的通用socket错误，同样也是从recvmsg()中以integer形式返回。 涉及用户空间的Netlink开发的有两个库：libnl和libmnl。这些库都是用C开发，用来简化Netlink开发。Netlink用户空间的进一步开发可以参考这两个库的例子和教程。 原始API的文档：https://www.systutorials.com/docs/linux/man/7-netlink/ 9.1.1 打开socket 下面来阐述一下用户空间的Netlink开发的重要事项。前面提到Netlink使用了BSD socket的接口。一般而言，创建socket的接口长这样子（socket接口）： 1int socket (int family, int type, int protocol); 第一个参数family是socket的大类。在开发TCP/IP应用的时候，这里总是AF_INET。而在Netlink中，这里总是设置为AF_NETLINK。 type可以选择SOCK_RAW或者SOCK_DGRAM。不过Netlink并不会区分这两者。 protocol为Netlink场景下定义的具体协议类型，现有的主要协议包括： 123456789101112131415161718192021222324#define NETLINK_ROUTE 0 /* Routing/device hook */#define NETLINK_UNUSED 1 /* Unused number */#define NETLINK_USERSOCK 2 /* Reserved for user mode socket protocols */#define NETLINK_FIREWALL 3 /* Unused number, formerly ip_queue */#define NETLINK_SOCK_DIAG 4 /* socket monitoring */#define NETLINK_NFLOG 5 /* netfilter/iptables ULOG */#define NETLINK_XFRM 6 /* ipsec */#define NETLINK_SELINUX 7 /* SELinux event notifications */#define NETLINK_ISCSI 8 /* Open-iSCSI */#define NETLINK_AUDIT 9 /* auditing */#define NETLINK_FIB_LOOKUP 10 #define NETLINK_CONNECTOR 11#define NETLINK_NETFILTER 12 /* netfilter subsystem */#define NETLINK_IP6_FW 13#define NETLINK_DNRTMSG 14 /* DECnet routing messages */#define NETLINK_KOBJECT_UEVENT 15 /* Kernel messages to userspace */#define NETLINK_GENERIC 16/* leave room for NETLINK_DM (DM Events) */#define NETLINK_SCSITRANSPORT 18 /* SCSI Transports */#define NETLINK_ECRYPTFS 19#define NETLINK_RDMA 20#define NETLINK_CRYPTO 21 /* Crypto layer */#define NETLINK_INET_DIAG NETLINK_SOCK_DIAG 我们可以直接使用NETLINK_USERSOCK供自己使用，或者自己定义一个新的量。 这里的protocol应当对应的是1.1.3中提到的总线。推理过程如下： 1. https://lwn.net/Articles/746776/ 这个链接中提叫的patch描述中称：This patch set aims to improve this situation by adding a new NETLINK_DESC bus with two commands 2. 在参考文献中谈论Netlink总线时，聚到了rtnetlink这个例子。根据rtnetlink的man page， #include &lt;asm/types.h&gt; #include &lt;linux/netlink.h&gt; #include &lt;linux/rtnetlink.h&gt; #include &lt;sys/socket.h&gt; rtnetlink_socket = socket(AF_NETLINK, int socket_type, NETLINK_ROUTE); 9.1.2 绑定socket地址 在打开了一个socket之后，我们需要为socket绑定一个本地地址。Netlink的地址格式如下： 1234567struct sockaddr_nl&#123; sa_family_t nl_family; /* AF_NETLINK */ unsigned short nl_pad; /* zero */ __u32 nl_pid; /* process pid */ __u32 ; /* mcast groups mask */&#125; nladdr; 这里的nl_pid可以通过getpid()这个函数来获取当前进程的pid来进行赋值 如果要在一个进程的多个线程中打开多个socket，可以用如下公式生成nl_pid： 1pthread_self() &lt;&lt; 16 | getpid(); struct socketadd_nl中的nl_groups为bit mask，代表了广播分组。当设置为0时代表单播消息。 确定地址后可以将其绑定到socket 12// fd为socket()返回的句柄bind(fd, (struct sockaddr*)&amp;nladdr, sizeof(nladdr)); 9.1.3 发送Netlink消息 为了发送Netlink消息，我们还需要创建一个struct socketaddr_nl作为发送的目的地址。如果消息是发送给内核的，那么nl_pid和nl_groups都要设置为0。如果这个消息是一个多播消息，那么需要设置nl_groups的对应比特。设置好目的地址之后，我们可以开始组装sentmsg()API需要的消息格式 123struct msghdr msg;msg.msg_name = (void *)&amp;(nladdr);msg.msg_namelen = sizeof(nladdr); 上面是socket的通用header，我们还需要设置Netlink自己的Message header这里struct nlmsghdr定义为： 12345678struct nlmsghdr&#123; __u32 nlmsg_len; /* Length of message */ __u16 nlmsg_type; /* Message type*/ __u16 nlmsg_flags; /* Additional flags */ __u32 nlmsg_seq; /* Sequence number */ __u32 nlmsg_pid; /* Sending process PID */&#125;; 在1.5中我们队各个字段的含义有了详细的介绍。按照对应的含义进行设置。 Netlink的消息由Netlink header和payload组成。因此我们需要一次性创建包含header和payload的内存块。 12345struct nlmsghdr *nlh = (struct nlmsghdr *)malloc(NLMSG_SPACE(MAX_PAYLOAD)); memset(nlh, 0, NLMSG_SPACE(MAX_PAYLOAD));nlh-&gt;nlmsg_len = NLMSG_SPACE(MAX_PAYLOAD);nlh-&gt;nlmsg_pid = getpid();nlh-&gt;nlmsg_flags = 0; 此处使用的NLMSG_SPACE宏定义是Netlink提供的工具，其定义如下： 12#define NLMSG_LENGTH(len) ((len) + NLMSG_HDRLEN)#define NLMSG_SPACE(len) NLMSG_ALIGN(NLMSG_LENGTH(len)) 这个宏做了两件事： 在长度上加上header的长度 将Payload进行32bit对齐 设置好负载内容后（负载数据段可以通过NLMSG_DATA(nlh)来获取），就可以发送了： 123456789struct iovec iov;iov.iov_base = (void *)nlh;iov.iov_len = nlh-&gt;nlmsg_len;msg.msg_iov = &amp;iov;msg.msg_iovlen = 1;sendmsg(fd, &amp;msg, 0); 9.1.3 接收Netlink消息 接收过程是类似的。接收程序需要提前分配一个足够的buffer来接收Netlink消息： 123456789101112struct sockaddr_nl nladdr;struct msghdr msg;struct iovec iov;iov.iov_base = (void *)nlh;iov.iov_len = MAX_NL_MSG_LEN;msg.msg_name = (void *)&amp;(nladdr);msg.msg_namelen = sizeof(nladdr);msg.msg_iov = &amp;iov;msg.msg_iovlen = 1;recvmsg(fd, &amp;msg, 0); 9.2 内核空间开发 9.2.1 创建新的Netlink协议类型 除非要复用内核既有Netlink协议类型，不然最好定义一个自己用的总线类型 1#define NETLINK_TEST 31 这个定义可以加在netlink.h中，或者放在模块的头文件里。 9.2.2 创建socket 在用户态，我们通过socket()接口来创建socket，而在内核中，我们使用如下的API： 12struct sock *netlink_kernel_create(struct net *net, int unit, struct netlink_kernel_cfg *cfg); net一般固定为全局变量init_net unit即为协议类型，我们在这里填上NETLINK_TEST cfg为Netlink的内核设置 123456789struct netlink_kernel_cfg &#123; unsigned int groups; unsigned int flags; void (*input)(struct sk_buff *skb); struct mutex *cb_mutex; int (*bind)(struct net *net, int group); void (*unbind)(struct net *net, int group); bool (*compare)(struct net *net, struct sock *sk);&#125;; 其中input是必须要设置的，是socket在接收到一个消息后的回调函数。回调函数的一个例子如下： 1234567891011121314151617181920212223242526272829303132333435static void hello_nl_recv_msg(struct sk_buff *skb)&#123; struct nlmsghdr *nlh; int pid; struct sk_buff *skb_out; int msg_size; char *msg = "Hello from kernel"; int res; printk(KERN_INFO "Entering: %s\n", __FUNCTION__); msg_size = strlen(msg); nlh = (struct nlmsghdr *)skb-&gt;data; printk(KERN_INFO "Netlink received msg payload:%s\n", (char *)nlmsg_data(nlh)); pid = nlh-&gt;nlmsg_pid; /*pid of sending process */ skb_out = nlmsg_new(msg_size, 0); if (!skb_out) &#123; printk(KERN_ERR "Failed to allocate new skb\n"); return; &#125; nlh = nlmsg_put(skb_out, 0, 0, NLMSG_DONE, msg_size, 0); NETLINK_CB(skb_out).dst_group = 0; /* not in mcast group */ strncpy(nlmsg_data(nlh), msg, msg_size); res = nlmsg_unicast(nl_sk, skb_out, pid); if (res &lt; 0) printk(KERN_INFO "Error while sending bak to user\n");&#125; 9.2.3 从内核向用户态程序发送消息 正如在用户空间的发送流程那样，发送消息需要先设置一个socket接收地址。设置接收地址需要通过NETLIN_CB宏访问skb从control buffer中存储的netlink参数（struct netlink_skb_parms）。 123456789struct netlink_skb_parms &#123; struct scm_creds creds; /* Skb credentials */ __u32 portid; __u32 dst_group; __u32 flags; struct sock *sk; bool nsid_is_set; int nsid;&#125;; 其中重要的参数时dst_group和flags。 如果要发送的数据包是单播数据包，发送方式为： 12NETLINK_CB(skb_out).dst_group = 0; /* not in mcast group */res = nlmsg_unicast(nl_sk, skb_out, pid); 这里的目标pid可以通过接收到的消息nlh-&gt;nlmsg_pid获取 如果要发送的数据包是多播： 1res = nlmsg_multicast(nl_sk, skbout, own_pid, group, flags); 此处的own_pid是传输自己的pid来纺织消息传递给自己。因此内核态在这里填写0 NETLNK_CB(skb_out).dst_group会在发送函数内设置。 10 Further Reading Kernel Korner - Why and How to Use Netlink Socket https://gist.github.com/arunk-s/c897bb9d75a6c98733d6]]></content>
      <categories>
        <category>kernel</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用iptables和route来建立起Linux的网关设置]]></title>
    <url>%2Fposts%2F32824%2F</url>
    <content type="text"><![CDATA[本文翻译自：Setting Up Gateway Using iptables and route on Linux。 网络资源的分享是非常重要的，而建立起一个网关来进行网络分享是一个比较好的解决方案。在Linux系统中创建和设置网关非常简单，成本低廉，而且性能可靠。 1 Linux网络设置 假定我们要处理的Linux有如下的配置： NIC1: eth0, ip: 192.168.0.1，连接到局域网(LAN) NIC2: eth1, ip: 1.2.3.4, 连接到公网 网络拓扑图 现在我们希望将分享这台机器的网络连接给LAN网络上的其他电脑(ip: 192.168.0.0/16) 2 设置网关 下面提到的所有操作都需要root权限来执行。 2.1 操作IP路由表 1234ip route add 192.168.0.0/16 dev eth0# or# route add -net 192.168.0.0/16 dev eth0 2.2 启用Linux IP 转发(IP Forwarding) 1234sysctl -w net.ipv4.ip.forward=1# or# echo 1 &gt; /proc/sys/net/ipv4/ip_forward 你也可以直接编辑/etc/sysctl.conf来持久化这一设置： 1net.ipv4.ip_forward = 1 2.3 通过iptables设置源地址映射(SNAT) 将（其他电脑发送的）包的源地址修改为网关的源地址。iptables会自动将响应包的目的地址替换成正确的IP地址。 1iptables -t nat -A POSTROUTING ! -d 192.168.0.0/16 -o eth1 -j SNAT --to-source 1.2.3.4 除了使用SNAT，也可以使用MASQUERADE: 1iptables -t nat -A POSTROUTING ! -d 192.168.0.0/16 -o eth1 -j MASQUERADE 注意，对于静态IP而言，SNAT的方式要更好一些。根据iptables man page: This target is only valid in the nat table, in the POSTROUTING chain. It should only be used with dynamically assigned IP (dialup) connections: if you have a static IP address, you should use the SNAT target. Masquerading is equivalent to specifying a mapping to the IP address of the interface the packet is going out, but also has the effect that connections are forgotten when the interface goes down. This is the correct behavior when the next dialup is unlikely to have the same interface address (and hence any established connections are lost anyway). 你还需要确保其他iptables不会阻拦对应的连接。如果你有这方面的问题，可以尝试： 123iptables -Fiptables -t nat -Fiptables -t nat -A POSTROUTING ! -d 192.168.0.0/16 -o eth1 -j SNAT --to-source 1.2.3.4 上面的代码可以允许所有的接入连接。不过这会存在一些安全性问题。 3 客户端配置 客户端配置主要是把网关设置成192.168.0.1。例如如下命令 1234ip route add default via 192.168.0.1 dev eth0# or# route add default gw 192.168.0.1 eth0]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>linux</tag>
        <tag>iptables</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派上搭建视频流服务的方法尝试]]></title>
    <url>%2Fposts%2F28769%2F</url>
    <content type="text"><![CDATA[最近实验需要在树莓派上搭建一个简单的视频服务，而且，希望画质一定的情况下，消耗的带宽越少越好。关于带宽的问题，其实开始并没有考虑太多，但是在尝试用uv4l工具创建mpeg流的时候发现，尽管分辨率很低（720p）不到，需要的数据率却达到了大约5MB/s。我们待测试的通信层不具备这样高的传输传输能力。因此需要想办法把数据率降下来。综上，我们需要产生一个编码后的视频流，如H264。 幸运的是我发现了h264-live-player这个项目。这个项目是基于Node.js的工程，利用Websocket传输H264编码数据，在客户端用Broadway解码，而服务端的H264流通过raspivid产生。 在接下来的部分，我先简要介绍一下Raspivid的使用，然后介绍一下h264-live-player的情况。如果只是想上手使用，可以直接拉到最后。 Raspivid raspivid是一个在树莓派上用于捕捉视频数据的命令行工具。在h264-live-player中，lib/raspivid.js文件调用了这个命令来产生H264的视频流。在这个文件中使用的命令是： 1raspivid -t 0 -o - -w WIDTH -h HEIGHT -fps FPS 其中，-t 0表示捕捉的时间不限。-o -表示将H264流输出到stdout。后面的-w, -h, -fps则分别是制定画面的宽高还有帧率。在raspivid命令产生H264流后，h264-live-player会通过一系列的回调函数通过Websocket将H264数据发送给前端。 h264-live-player 关键代码解析。 注意，原作者的工程里面存在一些问题，其中重点是客户端刷新后视频流解析会出现异常。我在我的fork中修复了这些问题，还做了一些其他的改进。因此这里的介绍都以我的fork中的代码为准。 后端 首先还是要看lib/raspivid.js这个文件。RpiServer这个类继承于Server，Server中预留了get_feed给子类实现，器作用是产生视频流。 12345678910111213141516get_feed() &#123; if (this.streamer !== undefined) &#123; this.streamer.kill(); &#125; var msk = "raspivid -t 0 -o - -w %d -h %d -fps %d"; var cmd = util.format(msk, this.options.width, this.options.height, this.options.fps); console.log(cmd); var streamer = spawn('raspivid', ['-t', '0', '-o', '-', '-w', this.options.width, '-h', this.options.height, '-fps', this.options.fps, '-pf', 'baseline']); streamer.on("exit", function(code)&#123; if (code) &#123; console.log("Failure", code); &#125; &#125;); this.streamer = streamer; return streamer.stdout;&#125; 这个函数返回的是raspivid子进程的stdout流，也即H264流。 然后我们来看lib/_server.js文件中_Server的定义。注意start_feed这个函数： 12345678910start_feed() &#123; if (this.readStream) &#123; this.readStream.end(); &#125; var readStream = this.get_feed(); this.readStream = readStream; readStream = readStream.pipe(new Splitter(NALseparator)); readStream.on("data", this.broadcast);&#125; 这个函数在客户端发起播放流的请求后调用。这里Server调用子类实现的get_feed函数获取视频流，然后视频流上注册data事件的回调函数。 这里需要解释一下readStream = readStream.pipe(new Splitter(NALseparator));这行代码。这里我们为视频流增加了一个Splitter，生成Splitter的参数为一个Buffer。 1const NALseparator = new Buffer([0,0,0,1]);//NAL break 在H264规范中，帧中间的会插入00 00 00 01作为帧间隔标识。这里插入的Splitter的作用是，在每次遇到NALseperator形式的字符流时，将之前收到的数据作为一个chunk，调用data事件的回调函数。 再来看看broadcast函数。在视频流收到一定的函数时会调用这个函数： 12345678910111213141516broadcast(data) &#123; this.wss.clients.forEach(function(socket) &#123; if (socket.readyState !== WebSocket.OPEN) &#123; return; &#125; if(socket.buzy) return; socket.buzy = true; socket.buzy = false; socket.send(Buffer.concat([NALseparator, data]), &#123; binary: true&#125;, function ack(error) &#123; socket.buzy = false; &#125;); &#125;);&#125; 这里的代码非常简单，核心就是通过socket.send将数据发送给客户端。注意这里的数据的内容是Buffer.concat([NALseperator, data])。这是因为Splitter会截断分隔符。 前端 前端的代码集中在vendor/wsavc/index.js中。重点是下面这段代码： 12345678910111213141516171819202122232425262728293031323334var framesList = [];this.ws.onmessage = (evt) =&gt; &#123; if(typeof evt.data == "string") return this.cmd(JSON.parse(evt.data)); this.pktnum++; var frame = new Uint8Array(evt.data); //log("[Pkt " + this.pktnum + " (" + evt.data.byteLength + " bytes)]"); //this.decode(frame); framesList.push(frame);&#125;;var shiftFrame = function() &#123; if(!running) return; if(framesList.length &gt; 10) &#123; log("Dropping frames", framesList.length); framesList = []; &#125; var frame = framesList.shift(); if(frame) &#123; this.decode(frame); &#125; requestAnimationFrame(shiftFrame);&#125;.bind(this);shiftFrame(); 在接收到服务器发送的数据时，数据会被转换成Uint8Array，然后压入到一个队列中。而在shiftFrame这个函数会周期性的调用，从队列中取出数据进行解码。解码后会触发Broadway解码器的onPictureDecoded回调，在这个回调中canvas中的图像会被更新。 h264-live-player的部署和使用 安装Node.js到树莓派 SSH登录到树莓派，然后运行 12345sudo apt-get updatesudo apt-get dist-upgradecurl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash -sudo apt-get install -y nodejs 使用下面的命令来验证安装成功： 1234$ node -vv8.14.1$ npm -v # npm是Node.js的包管理器6.4.1 安装h264-live-player 123456# 下载仓库git clone git@gitlab.vlionthu.com:tdma-uav/raspberry-pi-video-stream.git playercd player# 安装依赖npm install 运行 12cd playernode server_rpi.js 上面的运行方法会在terminal中启动服务脚本。如果要这个程序常驻后台，可以尝试使用pm2 12345678910sudo npm install -g pm2 # 安装pm2，这里的-g表示安装到全局环境下cd player # cd to player folder# 启动pm2 start ./server-rpi.js \ -i 1 \ --name "video-stream" \ -o "/home/pi/player/stdout.log" \ -e "/home/pi/player/stderr.log" 在网页端访问摄像头 1http://rasp_ip:8080 可以通过添加/?r的query参数来上下翻转画面。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>折腾</tag>
        <tag>树莓派</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dependency Injection in Node.js | 2016]]></title>
    <url>%2Fposts%2F30333%2F</url>
    <content type="text"><![CDATA[在上一篇文章中我们初步讨论的Dependency Injection的一些理念。在这篇文章中，我翻译了awilix模块的作者Jeff Hansen的文章：Dependency Injection in Node.js - 2016 edition。原文包含三个部分，我在这里直接整理成为一篇完整的文章。 在翻译中我以传到核心思想为主，故不会太拘泥于一些细节问题。对于一些插科打诨的话，如果不是特别有意思的话，也许不会翻译。 作者Jeff Hansen Part I 在2015年，RisingStack写了一篇关于Dependency Injection(缩写为DI)的文章，解释了什么是DI，以及如何手动实现。如果你还没有阅读这篇文章，我强烈建议你先阅读以下那篇文章。这样你对于本文的一些概念会有更加清晰的理解。 这里提到的RisingStack的文章的中文版可以在我的博客里找到: Node.js | Dependency Injection。 在这一系列文章中，我会扩展一下手动实现的DI，为什么这种做法是糟糕的，以及我们如何最终能够让DI的现实变得优雅 -- 甚至比require/imports方式要更好。我将要证明Node中使用DI可以不像之前的做法那样沉闷。这都要归功于在ES6中引入的新特性：Proxies（直译就是代理）。 我100%肯定作为一个Node的开发者，你会见过某种形式的DI。借鉴一下RisingStack文章中的例子: 1234567var express = require('express')var app = express()var session = require('express-session')app.use(session(&#123; store: require('connect-session-knex')&#125;)) session needs a store! - 这种存储的具体实现方式是多样的 ：redis，MySQL。Express本身并不关心背后的实现。我们来看下面的这个例子 -- 非DI实现： 1234567import db from '../mydatabase'export default &#123; getToDos: () =&gt; &#123; return db.query('select * from todos') &#125;&#125; 在这个例子中我们直接导入了db模块，因此这个文件就依赖于db模块在磁盘上的具体存储位置，以及依赖于特定的是方式。在大多数场景下这并不算一个大问题。不过这种方式让测试变得更加困难 -- 不至于无法进行测试，但是无论如何都变得更加地困难了。另外，这个模块还假定db模块已经准备好了（例如：数据库连接已经建立起来了）。 如果我们进一步将上面的代码转化成为对于测试友好的DI实现方式： 1234567export default function makeTodosService (&#123; db &#125;) &#123; return &#123; getTodos: () =&gt; &#123; return db.query('select * from todos') &#125; &#125;&#125; 那么上面两个例子有什么区别呢？在下面的DI实现的例子中我们不是export出一个对象，而是export出一个生成这种对象的函数。这个函数同时阐明了为了创建此种对象所需要的依赖。 如果你熟悉在其他语言中的DI实现，如Java, C#，还有PHP。下面这个使用ES6的类实现的例子可能更受你喜欢一些： 12345678export default class TodosService &#123; constructor(&#123; db &#125;) &#123; this.db = db &#125; getTodos() &#123; return this.db.query('select * from todos') &#125;&#125; 不过从个人角度我还是更喜欢函数的方法：不用担心this的上下文的问题。 测试上面这个基于DI的例子非常简单 -- 你不再需要担心对require进行修修补补来替代数据库模块从而连接到测试数据库。 12345678910111213describe('Todo Service', function () &#123; beforeEach(() &#123; subject = makeTodosService(&#123; db: testDatabaseSomehow &#125;) &#125;) it('work', async function() &#123; const todos = await subject.getTodos( expect(todos.length).to.equal(3) ) &#125;)&#125;) Part II 在这个部分我们来构思一个Todo APP。 在我们开始折腾API框架和其他乱七八糟的部分之前，我们来大致搭建一下项目的骨架 -- the service and data access。为了可读性的考虑我在这里使用了ES7的async-await机制。 然我们来开始我们的Todos Service - 这个模块来负责处理所有的业务逻辑。 我会在下面的代码片段那种使用不同的风格（函数式或者是面向对象的）来证明，这些具体的代码风格并不本质，你可以使用任何你喜欢的方式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// todosService.jsimport assert from 'assert'// Using object destructring to make it look goodexport function makeTodosService (&#123; // "repository" is a fancy term to describe an object // that is used to retrieve data from a datasource - the actual // data source does not matter. Could be a database, a REST API, // or some IoT things like sensors or what ever todosRepository, // We also want info about the user that is using the service, // so we can restrict access to only their own todos. currentUser&#125;) &#123; assert(todosRepositry, 'opts.todosRepository is required.') assert(currentUser, 'opts.currentUser is required.') return &#123; // Gets todos for the current user getTodos: async(query) =&gt; &#123; const todos = await todosRepository.find(&#123; // can be ALL, INCOMPLETED, COMPLETED filter: query.filter, userId: currentUser.id &#125;) return todos &#125;, createTodo: async (data) =&gt; &#123; const newTodo = await todosRepository.create(&#123; text: data.text, userId: currentUser.id, completed: false &#125;) return newTodo &#125;, updateTodo: async (todoId, data) =&gt; &#123; const todo = await todosRepository.get(todoId) // verify that we are allowed to modify this todo if (todo.userId !== currentUser.id) &#123; throw new Error('Forbidden') &#125; const updatedTodo = await todosRepository.update(todoId, &#123; text: data.text, completed: data.completed &#125;) return updatedTodo &#125;, deleteTodo: async (todoId) =&gt; &#123; const todo = await (todoId) const todo = await todosRepository.get(todoId); if (todo.userId !== currentUser.id) &#123; throw new Error('Forbidden') &#125; await todoRepository.delete(todoId) &#125; &#125;&#125; 代码有点长，但是并没有什么太fancy的东西。我们并没有依赖于外部库（除了自带的assert模块用于输入检验）。不过，我们导出的函数其实有两个依赖： todosRepository -- 给予todos数据库访问的对象（我们并不关心具体的实现细节）。 currentUser -- 正在使用这个服务的用户。注意我们并不知道这个对象从何处生成，也不关心这些细节。 我们继续往下走，给出todos repository的一个不错的实现方式： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253// todosRepository.js// Let's do an in-memory implementation for now.const _todos = []export default class TodosRepository &#123; // Making all methods async makes them return promises! async find(query) &#123; const filtered = _todos.filter((todo) =&gt; &#123; // Check the user id if (todo.userId !== query.userId) &#123; return false; &#125; // check the filter if (query.filter === "COMPLETED") &#123; return todo.completed === true &#125; if (query.filter === "INCOMPLETED") &#123; return todo.completed === false &#125; return true &#125;) return filtered &#125; async get(id) &#123; const todo = _todos.find(x =&gt; x.id === id) return todo &#125; async create(data) &#123; const newTodo = &#123; id: Date.now(), text: data.text, userId: data.userId, completed: data.completed &#125; _todos.push(newTodo) return newTodo &#125; async update(id, data) &#123; const todo = await this.get(id) Object.assign(todo, data) return todo &#125; async delete(id) &#123; const todo = await this.get(id) _todos.splice(todo, 1) &#125;&#125; 上面的代码只是todos repository的一个in-memory实现。任何时候我们准备好的时候，可以替换成MySQL，Rethink，MongoDB等存储后端，只要具有同形式的API就可以了。Typescript和Flow在这里可以发挥很大的作用。 把系统粘合起来 在我们进入到RESTful API之前，让我们先把上门两个模块在测试中整合起来。下面的方法被称为“穷人式的DI”，不过别担心，在后面我们会展示更加fancy的做法。 1234567891011121314151617181920212223242526272829303132333435363738394041import makeTodosService from './todosService'import TodosRepository from './todosRepository'describe('Todos System', function () &#123; it('works', async function() &#123; // This is how DI is done manually const todosService = makeTodosService(&#123; todosRepository: new TodosRepository(), // Let's fake it til we make it! currentUser: &#123; id: 123, name: 'Jeff' &#125; &#125;) // Todos Service already knows who's creating it! const created = await todosService.create(&#123; text: 'Write Medium article' &#125;) expect(created.userId).to.equal(123, 'user id should match currentUser') const todos = await todosService.getTodos(&#123; filter: 'ALL' &#125;) expect(todos.length).to.equal(1) await todosService.update(todo.id, &#123; completed: true &#125;) const incompleteTodos = await todosService.getTodos(&#123; filter: 'INCOMPETED' &#125;) expect(incompleteTodos.length).to.equal(0) const completedTodos = await todosService.getTodos&#123; filter: 'COMPLETED' &#125; expect(completedTodos.length).to.equal(1) &#125;)&#125;) 看到上面的代码你可能会想：“这里的代码不是已经知道了两个模块了么？”。没错，在一个真实的APP中（下文中我们会提及），还是需要有一个知道所有使用的模块的单一置信源（source of truth）。在我们倒腾DI黑科技的时候，我们把这个部分的代码称为：组合根（The Composition Root，译者按：这个名字放在中文下太绕口了）。这是在应用中将所有的模块胶合在一起的地方。Composition Root可能长这个样子： 12345678910111213141516cosnt currentUser = &#123; id: 123, name: 'Jeff'&#125;const todoRepository = new TodosRepository()const todosService = makeTodosService(&#123; todosRepository, currentUser&#125;)export default &#123; todosService, todosRepository&#125; 看到这个代码，我知道你一定在想：“我现在还不知道这个currentUser具体是指哪个用户呢！我要构建的是一个Web应用，这种方法根本没用！”。你说的对。有两种方法来手动解决这个问题： 为所有需要currentUser的方法手动传递这个参数 -- 这也太坑了。 将实例化过程推迟到你拥有了所有的数据之后（译者按：即在已知了currentUser之后再调用工厂函数初始化todosService）-- 这种方法也不好，你需要在很多的地方重复地进行实例化。 为了进一步解释以下第二点，下面给出一个例子。例子中使用到了Koa Router 123456789101112131415161718192021const router = new KoaRouter()router.get("/todos", async (ctx) =&gt; &#123; const todosService = makeTodosService(&#123; todosRepository: new TodosRepository(), currentUser: ctx.state.user &#125;) ctx.body = await todosService.getTodos(ctdx.request.query) ctx.status = 200&#125;)router.post("/todos". async (ctx) =&gt; &#123; const todosService = makeTodosService(&#123; todosRepository: new TodosRepository(), currentUser: ctx.state.user &#125;) // ...&#125;)// and so on 这还只是涉及到两个模块。想象一下要是需要处理10个模块（这还只是对于小型的应用）。没错，第二种方法也是很糟糕的。 Part III Angular曾经是在JavaScript世界中第一个引入了DI的大型框架。他们的做法是使用函数的字符串表达来提取使用的模块名称。在当时这是唯一的做法。 有一些人尝试将DI功能从Angular中独立出来做成一个独立模块。但是问题是，大多数DI模块要求你的所有代码都要围绕着特定的DI系统来开发，这位违背了DI设计理念的初衷。 DI的作用是减少程序模块之间的耦合程度，提高代码的可维护性。在这种目标下，DI系统的设计应当尽可能减少对于其它业务代码的影响。如果为了使用DI要对业务代码结构进行大范围的改动的话就得不偿失了。 我们希望能够在不改动我们的service和repository模块的情况下使用DI机制。 关于Awilix - The DI container you deservce 如果你不知道DI容器是什么，下面是一个简短的解释。DI容器的功能是将系统中的模块整合起来，从而让开发者不再需要太关注这些DI的实现细节问题。在前面两个Part中我们给出的示例代码：实例化services和repositories，确保service获取repository对象。这些工作都将由DI容器来完成。 Awilix就是这样的一个容器，其实现是基于ES6 Proxies，这一意味着不再需要对函数的参数进行字符串解析。 现在让我们回到开头的todo应用。让我们使用Awilix来将各个模块整合起来。我们将会使用Koa 2来实现Web API。先让我们来安装这些依赖： 1npm install -S koa@next koa-router@next awilix awilix-koa 这里的awilix-koa模块让Awlix和Koa的搭配更加易用。现在让我们从composition root开始 123456789101112131415161718192021// configureContainer.jsimport &#123; createContainer, asClass, asFunction &#125; from 'awilix'import makeTodosService from './todosService'import TodosRepository from './todosRepository'export default function configureContainer () &#123; const container = createContainer() // Ordering does not matter container.register(&#123; // Notice the scoped() at the end - this signals // Awilix that we gonna want a new instance per "scope" todosService: asFunction(makeTodosService).scoped(), // We only want a single instance of this for the apps // lifetime (it does not deal with user context) // so we can reuse it! todosRepository: asClass(TodosRepository).singliton() &#125;) return container&#125; 这看起来已经非常不错了。不过如果你有超过100个服务需要注册，Awilix提供了自动化的工具。 现在让我们来配置Koa应用 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// server.jsimport Koa from 'koa'import KoaRouter from 'koa-router'import &#123; asValue &#125; from 'awilix'import &#123; scopePerRequest, makeInvoker &#125; from 'awilix-koa'import configureContainer from './configureContainer'const app = new Koa()const router = new KoaRouter()const container = configureContainer()// This installs a scoped container into our// context - we will use this to register our current userapp.use(scopePerRequest(container))// Let's do that now!app.use((ctx, next) =&gt; &#123; ctx.state.container.register(Value)(&#123; // Imagine some auth middleware somewhere... // This makes currentUser available to all services currentUser: ctx.state.user &#125;) return next()&#125;)// Now our handlers will be able to resolve a todos service// using DI!// P.S: be a good dev and use multiple files. ;)const todosAPI = (&#123; todosService &#125; =&gt; &#123; return &#123; getTodos: async (ctx) =&gt; &#123; const todos = await todosService.getTodos(ctx.request.query) ctx.body = todos ctx.status = 200 &#125;, createTodos: async (ctx) =&gt; &#123; const todo = await todosService.createTodo(ctx.request.body) ctx.body = todo ctx.status = 201 &#125;, updateTodo: async (ctx) =&gt; &#123; const updated = await todosService.updateTodo( ctx.params.id, ctx.request.body ) ctx.body = updated, ctx.status = 200 &#125;, deleteTodo: async (ctx) =&gt; &#123; await todosService.deleteTodo( ctx.params.id, ctx.request.body ) &#125; &#125;&#125;)// Awilix magic will run the above function// every time a request comes in, so we have// a set of scoped services per requestconst api = makeInvoker(todosAPI)router.get('/todos', api('getTodos'))router.post('/todos', api('createTodos'))router.patch('/todos/:id', api('updateTodo'))router.patch('/todos/:id', api('deleteTodo'))app.use(router.routes())app.listen(1337) 上面的代码还只是一个简单的雏形，不过你现在已经有了构建大规模项目的基础。 结论 DI是一个很有用的东西，不过手动去实现DI是一件糟心的事情。这也是Awilix这种DI容器扮演作用的地方。]]></content>
      <categories>
        <category>形而上</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node.js | Dependency Injection]]></title>
    <url>%2Fposts%2F61013%2F</url>
    <content type="text"><![CDATA[Dependency Injection这个概念是我之前在实习的时候做Java开发的时候接触的。Dependency Injection可以大大降低模块之间的耦合度，提高系统的可扩展性和鲁棒性，不过这个概念对于新人来说理解起来还是存在比较大的障碍。由于当时实习的时间比较短，对于这个概念我并没有吃透。这次学习Node.js的时候，又在awilix这个库里面遇到了这个概念。以此为契机就来好好学习一些Dependency Injection和其后的设计逻辑与方法。 下面的内容翻译自：Dependency Injection in Node.js。这篇文章浅显地介绍了Dependency Injection的基本理念。选择这篇文章是因为我在阅读awilix模块作者关于Dependency Injection的系列文章中时，作者在开篇提议阅读此文。 不过这篇文章毕竟是2015年的文章，在js的一些语法和模块细节上和今时今日的有些不同，但是并不妨碍我们对于其核心理念的理解。 使用Dependency Injection的理由 解耦 (Decoupling) Dependency Injection使你的模块耦合度降低，从而提升代码的可维护性。 更简单的单元测试 比起需要硬编码的依赖关系，你可以将依赖关系传输进入你要用的模块。在大多数场合下使用这种范式你不必要使用proxyquire这样的模块。 这一段作者写的比较含糊。其实意思是在使用Dependency Injection场景下，我们在独立测试一些单元功能的时候，对于其他模块可以通过注入Mock对象，从而将待测试的模块独立出来进行测试。 更快速的开发 在使用了Dependency Injection的场景下，在接口定义好了以后，开发会更加容易，Merge conflict会更少。 如何在Node.js中使用Dependency Injection 下面我们来看看如何在不适用Dependency Injection的前提下开发应用，然后看看如何进行转化。 不使用Dependency Injection的例子 下面是一段简单的没有使用Dependency Injection的代码： 12345678// team.jsvar User = require('./user');function getTeam(teamId) &#123; return User.find(&#123;teamId: teamId&#125;);&#125;module.exports.getTeam = getTeam; 对应的测试可能是： 1234567891011121314151617// team.spec.jsvar Team = require('./team');var User = require('/user');describe('Team', function() &#123; it('#getTeam', function* () &#123; var users = [&#123;id: 1, id: 2&#125;]; this.sandbox.stub(User, find, function() &#123; return Promise.resolve(users); &#125;) var team = yield team.getTeam(); expect(team).to.eql(users); &#125;)&#125;) 在上面的代码中我们做的是创建了一个名为team.js的模块，该模块可以返回属于一个team的用户列表。为了实现这一功能，我们导入User模块，然后我们再调用其find方法返回用户列表。 看起来不错，是吗？但是当我们需要进行测试时，我们必须要使用sinon的test stubs. 在测试文件中，我们需要引入User模块，为其stub一个find方法。注意，我们在这里要使用sandbox功能，这样我们不需在测试完成后回复find的原函数。 注意：如果原始对象使用了Object.freeze，那么stubs将不会起作用。 使用Dependency Injection的例子 123456789101112// team.jsfunction Team(options) &#123; this.options = options;&#125;Team.prototype.getTeam = function(teamId) &#123; return this.options.User.find(&#123;teamId: teamId&#125;);&#125;function create(options) &#123; return new Team(options);&#125; 你可以使用下面的这个文件来进行测试 12345678910111213141516171819202122// team.spec.jsvar Team =- require('./team');describe('Team', function() &#123; it('#getTeam', function* () &#123; var users = [&#123;id: 1, id: 2&#125;]; var fakeUser = &#123; find: function() &#123; return Promise.resolve(users); &#125; &#125; var team = Team.create(&#123; User: fakeUser &#125;) var team = yield team.getTeam(); expect(team).to.eql(users); &#125;);&#125;); 那么，使用了Dependency Injection的版本同之前的版本有什么区别呢？首先你可能注意到的是这里使用了工厂模式：我们使用这种设计模式来将options/dependencies inject到新创建的对象中 - 这里是我们注入User模块的方法。 在测试文件中我们还需要创建一个fake model来代表User模块，然后将这个伪造的模块传递给工厂函数。很简单，不是吗？ Dependency Injection in Real Projects 你可以在非常多的开源项目中发现Dependency Injection的例子。例如，你在日常工作中常常用到的Express/Koa的大部分中间件都使用了这种技术。 Express Middlewares 1234567var express = require('express');var app = express();var session = require('express-session');app.use(session(&#123; store: require('connect-session-knex');&#125;)) 上面的代码片段使用了基于工厂模式的Dependency Injection：对应session中间件我们传递了一个connect-session-knex模块。这个模块需要实现session模块调用需要的借口。 在这个例子中，connect-session-knex模块需要实现下面的方法： store.destroy(sid, callback) store.get(sid, callback) store.set(sid, session, callback) Hapi plugins Dependency Injection的概念还可以在Hapi中找到。下面的例子中，handlebars模块被作为view engine注入给Hapi使用: 1234567server.views(&#123; engines: &#123; html: require('handlebars`) &#125;, relativeTo: __dirname, path: 'templates'&#125;)]]></content>
      <categories>
        <category>形而上</category>
      </categories>
      <tags>
        <tag>nodejs</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab|安装-迁移-删除]]></title>
    <url>%2Fposts%2F25664%2F</url>
    <content type="text"><![CDATA[1 安装 1.1 Omnibus package installation 这是Gitlab官网推荐的安装方式。官网文档链接位于Gitlab Installation。不过，现在直接去官网默认给出的是企业版，即gitlab-ee的安装方式（付费的），而个人版其实用gitlab-ce就够了。gitlab-ce安装方式如下 1.1.1 安装并配置依赖 1sudo apt-get install -y curl openssh-server ca-certificates 然后安装Postfix来启动邮件提醒功能。（如果你使用了第三方的邮件服务，可以跳过这一步并且参照配置外部SMTP服务器）。 1sudo apt-get install -y postfix 在接下来的配置过程中，选择'Internet Site'选项。使用你的服务器的域名来作为'mail name'。如果还有后续的选项，输入Enter直至安装完成。 1.1.2 安装Gitlab-EE 添加Gitlab Package仓库： 1curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bash 注意这里安装的是CE版本，故是gitlab-ce，企业版对应的是gitlab-ee 接下来安装Gitlab： 1sudo EXTERNAL_URL="http://gitlab.example.com" apt-get install gitlab-ce 这里的EXTERNAL_URL是你的Gitlab服务要使用的域名。如果你只使用http，或者后续要使用已有的Nginx，可以在这里使用http。如果使用https，gitlab会调用Let's encrtpy的服务为你的网站添加ssl证书。 1.1.3 登录Gtilab 进入你在安装阶段的域名，你会被重定向到密码重置界面。在这个页面你要设置管理员账户的密码，然后回到登录界面。在这个登录界面，使用root用户名和上一步设置的密码登录。 1.2 使用已有的Nginx 这个章节我们参考官方文档给出使用已有的Nginx的方法。 1.2.1 禁用Gitlab自带的Nginx 编辑/etc/gitlab/gitlab.rb文件，设置 1nginx['enable'] = false 1.2.2 设置外部服务器的用户 这一步是为了保证外部服务器用户能够访问gitlab。使用Nginx时，可以通过/etc/nginx/nginx.conf文件查看到nginx用户。一般情况下这个用户名是www-data。修改/etc/gitlab/gitlab.rb： 1web_server['external_users'] = ['www-data'] 然后使用sudo gitlab-ctl reconfigure来使得更改生效。 1.2.3 Trusted proxies 如果你的反向代理服务器和gitlab不是在同一台机器上，那么你还需要设置Trusted proxies。 1gitlab_rails['trusted_proxies'] = ['192.168.1.0/24', '192.168.2.1', '2001:0db8::/32'] 1.2.4 Nginx示例配置文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# gitlab socket 文件地址upstream gitlab &#123; # 7.x 版本在此位置 # server unix:/var/opt/gitlab/gitlab-rails/tmp/sockets/gitlab.socket; # 8.0 位置 server unix:/var/opt/gitlab/gitlab-rails/sockets/gitlab.socket;&#125;server &#123; listen *:80; server_name gitlab.example.com; # 请修改为你的域名 server_tokens off; # don't show the version number, a security best practice root /opt/gitlab/embedded/service/gitlab-rails/public; # Increase this if you want to upload large attachments # Or if you want to accept large git objects over http client_max_body_size 250m; # individual nginx logs for this gitlab vhost access_log /var/log/gitlab/nginx/gitlab_access.log; error_log /var/log/gitlab/nginx/gitlab_error.log; location / &#123; # serve static files from defined root folder;. # @gitlab is a named location for the upstream fallback, see below try_files $uri $uri/index.html $uri.html @gitlab; &#125; # if a file, which is not found in the root folder is requested, # then the proxy pass the request to the upsteam (gitlab unicorn) location @gitlab &#123; # If you use https make sure you disable gzip compression # to be safe against BREACH attack proxy_read_timeout 300; # Some requests take more than 30 seconds. proxy_connect_timeout 300; # Some requests take more than 30 seconds. proxy_redirect off; proxy_set_header X-Forwarded-Proto https; proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Frame-Options SAMEORIGIN; proxy_pass http://gitlab; &#125; # Enable gzip compression as per rails guide: http://guides.rubyonrails.org/asset_pipeline.html#gzip-compression # WARNING: If you are using relative urls do remove the block below # See config/application.rb under "Relative url support" for the list of # other files that need to be changed for relative url support location ~ ^/(assets)/ &#123; root /opt/gitlab/embedded/service/gitlab-rails/public; # gzip_static on; # to serve pre-gzipped version expires max; add_header Cache-Control public; &#125; # error_page 502 /502.html;&#125; 2 迁移 2.1 备份 迁移首先要做的是备份。在git学习------&gt; Gitlab如何进行备份恢复与迁移？这篇文章中详细讲述了备份的问题。我们这里介绍的是最为直接和简单的步骤。如果要更加详细的信息请阅读这篇参考。 备份使用如下命令： 1gitlab-rake gitlab:backup:create 备份会生成在/var/opt/gitlab/backups目录下。名称类似于1502357536_2017_08_10_9.4.3_gitlab_backup.tar。下面这些配置信息，没有包含在backup文件里面。需要手动迁移。 /etc/gitlab/gitlab.rb 配置文件须备份 /var/opt/gitlab/nginx/conf nginx配置文件 /etc/postfix/main.cfpostfix 邮件配置备份 备份命令的执行 2.2 在目标机器上安装gitlab 迁移过程中要求源机器和目标机器上安装的gitlab版本是相同的。如果不同，其实最好的做法是先将源机器上的gitlab升级到最新的版本。然后再生成备份。 如何查看Gitlab版本 2.3 上传备份 使用scp命令将备份文件上传到目标机器的/var/opt/gitlab/backups。 如果scp上传目标文件文件夹的权限不够，可以先上传到自己的home目录下，然后ssh登录到服务器使用sudo进行移动。 2.4 应用备份文件 首先为了避免潜在的权限问题，将备份文件的权限设置为777 1chmod 777 1502357536_2017_08_10_9.4.3_gitlab_backup.tar 然后停止gitlab的相关数据连接服务 12gitlab-ctl stop unicorngitlab-ctl stop sidekiq 然后用下面的命令读取备份： 1gitlab-rake gitlab:backup:restore BACKUP=1502357536_2017_08_10_9.4.3 在后续出现的所有询问中输入yes，等待执行完毕，即完成了迁移过程，接下来再次启动gitlab 1sudo gitlab-ctl start 3 删除 下面的删除过程在Ubuntu 16上得到验证： 3.1 移除gitlab服务 1sudo gitlab-ctl uninstall 3.2 清楚Gitlab产生的数据 1sudo gitlab-ctl cleanse 3.3 删除Gitlab生成的系统账户 1sudo gitlab-ctl remove-accounts 3.4 删除gitlab 1sudo dpkg -P gitlab-ce 3.5 其他文件的删除 除了上述操作，Gitlab使用的其他文件夹还需要手动删除，包括： /opt/gitlab: 包含了Gitlab的应用代码和依赖 /var/opt/gitlab: 包含了应用的数据和配置信息(gitlab-ctl reconfigure的写入内容) /etc/gitlab: omnibus gitlab的配置信息。这里的文件是唯一允许你手动编辑的部分 /var/log/gitlab: 日志文件 在你完成了开始的四个步骤后，这里的四个文件夹可以安全地手动删除。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>gitlab</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP:拥堵控制]]></title>
    <url>%2Fposts%2F60823%2F</url>
    <content type="text"><![CDATA[网络数据包如果一次发送太多，就会造成网络拥堵；如果发送太少，就浪费了带宽，延长了通信时间。TCP 协议有一个拥堵窗口机制，负责动态调整每次发送数据包的数量。本文通俗地解释了这种算法的细节。 本文翻译自Intro to Congestion Control 这个夏天，我一直在思考更好地解决网络拥塞问题的方法。在这篇文章中，我将会讨论为什么网络拥塞问题会出现，以及一些传统的解决办法。如果你有更深厚的兴趣，这个Juptier notebook包含了我用来获取相应结果的代码，以及对这些结果的分析。 什么是TCP 在我们开始正文讨论之前，我来先简要介绍一些信息在网络上流通的细节。 TCP协议被用来将信息从一台电脑经过英特网传输给另一台电脑。这个协议也是这篇文章所关注的协议。把TCP协议同其他协议（如UDP）区分开来的特征是，TCP确保了100%的传输成功率。也就是说如果你从一台电脑上发送了100kb的数据，那么你会在接收端准确地收到这100kb的数据。 TCP的这个特性非常强大，而这一特性也是很多网络应用采用TCP协议的原因。现有的Web应用和Email都是构筑于TCP协议之上。 TCP实现所有数据的可靠传输的核心原理是，对于从A端发送到B端的数据，B端会发送回一个ACK(Acknowlegement)信息给A端来告知自己收到了对应的信息。 TCP传输 另外还值得注意的是，TCP工作在IP协议之上，IP协议最多允许在一个包中包含1500个字节的数据，因此要发送100kb的数据，需要拆分成多个分段。根据TCP协议，每个分段都会收到对应的ACK。 如果发送者没有收到一个数据分段的ACK，其会重新发送这个分段。 什么时候会还产生拥塞 拥塞（Congestion）问题是由于网络传输延时导致的。信息传输速率会收到物理信道，如以太网线，蜂窝网络等，的制约。在因特网中，大部分独立设备都连接到这些信道上。 下图是一个典型场景： 拥塞产生的场景 在上面的示意图中，两个发送者要各自要传输1GB的数据。然而这两个发送者最终接入到了一个1GB的链接中。第二个链接的传输能力无法匹配上前两个链接的输入，故而不得不丢弃一部分数据包。如果发送者不主动调整自己的发送速度，那么会产生非常坏的情况。在TCP协议中，如果发送者发现一个数据分段没有送达，会重新发送这个数据包。那么拥塞情况会持续，两个发送者会无法完成发送过程。 为了让两个发送者能够成功传输各自的数据，他们需要共同减少发送数据的速率。如果只有一个发送者减少了发送的数据，而另一个仍然维持1GB的发送量，那么仍然会产生拥塞。在因特网的架构中，不会有一个中央控制系统来协调两者的发送速率。 迂回：什么是链接(link)？ 在我们深入到这个问题的解决方案前，我还想进一步讨论链接（link）的属性。关于网络链接，有下面三个重要的细节问题你需要知道： 延时（毫秒）：一个包从链接的一端发送到另一端需要的时间 带宽（mb/s）：链接每秒能够通过的比特数 队列：在链接正在工作时，等候发送包的队列的长度，以及在队列满时管理队列的策略 如果把链接比喻成水管，那么延时可以理解为管道的长度，带宽就是水管的周长。 链接模型 关于链接还有一个重要的统计参数时带宽延时积（bandwidth-delay product, BDP）。这个参数表现了体现了停留在链接中的数据量，可以理解为管道本身的容量。当链接中传输的数据量达到了BDP时，就可以说链接被充分利用了。如果发送端尝试发送比BDP更多的数据，那么链接的队列将会填满，并最终开始丢包。 方法 在给出方法之前，我们要思考一个问题：发送者如何知道产生了拥塞呢？如同我们之前提到的，因特网是一个分布式的系统，故而并没有一个位于中央的协调者来在下游链接产生拥塞的时候提醒发送者要减慢发送速度。 主要有两个指标：丢包率和传输往返时间。在拥塞发生时，链接的队列逐渐填满，开始发生丢包。如果一个发送者注意到了丢包现象，这就很可能意味着发生了丢包。另一个队列满负荷的现象是数据包在队列中等待的时间增加了，这会导致传输往返时间，即发送包到收到ACK的时间增加。 今天的一些拥塞控制机制考虑了上面两个指标，不过在一些比较早期的设计中，只使用到了丢包率这一个指标。 还需要注意的是，发送者可能并不提前知道传输链接的特性参数。例如，如果你访问&quot;http://www.google.com&quot;，那么你发送的数据包可能要经过很多不同性质的链接才能到达Google的服务器，而你的传输速率是收到其中最慢的链接的制约的。 因此，出了规避网络拥塞的能力，拥塞控制机制还需要能够探索可用带宽的具体大小。 拥塞窗口（Congestion Window） 理解任何拥塞控制机制的关键在于理解拥塞窗口的概念。拥塞窗口指的是在收到一个ACK前发送者能发送的包的数量。如果一个发送者的拥塞窗口被设置为2，这意味着在发送了两个包之后，它必须等到接收端回复的ACK之后才能继续发送。 拥塞窗口越大，发送者就能在相通的时间间隔内向接收端发送更多的数据包。为了更加直观的理解，假设网络传输的延时是88ms，拥塞窗口设置为10，那么在一轮往返传输（88 * 2 = 176ms）时间内可以发送10个数据包。而如果拥塞窗口设置为20，则相同的时间间隔内可以发送20个数据包。 不过当然，提升拥塞窗口的大小，也会提高发生拥塞的概率。拥塞控制算法的目标，就是计算出合适的拥塞窗口大小。 从理论角度来看，拥塞窗口的大小应当就是链接的BDP。 TCP Tahoe TCP Tahoe是在80年代设计出来的拥塞控制算法。那是拥塞问题才刚刚在因特网上出现。算法本身非常简单。增加拥塞窗口分为两个阶段： 第一阶段： Slow Start：算法的开始状态是Slow Start。在这个阶段拥塞窗口在每收到一个ACK就增加1。这种机制有效地在每轮往返传输成功后，将拥塞窗口的大小翻倍。如果拥塞窗口的大小是4，那么在同时会有4个包在传输路途中。当每个包的ACK返回时，拥塞窗口加一，即当这四个包的ACK都收到后，拥塞窗口会翻倍成为8。这个过程会一直持续到拥塞窗口达到阈值，ssthresh。 第二阶段：Congestion Avoidance：当拥塞窗口达到阈值ssthresh时，进入Congestion Avoidance阶段。在这一阶段，每轮往返传输后拥塞窗口加一。也就是说，在上面的例子中，当所有4个包的ACK收到后，拥塞窗口只会加1. 在这个阶段拥塞窗口的大小会大大减小。 当Tahoe检测到丢包后，会把ssthresh设置为当前拥塞窗口的一半，然后将拥塞窗口设置为1，算法重新回到Slow Start阶段。 丢包检测与快速重传 TCP发送端有两种方法来检测丢包现象： 发送端超时。发送端会给每个发送出去的数据包设置一个超时。如果在超时时限达到时尚未收到该包的ACK，则认为发生丢包，并重传改数据包，将拥塞窗口设置为1. 接受者发送回重复的ACK。在TCP中，接收端只会接收按照顺序发送的包。如果收到了不合顺序的包，接收端会返回他收到的最后一个符合顺序的包的ACK。例如，接收端收到了1，2，3，其后又收到了包5，那么接收端会再次回复3的ACK。在Tahoe中，如果发送端检测到重复的ACK，就意味着发生了丢包。这种机制被称为快速重传(Fast Retransmit)，因为这种机制不一定要等待到传输超时。 一些思考 在开头提到的Jupitor Notebook中，我实现了Tahoe，下图是拥塞窗口随着时间变化的曲线： Tahoe的拥塞窗口曲线 注意到上图的中变化曲线存在锯齿形的行为。开始的突增为Slow-Start阶段，后面的平缓部分为Congestion Avoidance阶段。急遽掉落到1则是由于丢包导致的。 为什么Tahoe要如此工作？ Tahoe在工作过程中不断增加拥塞门限的原因是因为网络条件会随着时间不断变化。例如如果另一个发送者开始在同一个信道上发送数据，这会导致可用带宽的降低，其他的发送者需要按照实际情况调整。相反，如果有一个发送者停止发送数据了，可用带宽会增加，这也需要其他发送者根据实际情况来调整。 这种方法其实还是存在很多问题，这也是Tahoe目前已经基本没人使用了。特别的，Tahoe需要很长的时间，尤其是在高带宽网络上，才能全面有效地利用可用带宽。这是因为在拥塞窗口增长到Slow Start门限以后，其增长就变得非常缓慢了。 另外一个问题是，发生丢包并不一定意味着网络发生了拥塞，例如Wifi信道下，本身信道就是可能发送丢失的。对于丢包产生剧烈的将拥塞窗口砍到1并不总是合适的做法。 最后一个问题是，Tahoe使用丢包这个因子来作为判断是否发生丢包的依据。然而由于拥塞发生了丢包，此时调整拥塞窗口已经太晚了。 其他的方法 80年代以后，涌现了不少新的算法来解决上面这些问题。我会在将来的文章中详细讨论这些方法： CUBIC：这个算法在2005年实现，目前是Linux系统的默认拥塞控制算法。如同Tahoe，这个CUBIC也是用丢包作为判断拥塞是否发生的依据。不同的是，CUBIC在高带宽网络下的性能要远高于Tahoe。不同于Tahoe在每一轮往返传输后将拥塞窗口增加1的做法，CUBIC如同其名，使用一个立方函数来确定窗口大小，从而实现拥塞窗口的快速增长。 BBR(Bufferbloat)：这是最近才被Google提出的新的算法。不同于CUBIC和Tahoe，这个算法使用延时来作为判断拥塞是否发生的标识。这背后的思路是延时是拥塞在导致丢包前就能起作用的判断因子。在实际丢包发生前就开始减少发送速率能够带来更高的吞吐率。 公平性 在研究拥塞控制算法时，一个有意思的问题是考虑不同的算法对于同一网络链接上的各个发送者是否公平。如果一个算法在发生拥塞时，没有缩减发送规模，而是按照之前相同的速率继续发送，那么这个算法就是不公平的。在这个结果中，如果同一个链接上 有一个发送者没有采用拥塞窗口控制，而另一个发送者使用Tahoe。从结果可以看到，在一分钟的时间内，Tahoe发送者几乎没法发送任何数据，因为它没有机会增加它的拥塞窗口。而固定窗口的发送者全占了发送信道。 尽管固定窗口发送者是一个不好的情形，这种算法可能具有对其他的算法的不公平地位，从而占据更多带宽。由于缺乏中央控制这，可能有贪婪的发送者蓄意采用固定窗口来谋取更大的带宽。这就是需要从博弈论的角度来研究拥塞控制算法了。 结论 拥塞控制算法是互联网的基础，同时也是在有限信息条件下进行分布式决策的一种迷人的实践。]]></content>
      <categories>
        <category>形而上</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>网络</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Make|自动生成依赖关系]]></title>
    <url>%2Fposts%2F56042%2F</url>
    <content type="text"><![CDATA[Make一般是在Unix环境下使用的自动化编译工具。他本身不是编译器，而是将众多C/C++源文件组织起来，确定其编译方式和编译顺序的工具。一旦我们写好的Makefile配置文件，那么无论多么复杂的工程我们都可以用一条make命令来解决。事实上，尽管通常和C/C++搭配起来使用，make也能应用到其他的编程语言之中。 在使用make过程中的第一个核心问题是处理文件依赖的问题。例如： 12foo.o : foo.c defs.h # foo模块 cc -c -g foo.c 这里foo.o依赖于foo.c和defs.h。当后面两个文件发生变化时，make会自动运行cc -c -g foo.c命令更新foo.o文件。但是，随着项目扩大。这种文件之间的依赖关系会变得非常复杂，一个小的改动可能会涉及到众多依赖关系的修改。因此有必要在项目的开始就引入自动构建依赖关系的工具链。 在跟我一起写Makefile:书写规则这篇教程中，提到了编译器的一个特性：大多数的C/C++编译器都支持一个&quot;-M&quot;的选项，即自动寻找源文件中包含的头文件，并生成一个依赖关系。例如如果我们执行 1cc -M main.c 其输出是： 1main.o: main.c defs.h 注意如果你用的是GNU的C/C++编译器，你得用&quot;-MM&quot;参数，不然，&quot;-M&quot;参数会把一些标准库头文件也引入进来。 这篇教程里面详细阐述了如果在Makefile中使用这一特性的方法，综合而来就是： 123456# 对于每个.c源文件，建立一个描述其依赖关系的.d依赖文件%.d: %.c @set -e; rm -f $@; \ $(CC) -M $(CPPFLAGS) $&lt; &gt; $@.$$$$; \ sed &apos;s,\($*\)\.o[ :]*,\1.o $@ : ,g&apos; &lt; $@.$$$$ &gt; $@; \ rm -f $@.$$$$ 上述命令中sed命令的作用是在依赖关系对中，在左侧加上.d文件本身。即 将 12&gt; main.o: main.c defs.h&gt; 转换成 12&gt; main.o main.d : main.c defs.h&gt; 然后将生成的依赖关系文件include进来 12sources = foo.c bar.cinclude $(sources:.c=.d) 在教程中还提到，这个include要放在默认目标之后，避免include载入的文件的目标替换了默认目标。 走完上面的流程，会得到一个类似的如下内容的文件： 1234567891011121314151617%.d: %.c @set -e; rm -f $@; \ $(CC) -M $(CPPFLAGS) $&lt; &gt; $@.$$$$; \ sed &apos;s,\($*\)\.o[ :]*,\1.o $@ : ,g&apos; &lt; $@.$$$$ &gt; $@; \ rm -f $@.$$$$sources = main.c foo.c bar.cobjs = $(sources:.c=.o)include $(sources:.c=.d)main: $(objs) $(CC) -o main $(objs).PHONY : cleanclean: @rm -f *.d *.o @rm -f ./main 不过按照这个Makefile第一次执行的时候会产生一个问题：第一次执行时，.d文件尚未生成，这里的include导入的文件不存在，会产生如下的错误信息 12Makefile:8: main.d: No such file or directormake: *** No rule to make target 'main.d'. Stop. 最后是通过面向google的debug找到了Autodependencies with GNU make这篇2001年的文章，细致地阐述了这个问题。解决的关键在于在include前面添加一个dash（-），其作用是：如果include的对象不存在，make继续执行，后续make会自动生成.d文件，然后执行include。这篇新的教程提供的完整Makefile示例如下（和前面的形式有不同，但是思路是一致的）： 1234567891011121314151617OBJS := foo.o bar.o# linkproggie: $(OBJS) gcc $(OBJS) -o proggie# pull in dependency info for *existing* .o files-include $(OBJS:.o=.d)# compile and generate dependency info%.o: %.c gcc -c $(CFLAGS) $*.c -o $*.o gcc -MM $(CFLAGS) $*.c &gt; $*.d# remove compilation productsclean: rm -f proggie *.o *.d]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>make</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于无神论者的笑话两则]]></title>
    <url>%2Fposts%2F39480%2F</url>
    <content type="text"><![CDATA[## 一 一个坚定的无神论者去世了，突然发现自己在一个昏暗的过道里。过道里有一个牌子，上写“通向地狱”。没办法，那就进地狱吧。他开门进去，几乎不敢相信自己的眼睛：阳光明媚，暖风宜人，白沙滩，棕榈树，每一百米一个酒吧，到处都是欢快的人们。他沿着沙滩漫步，突然发现一个长着马脚和尾巴的家伙坐在一个沙滩躺椅里。他走上前去问，你是魔鬼吗？魔鬼回答说是，并热烈欢迎新人到地狱。不久，想了解一下地狱的无神论者，两个沙包之间看到一个很大很深的坑，便好奇地往里看，结果吓坏了：坑底烧着熊熊大火，到处是哭天喊地的人，撒了疯的怪物披头盖脸地往人身上打。 无神论者疑惑地跑回魔鬼身边，痛心地问：后边沙包那里那个坑是怎么回事？魔鬼说：噢，他们哪，都是基督徒。他们非要这样，我也没什么办法…… 二 一个忠诚的共产党员死了，上帝不愿意在天堂接受无神论者的灵魂，于是把他送到地狱。一个月后，魔鬼大汗淋漓跑来说“你赶紧把那人带走吧，他差不多把我所有小鬼都发展成了少先队员！” 上帝就接受了。 又过了一月，魔鬼幸灾乐祸地问上帝“那共产党员怎样了？”上帝说：“首先请叫我同志” 非常惭愧，只讲了两个微小的笑话，谢谢大家 来源：https://www.zhihu.com/question/27030419/answer/121040045 续 宗教逻辑]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
        <tag>宗教</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[酵素]]></title>
    <url>%2Fposts%2F25658%2F</url>
    <content type="text"><![CDATA[今天在朋友们的群里又看到有朋友在谈论吃酵素的事情。这让我想到了2017年二月，我去东京交流访问，参观了日本最大的酵素生产商之一：中原株式会社。有意思的是，这家公司虽然是日本的公司，却是中国人创立的。之所以公司的名字叫做中原，是因为创始人是郑州人。当时接待我们的人中，有一个负责做产品研发的生物博士，筑波大学毕业，也是中国人。他带我们参观了公司总部顶楼的一个小型的检测间。有一个随行的朋友很实诚地问道：“酵素这个东西到底有没有用。”那名生物学博士倒也没直接回答，而是笑着说：”大家都是学工科的，都懂“。 酵素这个东西，其实就是酶的另一种说法。吃酵素的风气，也是从日本舶来的。不过在日本那边，酵素是作为”保健食品的“，因此，在酵素包装上面，是不能声称任何疗效的。日本的酵素从业者，不得不利用各种渠道在宣传刊物上宣传酵素成分的一些益处（还不能直接说产品），然后在包装上注明这些成分，以此来吸引消费者购买。不过在中国，法规不是这么健全，因此中国的酵素商家，宣传起酵素功效来，宛如过去街头卖大力丸一般，怎么牛逼怎么来。 某厂商的酵素宣传 其实，酵素就是酶，也就是蛋白质，进入到肠胃，也都被分解成氨基酸，和鸡蛋，肉类无异。故，吃酵素还不如吃鸡蛋，同等营养的情况下，鸡蛋更便宜。]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
        <tag>智商税</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS绕过SIP安全机制限制的一种办法]]></title>
    <url>%2Fposts%2F36948%2F</url>
    <content type="text"><![CDATA[SIP(System Security Protection)是苹果在OSX EI Capitan及其后版本的操作系统中引入了一种新的安全机制。望文生义就可以看出，这个安全机制是用来维持系统的完整性，保护系统免收恶意软件的篡改。具体来说，SIP限制了root账户的权限范围，限制了root用户在对一些系统保护目录即其中文件的操作能力。 SIP的保护范围包括下列路径： /System /usr /bin /sbin OSX的预装应用 第三方应用可以继续操作的目录包括： /Applications /Library /usr/local 但是任何对于安全性加强都意味着对灵活性的削弱。例如，在SIP保护下，类似proxychains-ng的程序无法再给受保护的目录下的程序添加网络钩子(hook)。 proxychains ng (new generation) - a preloader which hooks calls to sockets in dynamically linked programs and redirects it through one or more socks/http proxies. 一般来说，很多解决方案都建议关闭SIP功能（例如proxychains-ng的issue中给出的方法：# issue78）。不过这样也意味着丧失了SIP提供的保护功能。这篇文章给出了一个妥协的做法。在保留SIP的保护的同时，为保护目录下的程序应用proxychains-ng（其他类似的应用场景也可以使用这个办法）。这个解决方案的思路其实很简单：既然保护目录下的程序我们不能动，那么我们把保护目录下的程序复制一份到其他目录下运行就可以。 首先创建一个新的文件夹： 1mkdir ~/.unprotected_apps 然后将这个路径添加到PATH环境变量的头部： 12# 可以添加到shell的配置文件中，如~/.bashrc或者~/.zshrcexport PATH="~/.unprotected_apps:$PATH" 然后将需要添加钩子的应用复制到这个目录下就可以了，例如： 12cp $(which ssh) ~/usr/bin/sshcp $(which curl) ~/usr/bin/curl]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>macOS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks上手配置]]></title>
    <url>%2Fposts%2F37347%2F</url>
    <content type="text"><![CDATA[Shadowsocks配置的一个非常便利之处在于，Shadowsocks支持将配置信息导出成二维码再在其他机器上导入。这节约了很多沟通成本。所以在开始这篇教程之前，你需要有一个Shadowsocks的配置信息。可以是具体参数，或者是一个配置二维码。 1. 客户端准备 Shadowsocks提供了绝大多数平台的客户端支持，甚至包括智能路由器。我们这里介绍最为常见桌面端的平台上的配置。 这里我提供了mac和win这两个主要平台截止到目前为止最新版的客户端下载： macOS客户端下载; win客户端下载. 其中，mac文件下载下来解压缩后，直接拖拽进入Application文件夹（应用文件夹），然后双击打开使用就可以了。win端的文件解压缩后是一个可以直接运行的绿色版（不需要安装）。将解压缩文件移动到一个稳妥的位置，然后双击打开Shadowsocks.exe文件就可以了（此时右下角会出现一个小飞机图标） 更加丰富的客户端下载：https://shadowsocks.org/en/download/clients.html 2. 导入配置 写这篇文章的时候我使用的是mac，因此后面的配置方法过程都以mac为例。mac和win上客户端的使用都是相通的。不同的是小飞机图标在mac中位于顶部，而在win中位于底部。 ShadowsocksX-NG右键菜单截图 右键点击小飞机图标可以看到如上图所示的菜单。其中 第一个section中，负责控制Shadowsock的开启和关闭，我这里显示的是已经开启了Shadowsocks，如果你的客户端代理还没有启动，点击一下&quot;打开 Shadowsocks&quot; 第二个section中，可以设置Shadowsocks的代理模式。其中PAC模式是最为常用模式。在这种模式下，Shadowsocks会根据一张预先订好的表，来判断你当前访问的网址是否被墙了。如果是就会通过代理访问这个网站，否则照常直接连接网站就可以了。与之相对的，全局模式是让所有的网站都通过代理进行访问。 第三个section中，可以进行服务器的配置。 如果你是使用二维码进行配置，那么，将二维码用预览打开，确保这个预览窗口位于最上层可见，然后点击菜单中的“扫描屏幕上的二维码”就可以导入服务器配置了。 如果你是使用详细配置信息进行配置，那么需要进入服务器 -&gt; 服务器设置，手动填写各个参数进行添加。 第四个section是用来配置本地代理和PAC的，对于这部分的详细讨论超出了这篇文章的范畴，我们会在后续的文章中进行讨论。 3. 手机端配置 由于政策原因，手机端APP，尤其是iOS的手机端APP的审查情况非常严重，基本上很少有APP能够长期屹立不倒。因此手机端APP的选择要实时来看。我自己使用的SuperWingy这个应用已经下架了（不过从已购里面还是可以下载的）。因此，大家发现还有什么可以用的手机端应用，就更新在评论里把。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开源对象存储服务(OSS) Minio 及其在Hexo中的使用]]></title>
    <url>%2Fposts%2F5440%2F</url>
    <content type="text"><![CDATA[研究对象存储服务(OSS)是因为考虑到将来可能会有在博客上放出一些可供分享的文件下载的服务需求，直接使用现有图床，容易混杂乱。因此我考虑重新建立一个独立OSS存储服务。直接Google搜到了Minio这个框架，10k+的Star，就决定选择这个了。Minio框架有如下几个优势： 可以Docker部署，非常省事 文档完善 全面的平台支持 多种客户端语言支持（有完善的JS SDK） ## 1. Minio部署 使用Docker部署可以说是非常方便省事了。我的部署命令如下： 1234567docker create -p 9000:9000 \-e "MINIO_ACCESS_KEY=your-access-key" \-e "MINIO_SECRET_KEY=your-secret-key" \--name=minio \-v /path/to/minio/data:/data \-v /path/to/minio/config:/root/.minio \minio/minio server /data 其中的访问秘钥对需要替换成你自己设置的值。这一对值稍后会用于网页端的登录。然后用 1docker container start minio 来启动镜像。完成后就可以在http://domain.com:9000中访问到了，输入docker命令中的秘钥对来登录。 登录界面 而后你可以按照Lychee图床教程中的做法，添加Nginx反向代理和HTTPS支持。 2. Hexo中使用 部署完成后我才发现一个问题，那就是Minio生成的外链是强制有过期时间的，而且长度最多只七天。那我就不能像直接复制粘贴外链来使用了，同时，手动来每七天更新一次链接也是不可接受的。因此用Hexo脚本来自动实现了利用Minio的API接口来更新下载链接。脚本内容如下： 1234567891011121314151617181920212223'use strict';const Minio = require('minio');var hexo = hexo || &#123;&#125;;var fs = fs || require('fs');var yaml = yaml || require('js-yaml');var minio_client = minio_client || new Minio.Client(yaml.safeLoad(fs.readFileSync(__dirname + "/minio_key.yml", 'utf8')));hexo.extend.tag.register('minio', async (args, content) =&gt; &#123; var bucket = 'default', resource_name = ''; if (args.length == 1) &#123; resource_name = args[0]; &#125; else &#123; resource_name = args[1]; bucket = args[0]; &#125; var file_url = await minio_client.presignedGetObject(bucket, resource_name); return `&lt;a target="_blank" href="$&#123;file_url&#125;"&gt;$&#123;content&#125;&lt;/a&gt;`;&#125;, &#123;async: true, ends:true&#125;); 在博客工程的根目录下创建一个文件夹scripts,在其中创建一个js文件，如index.js，然后将上述脚本内容粘贴进去。然后在这个目录下创建设置文件，minio_key.yml，文件中需要包含如下信息： 1234endPoint: 'minio.domain.com'accessKey: 'your-access-key'secretKey: 'your-secret-key'useSSL: true # 是否使用https 然后还需要安装依赖 1npm install --save minio 至此我们完成了脚本的安装。脚本为我们提供了一个标签插件，其使用范例如下： 123&#123;% minio 'bucket_name' 'resource_name' %&#125;下载链接&#123;% endminio %&#125; 在使用Hexo进行静态页面渲染时，这部分内容会被自动渲染成下载链接： 1&lt;a target=&quot;_blank&quot; href=&quot;download_url&quot;&gt;下载链接&lt;/a&gt; 不过这种方法还是有一个显而易见的缺点：你需要是一个非常勤奋的作者，每周都来发布一次文章，不然旧文章的链接还是会失效。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Hexo</tag>
        <tag>Minio</tag>
        <tag>OSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks持续优化]]></title>
    <url>%2Fposts%2F35429%2F</url>
    <content type="text"><![CDATA[## Fast TCP开启 如果双端都支持FastTCP，那么可以通过开启FastTCP来降低延时。服务端设置方法有两种，要门在config.json中添加fast_open为true，要么在执行ssserver带上--fast-open。然后在命令行中运行 1echo 3 &gt; /proc/sys/net/ipv4/tcp_fastopen 进一步优化 这个优化方法适合所有的shadowsocks版本，具体方法如下。创建文件/etc/sysctl.d/local.conf，并在文件中添加如下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# max open filesfs.file-max = 51200# max read buffernet.core.rmem_max = 67108864# max write buffernet.core.wmem_max = 67108864# default read buffernet.core.rmem_default = 65536# default write buffernet.core.wmem_default = 65536# max processor input queuenet.core.netdev_max_backlog = 4096# max backlognet.core.somaxconn = 4096# resist SYN flood attacksnet.ipv4.tcp_syncookies = 1# reuse timewait sockets when safenet.ipv4.tcp_tw_reuse = 1# turn off fast timewait sockets recyclingnet.ipv4.tcp_tw_recycle = 0# short FIN timeoutnet.ipv4.tcp_fin_timeout = 30# short keepalive timenet.ipv4.tcp_keepalive_time = 1200# outbound port rangenet.ipv4.ip_local_port_range = 10000 65000# max SYN backlognet.ipv4.tcp_max_syn_backlog = 4096# max timewait sockets held by system simultaneouslynet.ipv4.tcp_max_tw_buckets = 5000# turn on TCP Fast Open on both client and server sidenet.ipv4.tcp_fastopen = 3# TCP receive buffernet.ipv4.tcp_rmem = 4096 87380 67108864# TCP write buffernet.ipv4.tcp_wmem = 4096 65536 67108864# turn on path MTU discoverynet.ipv4.tcp_mtu_probing = 1# for high-latency networknet.ipv4.tcp_congestion_control = hybla# for low-latency network, use cubic instead# net.ipv4.tcp_congestion_control = cubic 然后运行 1sysctl --system 应用上述设置。最后在启动脚本中，于ssserver前添加 12ulimit -n 51200 这个设置方法，会消耗比较多的内存，但是会换来速度的大幅上升。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks：多用户账号独立，并限制用户连接数]]></title>
    <url>%2Fposts%2F7835%2F</url>
    <content type="text"><![CDATA[自己搭建了一个SS服务器以后，自然而然的会同身边的朋友共享。自然，身边的朋友一起用，大部分服务器配置都可以毫无压力的支撑。但倘若一传十十传百，最后成百上千的人一起用一个服务器，那就撑不住了。 当然你可以隔一段时间换一次密码，但是后面的麻烦事也不少（要同步更新不同设备上的设置，身边的朋友来问你新设置）。 几天我研究了一下，为ss服务器增加了多用户即为每个用户设置独立的连接数限制的方法，这样能够比较完美的解决同朋友共享服务器的问题了。 这里默认你已经知道怎么按照通常的方法安装和配置SS了。如果你不了解的话，网络上的文章很多的。 1. 多用户的实现 多用户的实现比较简单，Python和Go实现的服务器自带多用户支持。通常的配置我们一般是这么写 123456&#123; "server": "::", "server_port": "8888", "password": "yourpassword" // Other configs&#125; 只需要将配置文件按照下面的方式进行修改就可以实现多用户了。 123456789&#123; "server": "::", "port_password": &#123; "8881": "password1", "8882": "password2", "8883": "password3" &#125; // other configs&#125; 就可以了。之后不同的用户可以通过不同的端口访问，而每个端口都有独立的密码。 Further Reading: Reference 2. 限制用户连接 我在网上调查了一下实现限制用户连接的方法，很多都提到了通过iptables来进行设置。但是这种方法太过复杂，很容易出问题。后来我找到一个ss的补丁，可以比较好的解决这个问题。补丁地址是falssen/PySocket。 这个工程提供了一些其他的功能，但是我们这里只关注Limit_Clients文件夹下的socket.py这个文件。这个文件的原理是利用Python包导入的机制，用自定义的socket.py来替换默认的socket包，并在socket接口中植入一些新的功能。 按照READMe.md的提示安装好socket.py文件 &gt; 有很多朋友不知道这里要怎么处理socket.py文件。其实并不复杂。用which命令查看一下ss脚本安装的位置，一般情况下是/usr/local/bin/，那么你只需要把socket.py文件放到/usr/local/bin下面就行。这一操作的原理是，python在导入包时总是先检查当前目录。注意，如果修改了socket.py文件，需要重启进程才能生效。 然后修改文件中white_list和black_list两个变量。例如我自己使用的1017端口，我不希望添加限制，则将white_list设置为 1white_list = [1017] 我给朋友们用的是[1018]端口，我希望这个端口的连接数不要超过40个，则将black_list设置为 1black_list = &#123;1018:40&#125; 3. 注意 注意方法的实质是限制接入的客户端IP数量，因此，处在同一路由器下面的多台设备也会被识别为一台。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自建图床: Lychee]]></title>
    <url>%2Fposts%2F65048%2F</url>
    <content type="text"><![CDATA[之前用的图床sm.ms的图片突然挂了。不知道为何，图片还是能够上传，但是访问图片的链接会出ERR_SPDY_PROTOCOL_ERROR的错误。 ERR_SPDY_PROTOCOL_ERROR错误示意图 正好我自己的翻墙服务器的硬盘长期富余。虽然只有十几个G，搭建一个自己图床还是够用的。更重要的是，Dogital Ocean的服务器的流量非常多（我买的$5的服务器的流量有一个T）。我选择的开源图床框架是Lychee。这个框架支持Docker安装，可以省很多事情。 1. Docker安装Lychee 常规的安装方法可以参考官方文档。我这里只介绍Docker方式。如果你没有什么特别的需求，Docker方式应该是非常适合你的。 注：这篇教程只是对于我的操作过程的一个记录，因此对于一些依赖环境的安装没有面面俱到。这些问题，都可以面向google进行解决。 1.1 Docker环境准备 首先你要安装一个Docker环境。在Ubuntu上，安装非常简单： 12$ sudo apt update$ sudo apt install docker-io 有时还需要将你当前用户加入到docker组中，这样每次执行docker命令不需要加sudo了。这个操作可能在安装过程中自动完成了，如果你发现docker命令执行时提示有权限相关的问题，可以运行 1$ sudo adduser user docker 注意确保一下docker-compose也安装完毕了。我们需要通过docker-compose来将Lychee和数据库组装在一起。 12$ docker-compose -vdocker-compose version 1.17.1, build 6d101fb 1.2 安装Lychee 首先创建好目录树： 12345lychee|-- config|-- db|-- pictures|-- docker-compose.yml 其中，config和pictures分别用来存储Lychee的设置和图片文件。db文件夹则是用于数据库，这三个文件夹需要你手动创建。docker-compose.yml文件内容如下： 123456789101112131415161718192021version: '1'services: lychee: image: linuxserver/lychee links: - lychee-db:lychee-db volumes: - /path/to/lychee/config:/config - /path/to/lychee/pictures:/pictures ports: - 8000:80 lychee-db: image: mariadb:10 volumes: - /path/to/lychee/db:/var/lib/mysql environment: - MYSQL_ROOT_PASSWORD=&lt;choose root password&gt; - MYSQL_DATABASE=&lt;db name&gt; - MYSQL_USER=&lt;username&gt; - MYSQL_PASSWORD=&lt;username&gt; 目前我没发现lychee的这个镜像支持用环境变量来配置数据库信息。所以上面对应的数据库信息后续需要在网页端手动输入。 然后在这个文件夹下运行 1$ docker-compose up -d 然后访问http://yourdoman.com:8000就可以访问了。 1.3 Lychee配置 在访问上述网页之后，Lychee会提示我们输入数据库信息。 Lychee 配置 注意这里的Database Host要填写lychee-db。其他的设置与上面的docker-compose.yml文件中的一致即可。 而后按照提示创建登录账户： 创建账户 2. Lychee Advanced 2.1 使用Nginx进行反向代理 Nginx配置文件如下： 12345678910111213server &#123; server_name imgs.codewoody.com; client_max_body_size 50M; location / &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://localhost:8000; &#125;&#125; 2.2 启用HTTPS 目前来看，Let's encrypt仍然是个人建站启用HTTPS的不二之选。其使用教程可以说是非常简明了，具体参考certbot。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>折腾</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这个博客是如何建立起来的]]></title>
    <url>%2Fposts%2F53793%2F</url>
    <content type="text"><![CDATA[在博客问题上我可是折腾了很多回了，先是尝试了wordpress（来来回回很多次），不过wordpress使用起来，感觉还是太“重”，很多东西配置起来非常麻烦(包括主题设置，甚至是Markdown支持)。后来迁移到简书上面，被国家政策教做人(一篇关于Shadowsocks的文章被屏蔽了，有种吃苍蝇的感觉)。思前想后，还是自己host自己的博客好。最终我是选择了Hexo + Github的方案，好处如下： 对Markdown支持比较好 不需要自己折腾服务器 用Git管理非常方便 在这篇文章里，我整理一下整个博客的搭建过程。 1. Hexo Setup Hexo是一款基于Node.js的静态博客框架，可以生成静态页面部署在Github和Heroku上面。Hexo的搭建过程如下： 申请域名 创建Github仓库 安装Hexo及其依赖 绑定域名 1.1 申请域名 虽然部署在Github上Github会提供一个免费的域名，但是如果有自己的独立域名的话，网站会更像&quot;博客&quot;一点。申请域名的地方有很多，我的域名是选用的阿里云的。传送门：阿里云-为了无法计算的价值。 1.2 创建Github仓库 在Github中创建一个名字为username.github.io的仓库，注意这里的username需要替换为你自己的用户名。例如我的仓库名字为huangy10.github.io。 &gt; 你可以尝试在这个仓库中添加一个名为index.html的文件，在其中接入hello world。然后访问http://username.github.io 就可以看到这个页面了。 &gt; 不过注意尝试之后删除这个仓库重新创建。后面我们在部署Hexo的时候最好让这个仓库是空的。 &gt; 1.3 安装Hexo及其依赖 1.3.1 安装Git，并配置好SSH秘钥 这里Github有全面的教程，传送门：https://try.github.io/ 1.3.2 安装Node.js Mac平台下面安装Node.js非常简单，可以通过Homebrew进行安装: 1brew install node 如果没有安装Homebrew，可以在Terminal中输入下面这个命令快速安装： /usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 安装完成后可以通过node -v来验证安装是否成功，并查看安装版本。进一步通npm -v来检查npm也正确安装了。 1.3.3 安装Hexo 使用npm来安装Hexo： 1npm install -g hexo-cli 完成安装以后，挑选一个合适的路径，然后运行 1hexo init blog 这个命令会在当前文件夹中创建一个名为blog的文件夹。博客相关的文件都会存储在这个文件夹中。cd进入这个文件夹，然后运行 1234# 生成静态文件hexo g# 在本地运行一个测试服务器来伺服静态文件hexo s 然后在浏览器中访问http://localhost:4000 就可以访问自己的网站了。 博客初始页面 我们来看一下Hexo博客项目下的目录结构： Hexo目录结构 其中比较重要的是： _config.yml是整个项目的配置文件，YAML格式； public是发布的静态文件内容。注意这个文件会在hexo g命令后重新生成，其中内容会被重置； source是工程源文件，其中的_posts文件夹存储了博文的Markdown文件。其中的其他文件，则会在hexo g命令的作用下发布到public文件夹中； themes存储了博客的主题。在各个主题自己内部也有自己的_config.yml文件，用来定制化模板的参数。 1.4 Hexo部署 我们选择将Hexo部署到Github上。打开博客项目根目录下的_config.yml文件，跳到最后，修改 1234deploy: type: git repo: git-repo-path(ssh方式，不要用https) branch: master(不出意外就填写master) 保存退出。 然后我们需要安装一个git部署的工具: 1npm install hexo-deployer-git --save 然后运行 123hexo cleanhexo ghexo d 三个命令，就可以逐步完成清理之前的生成，重新生成静态文件，将静态文件部署到Github上。全部完成后访问username.github.io 。就可以看到站点了。 2. Hexo Advanced 2.1 自定义域名 使用github提供的免费域名还是不够fancy，我还是希望使用自己的域名。首先进入域名管理后台，添加两条记录。分别是 yourdomain.com 添加一条A记录，指向username.github.io对应的ip地址。（这个ip地址可以通过ping命令看到） www.yourdomain.com 添加一条CNAME记录，指向username.github.io 然后在本地博客工程中的public文件夹下，添加一个CNAME文件，文件中写入自定义的域名www.yourdomain.com。重新三连： 1hexo clean; hexo g; hexo d 这是输入https://www.yourdomain.com就可以访问自己的网站了（可能需要等一段时间让dns刷新） 2.2 更换主题 自己搭建博客的乐趣之一就是各种更换主题。Hexo有自己的主题市场：Themes。我选择的主题是laughing。这个主题比较简洁，而且支持响应式布局。不过，这个主题支持的多说这个评论平台已经关闭了。其安装过程如下（其他的主题的安装方式大同小异）： 首先安装主题依赖的pug模板引擎: 1npm install hexo-renderer-pug --save 然后将主题文件夹下载到themes目录： 12cd themesgit clone git@github.com:BoizZ/hexo-theme-laughing.git 最后修改博客项目根目录下的_config.yml文件： 1theme: hexo-theme-laughing 主题的配置方式可以参考主题的Github文档。需要注意的是，文档中所说的_config.yml文件是指的主题文件夹中的配置文件，而非博客项目根目录下的配置文件。 2.3 插件 Hexo提供了很多插件来增强博客的功能。这个部分我也正在研究。这里我列出一下目前我安装了的插件： hexo-addlink: 在文章末尾中添加本文的链接 hexo-generator-feed: 生成rss订阅 hexo-generator-sitemap: 生成站点地图]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>教程</tag>
        <tag>Hexo</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2FREAMDE.html</url>
    <content type="text"><![CDATA[Woody Huang的个人博客 https://www.codewoody.com]]></content>
  </entry>
  <entry>
    <title><![CDATA[categories]]></title>
    <url>%2Fcategories%2Findex.html</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[知识库🛠]]></title>
    <url>%2Fknowledge-base%2Findex.html</url>
    <content type="text"><![CDATA[我希望用我的博客能够整理出一些呈体系话的知识库体系。这个页面是这个知识库的入口。以下是目录。注意因为知识还在不断的完善中，所以这些页面也是经常地处于WIP状态。这里的文章除了我自己撰写/翻译的内容外，还会转载一些优秀的博文。 News 这个部分主要整理日常中我见到的引起舆论广泛关注的新闻/案件 见闻 学术不端现象 严重事故 Downloading Resources 下载资源汇总 Programming How to install 这里给出了多种软件的安装方法 python apt使用和配置的一些信息 Linux Shell Linux命令行使用指北 Academic 智能交通系统 WLAN History 中国近现代史部分的史料 中国中古代部分的史料 Science 备份集]]></content>
  </entry>
  <entry>
    <title><![CDATA[tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[博客更新]]></title>
    <url>%2Fupdate%2Findex.html</url>
    <content type="text"><![CDATA[2019.06.29 在标题前方添加Emoji 2019.06.28 修改了内容宽度 具体方法为修改文件themes/next/source/css/_variables/Pisces.styl 1234// $content-desktop-large = 1160px$content-desktop-large = 960px// $content-desktop-largest = 73%$content-desktop-largest = 960px 启用了Han Support 在menu中添加update项目 字体修改为思源宋体：关于如何在网页中引入思源字体：漫谈Typekit 思源宋体 2019.05.20 困扰很久的VS Code引入莫名其妙添加的不可见08和05等控制字符的问题，最后可以通过“Remove backspace control character”这个插件解决。在VS Code的设置中将editor.formatOnSave设置为true来自动处理文件。 2019.05.15 修复了搜索和Feed的问题：文章中存在不可见字符，导致atom.xml和search.xml的格式出错 替换了字体服务器的CDN，从//fonts.googleapis.com修改为//fonts.css.network 20190507 2 修改了Reference的样式。方法是在themes/next/source/css/_custom/custom.styl文件中添加如下内容： 12345678div#refs &#123; font-size: 13px; line-height: 1.1;&#125;div#refs p &#123; margin: 0;&#125; 1 通过上标提供短的参考信息的方法： 1&lt;sup title="Hover Text"&gt;?&lt;/sup&gt;]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2Fknowledge-base%2Facademic%2Findex.html</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[备份集]]></title>
    <url>%2Fknowledge-base%2Fbackups%2Findex.html</url>
    <content type="text"><![CDATA[这个部分的作用是备份我在网上看到的好文章，避免因为“种种问题”文章消失不见了。 2019 为什么中国没有新闻法？ 佛罗里达大学博生生自杀事件]]></content>
  </entry>
  <entry>
    <title><![CDATA[见闻]]></title>
    <url>%2Fknowledge-base%2Fnews%2Findex.html</url>
    <content type="text"><![CDATA[2019.06 湖南怀化新晃一中操场埋尸案 新京报讯6月19日，湖南怀化新晃一中操场跑道下发现一具骨骸。新晃县公安局称，已对时任校长房某及10余人采取强制措施。新晃一中办公室工作人员称，案件未对学校造成影响，仍正常上课。新晃县教育局称，正配合警方调查该事件。 据新京报此前报道，怀化公安晃州派出所民警向新京报证实，确有老师被埋跑道的案件发生，遗骸于昨晚（6月19日）在操场被挖出，怀化市公安局负责人称，案件为2003年确实有一位邓姓男子失踪，最近破获另一案件，嫌疑人交代了16年前邓世平的案件，警方顺藤摸瓜找到遗骸。 邓世平之子邓军（化名）称，父亲16年前失踪，此前曾任学校后勤保障部门职工，邓世平失踪时正在负责学校操场的修整工作。“失踪前就是去学校上班，跟平时是一样的，在我的印象中没有什么异常，我们怀疑他可能去朋友家打牌去了，但亲戚朋友都没有找到。”邓军说，邓世平失踪3天后，邓军一家报案。 2019年4月17日，新晃警方对外公布，打掉了杜少平犯罪团伙，邓军称杜少平就是当年的施工方负责人。“杜少平因为别的案子被抓了，其交代又交代了我父亲可能会被埋在那里，警察根据这个线索去侦查办案，抓住了当时几个作案人，那几个人带警方去了埋尸地点。” 邓军告诉新京报记者，新晃一中挖出的骨骸是不是自己父亲的，仍需进行进一步鉴定。 嫌疑人-杜少平 挖掘现场 这次之所以能够挖出十六年前的案子，是因为今年中央扫黑除恶第16督导组进驻湖南调查。督导组派多路人马下沉到市州地县。其中赴怀化开展督导工作的是第七小组，时间为4月18日至24日。 这种案子藏了这么多年没有出事，必然是由保护伞了。目前公布出来的后台方是当时新晃一中校长，黄炳松。杜少平与黄炳松为亲戚，是十六年前杜少平作为校长亲戚获得操场的建设承包权。死者邓世平出生于1950年，当时是在新晃一中工作，负责后勤。邓认为操场质量有问题，还偷工减料、虚报工程款，先是拒绝签字然后又向县里举报，没有多久便失踪。邓世平的弟弟表示，2003年1月22日（腊月二十）上午8点，邓世平上班，中午没回家。家属四处寻找无果后报警。 邓世平的儿子也表示，其父失踪前曾任学校操场修整工程的质监人员。他也曾怀疑父亲被埋尸操场，“那天晚上挖机冒雨作业填土，这个很反常。 涉事的新晃一中始建于1939年，可谓历史悠久。长安街知事（微信ID：Capitalnews）注意到，早在1988年，黄炳松就成为副校长，10年后升任校长。2004年2月，也就是埋尸案发生一年后，他才卸去该职务。算下来，他管理学校长达17年。 黄炳松 以下是魔幻现实主义： 魔幻现实主义：活埋 因为邓世平案件，这次还意外引发了对李尚平案件的追问。时年32岁的李尚平是湖南益阳市龙光桥镇南塘中学教师。根据《南方周末》报道，2002年4月26日，其尸体被发现在离家300米的公路边，浑身是血，后脑有个像漏斗那么大的洞，半边脸整个塌陷。警察们和法医作了一番检查后，宣称李尚平死于“一场交通事故”。目前此案仍未水落石出。 李尚平]]></content>
  </entry>
  <entry>
    <title><![CDATA[为什么中国没有新闻法]]></title>
    <url>%2Fknowledge-base%2Fbackups%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%AD%E5%9B%BD%E6%B2%A1%E6%9C%89%E6%96%B0%E9%97%BB%E6%B3%95.html</url>
    <content type="text"><![CDATA[原文链接 这个世界没有绝对的自由。新闻和出版管制这事古今中外的政府都在干。焚书坑儒告诉人们：总有些东西政府不让你看，如果你一定要看就砍掉你的头。 中国几千年来都是皇上说禁什么就禁什么，到了近代才慢慢走上法制轨道。中国第一个正式的出版法是 1906年《大清印刷物专律》，后来还有1908年大清报律、1914年出版法、1937年修正出版法等。1949年新中国成立，《中华人民共和国宪法》确认了公民有言论和出版自由，但中国大陆至今没有专门的《出版法》和《新闻法》。这在世界各国中是非常罕见的。 为什么新中国成立六十多年也没有《新闻法》和《出版法》，不能连满清政府也不如吧？这主要是因为宪法已经规定了言论和出版自由，如果制定《新闻法》，新闻自由就是一个绕不过去的坎。任何法律都不能违宪。但如果《新闻法》确定新闻自由，那中宣部就无法命令各大媒体了。中共中央不会容许这种情况出现。 中国新闻立法推动人之一的孙旭培教授曾在《新闻立法之路》一文中引述了中国共产党老一辈革命家陈云的一句话：&quot;在国民党统治时期，制定了一个新闻法，我们共产党人仔细研究它的字句，抓它的辫子，钻它的空子。现在我们当权，我看还是不要新闻法好，免得人家钻我们空子。没有法，我们主动，想怎样控制就怎样控制。&quot;陈云的谈话反映了中央高层一部分人对新闻立法的态度。 当然，也可以制定一个中国特色的《新闻法》，规定一切媒体听党指挥。理论上这么做没问题，但在全世界都推崇新闻自由、保障媒体监督的时候，中国推出这样一个反潮流的《新闻法》，在国际上岂不贻笑大方？人多少还是要点脸的。 我们都知道，新闻和出版法事关言论自由，是最重要的法律之一，在国际法律界素有“第二宪法”之称。但因为以上所述的原因，《新闻法》和《出版法》在中国难产了几十年，短期之内也看不到制定这两部法律的希望。中国政府陷入了两难，制定不是，不制定也不是，干脆就拖着吧。2016年3月10日，在第十二届全国人大四次会议新闻发布会上，有记者问“新闻法立法有无具体的议程”，发言人干脆拒绝回答这个问题。 既然“第二宪法”没指望，那我们就回头来看看宪法，它明文规定了言论和出版自由。中宣部对媒体管得那么死，岂不是违反宪法？令计划下令全国媒体不准报导法拉利事件，岂不是也违反宪法？理论上确实如此，但中国的宪法基本只是摆看的，它不具备可诉性。 中国宪法明文规定了全国人大是宪法唯一的监督机构。全国人大有一堆委员会，教科文卫委、财经委等等，唯独没有最重要的宪法委员会。我们中国也没有宪法法院。所以，当出现违宪案件，比如中央禁止报导法拉利事件，如果哪位记者发飙了要起诉，他会发现无处可告，没有任何法院或机构受理违宪案件。我们既没有《新闻法》也没有《出版法》，加之《宪法》也被架空，所以新闻和出版自由在中国就只是一句空话。]]></content>
  </entry>
  <entry>
    <title><![CDATA[佛罗里达大学博生生自杀事件]]></title>
    <url>%2Fknowledge-base%2Fbackups%2F%E4%BD%9B%E7%BD%97%E9%87%8C%E8%BE%BE%E5%A4%A7%E5%AD%A6%E5%8D%9A%E7%94%9F%E7%94%9F%E8%87%AA%E6%9D%80%E4%BA%8B%E4%BB%B6.html</url>
    <content type="text"><![CDATA[The Hidden Story Behind the Suicide PhD Candidate Huixiang Chen]]></content>
  </entry>
  <entry>
    <title><![CDATA[下载资源]]></title>
    <url>%2Fknowledge-base%2Fresources%2Findex.html</url>
    <content type="text"><![CDATA[开发 iOS/Mac相关 Command Line Tools: 需要登录Apple Developer账户 书本]]></content>
  </entry>
  <entry>
    <title><![CDATA[科学]]></title>
    <url>%2Fknowledge-base%2Fscience%2Findex.html</url>
    <content type="text"><![CDATA[这里我们汇总一些好玩的科普知识内容，也许会涉及一些非常硬核的内容。]]></content>
  </entry>
  <entry>
    <title><![CDATA[历史]]></title>
    <url>%2Fknowledge-base%2Fhistory%2Findex.html</url>
    <content type="text"><![CDATA[虽然这个部分的题目时历史，但是显然我一己之力无法写个世界通史出来。这一部分的文章的目的，在于梳理，汇总一些对中外历史上一些经常被拿出来讨论的点做一些探究。因此与其说是“历史”，其实不如说是历史梗集。]]></content>
  </entry>
  <entry>
    <title><![CDATA[智能交通系统🚗]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Findex.html</url>
    <content type="text"><![CDATA[智能交通系统是将先进的信息技术、通讯技术、传感技术、控制技术及计算机技术等有效率地集成运用于整个交通运输管理体系，而创建起的一种在大范围内及全方位发挥作用的，实时、准确及高效率的综合的运输和管理系统。美国、日本、欧洲率先展开相应的研究并成为ITS发展的三强，此外加拿大、中国、韩国、新加坡、澳大利亚等国家的研究也具有相当规模。 现有的智能交通系统通信标准 WAVE(Wireless Access in Vehicular Environments) 研究话题 编队系统]]></content>
  </entry>
  <entry>
    <title><![CDATA[严重事故]]></title>
    <url>%2Fknowledge-base%2Fnews%2F%E4%B8%A5%E9%87%8D%E4%BA%8B%E6%95%85%2Findex.html</url>
    <content type="text"><![CDATA[河南永城玛莎拉蒂酒驾追尾 2019 年 7 月 3 日晚，河南省永城市一辆玛莎拉蒂来万台 「疑似」 酒驾，跟两车剐蹭后逃逸，逃逸过程中追尾一辆等红灯宝马，被撞宝马当场起火，视频中可以看见的有副驾后排两名死者已被烧焦，具体案情还需听官方通报。 情况通报 被追尾的宝马 肇事者 肇事者 谭某某，是河南永城市茴村乡谭桥村首富的孙女，她爷爷在谭桥村开了个很多亩地的皮革厂，她爸爸据说也混的不错（我不是她们村里的，不是很清楚）标准的富二代，名牌包包鞋子一大堆，平常生活在城里，只有逢年过节的时候，可能会去她爷爷的乡村别墅里。 -- 知乎匿名用户]]></content>
  </entry>
  <entry>
    <title><![CDATA[学术不端]]></title>
    <url>%2Fknowledge-base%2Fnews%2F%E5%AD%A6%E6%9C%AF%E4%B8%8D%E7%AB%AF%2Findex.html</url>
    <content type="text"><![CDATA[弗罗里达大学 - 李涛 6 月 13 日，佛罗里达大学在读博士生陈慧祥（Huixiang Chen）在校园自杀身亡，此前他担任第一作者的论文刚刚入选 2019 年计算机体系结构国际研讨会（ISCA）。 这一事件在知乎、Quora 等社交媒体上引发了广泛关注和讨论。6 月 29 日，Medium 用户 Huixiang's Voice 发布了陈慧祥生前的微信聊天记录和遗书。网络信息显示，陈慧祥对好友透露导师李涛（Tao Li）纵容甚至鼓励论文造假，靠关系让他的论文入选 ISCA，并且拒绝撤稿。他认为这样的文章会对他对职业生涯造成负面影响，并在遗书中表示“我反复考虑到了所有情况，觉得真的无路可走”。 7 月 2 日，Huixiang's Voice 发布第二篇文章，称李涛已通过邮件联系账号所有者，并表示“严正要求你们立即撤销、停止散布，和澄清网络不实消息，否则，有关责任人将面临法律起诉和司法责任”。 7 月 3 日，佛罗里达大学发表声明称正对事件展开调查。 后记 Further Reading: 佛罗里达大学博生生自杀事件 翟天临不知知网 2019年1月31日，翟天临在新浪微博晒出自己获得北京大学光华管理学院博士后职位的通知书。2月，因翟曾在直播中发表言论“知网是什么东西”，被网友发现知网上无法查到其博士学位论文，并质疑其学历可能掺水或造假。翟天临就不识知网一事辩称自己当时只是在开玩笑。网友随后对翟2018年8月发表在《广电时评》杂志上的论文进行查重，发现全文存在大段抄袭现象。其中被抄袭最多的是黄立华教授2006年发表在《黄山学院学报》上的文章，亦引得原作者抨击。不久，翟天临的高考分数也遭到网友质疑。2019年2月14日，翟天临就学术风波发表致歉声明，并正式申请退出北大博士后科研流动站的相关工作。2月19日，北京电影学院发布微博表示，撤销翟天临博士学位，取消陈浥博导资格。 翟天临的学术风波导致中国各高校开始对学生的论文变得十分严格，众多院校甚至要求学生论文重复率在10%以下；网络上时有本科生研究生抱怨翟天临使得写论文不能再浑水摸鱼。同时，国内教育界将严查学术不端。 翟天临]]></content>
  </entry>
  <entry>
    <title><![CDATA[apt使用和配置的一些信息]]></title>
    <url>%2Fknowledge-base%2Fprogramming%2Fhow-to-install%2Fapt.html</url>
    <content type="text"><![CDATA[apt国内镜像 我一般都是使用清华大学开源软件镜像站提供的资源，对于Ubuntu16.04，设置方法如下： 修改文件/etc/apt/sources.list，不过之前最好将系统自带的该文件备份。新的文件的内容为： 16.0418.0414.04测试 ``` # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse 预发布软件源，不建议启用 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse ```undefinedundefined]]></content>
  </entry>
  <entry>
    <title><![CDATA[How to Install]]></title>
    <url>%2Fknowledge-base%2Fprogramming%2Fhow-to-install%2Findex.html</url>
    <content type="text"><![CDATA[How to Install这个章节整理了常用软件的安装方法。]]></content>
  </entry>
  <entry>
    <title><![CDATA[如何安装Python]]></title>
    <url>%2Fknowledge-base%2Fprogramming%2Fhow-to-install%2Fpython.html</url>
    <content type="text"><![CDATA[Ubuntu 安装Python python3.7 以下安装脚本在Ubuntu 16.04上测试通过，引用自How to Install Python 3.7 on Ubuntu 18.04 123456789101112sudo apt updatesudo apt install software-properties-commonsudo add-apt-repository ppa:deadsnakes/ppa# When prompted press Enter to continue:sudo apt install python3.7python3.7 -v# 这里安装后只有python3.7的命令可以用，为了使用python命令，使用如下命令sudo ln -s $(which python3.7) /usr/bin/python 在sudo add-apt-repository ppa:deadsnakes/ppa命令中可能出现/etc/apt/sources.list文件无法访问问题。如果你改用了国内镜像，其内容包含了中文的注释，那么这个错误可能是由于locale设置导致的。通过export LC_ALL=&quot;zh_CN.UTF-8&quot;可以消除这个问题。 注意，可以在安装pip的同时一并安装python3。详情见下面。 安装pip pip for python3.6 为Python3安装pip的方法如下： 12345$ sudo apt update$ sudo apt install python3-pip$ pip3 --versionpip 9.0.1 from /usr/lib/python3/dist-packages (python 3.6) 注意，按照这种方法会连通python3一起安装。如果你用上面的方法安装了python3.7，那么在运行上面的脚本以后会同时存在3.7和3.6两个版本的python. pip for python3.7 经过实验，比较保险可靠的是如下的方法： 首先按照前面的方法安装好Python3.7 执行下面的命令： 1curl -s -L https://bootstrap.pypa.io/get-pip.py | sudo python3.7 如果不需要在全局安装python3.7的pip工具，只是在虚拟环境中使用的话，直接使用python3.7创建虚拟环境就可以了，虚拟环境中的pip会自动安装。虚拟环境的创建方法范例见下： 1virtualenv -p $(which python3.7) env 注意这个方法安装的pip会强制覆盖已有的pip pip for python2 为python2安装pip的方法如下： 123sudo apt updatesudo apt install python-pippip --version 同样，上面的脚本也会自动安装python2及其他必要的依赖。 pip的国内镜像配置方法 我这里使用清华大学开源软件镜像站提供的资源。设置方法如下： 临时使用 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package 注意，simple不能少, 是https而不是http 设置为默认 升级 pip 到最新的版本 (&gt;=10.0.0) 后进行配置： 12pip install pip -Upip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple 如果您到 pip 默认源的网络连接较差，临时使用本镜像站来升级 pip： 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U Reference How to Install pip for python 3.7 on Ubuntu 18? get-pip.py]]></content>
  </entry>
  <entry>
    <title><![CDATA[AWK]]></title>
    <url>%2Fknowledge-base%2Fprogramming%2Flinux-shell%2Fawk.html</url>
    <content type="text"><![CDATA[这篇文章转载自Linux三剑客老大 awk 概述 awk同sed命令类似，只不过sed擅长取行，awk命令擅长取列。（根据了解awk是一种语言，不过我们只关注他处理文本的功能，用的好的话几乎可以取代excel） 原理：一般是遍历一个文件中的每一行，然后分别对文件的每一行进行处理 用法: 1awk [可选的命令行选项] 'BEGIN&#123;命令 &#125; pattern&#123; 命令 &#125; END&#123; 命令 &#125;' 文件名 打印某几列 12$ echo 'I love you' | awk '&#123;print $3 $2 $1&#125;'youloveI 我们将字符串 I love you 通过管道传递给awk命令，相当于awk处理一个文件，该文件的内容就是I love you,默认通过空格作为分隔符(不管列之间有多少个空格都将当作一个空格处理)I love you就分割成三列了。 假如分割符号为 . ，可以这样用 12$ echo '192.168.1.1' | awk -F "." '&#123;print $2&#125;'168 条件过滤 我们知道awk的用法是这样的，那么pattern部分怎么用呢？ 12345678awk [可选的命令行选项] 'BEGIN&#123;命令 &#125; pattern&#123; 命令 &#125; END&#123; 命令 &#125;' 文件名$ cat score.txttom 60 60 60kitty 90 95 87jack 72 84 99$ awk '$2&gt;=90&#123;print $0&#125;' score.txtkitty 90 95 87 $2&gt;=90 表示如果当前行的第2列的值大于90则处理当前行，否则不处理。说白了pattern部分是用来从文件中筛选出需要处理的行进行处理的，这部分是空的代表全部处理。pattern部分可以是任何条件表达式的判断结果，例如&gt;，&lt;，==，&gt;=，&lt;=，!=同时还可以使用+，-，*，/运算与条件表达式相结合的复合表达式，逻辑 &amp;&amp;，||，!同样也可以使用进来。另外pattern部分还可以使用 /正则/ 选择需要处理的行。 判断语句 判断语句是写在pattern{ 命令 }命令中的，他具备条件过滤一样的作用，同时他也可以让输出更丰富 123456$ awk '&#123;if($2&gt;=90 )print $0&#125;' score.txtkitty 90 95 87$ awk '&#123;if($2&gt;=90 )print $1,"优秀"; else print $1,"良好"&#125;' score.txttom 良好kitty 优秀jack 良好 BEGIN 定义表头 1awk [可选的命令行选项] 'BEGIN&#123;命令 &#125; pattern&#123; 命令 &#125; END&#123; 命令 &#125;' 文件名 使用方法如下： 12345$ awk 'BEGIN&#123;print "姓名 语文 数学 英语"&#125;&#123;printf "%-8s%-5d%-5d%-5d\n",$1,$2,$3,$4&#125;' score.txt姓名 语文数学英语tom 60 60 60kitty 90 95 87jack 72 84 99 这里要注意，我为了输出格式好看，做了左对齐的操作(%-8s左对齐，宽8位)，printf用法和c++类似。 不仅可以用来定义表头，还可以做一些变量初始化的工作，例如 12$ awk 'BEGIN&#123;OFMT="%.2f";print 1.2567,12E-2&#125;'1.26 0.12 这里OFMT是个内置变量，初始化数字输出格式，保留小数点后两位。 END 添加结尾符 和BEGIN用法类似 123$ echo ok | awk '&#123;print $1&#125;END&#123;print "end"&#125;'okend 数据计算 这个地方我要放大招了！上面的知识点你都记住了吗？ 1234567891011$ awk 'BEGIN&#123;print "姓名 语文 数学 英语 总成绩"; \sum1=0;sum2=0;sum3=0;sumall=0&#125; \&#123;printf "%5s%5d%5d%5d%5d\n",$1,$2,$3,$4,$2+$3+$4;\sum1+=$2;sum2+=$3;sum3+=$4;sumall+=$2+$3+$4&#125;\END&#123;printf "%5s%5d%5d%5d%5d\n","总成绩",sum1,sum2,sum3,sumall&#125;'\ score.txt姓名 语文 数学 英语 总成绩 tom 60 60 60 180kitty 90 95 87 272 jack 72 84 99 255总成绩 222 239 246 707 因为命令太长，末尾我用。。 BEGIN体里我输出了表头，并给四个变量初始化0 pattern体里我输出了每一行，并累加运算 END体里我输出了总统计结果 当然了，一个正常人在用linux命令的时候是不会输入那么多格式化符号来对齐的，所以新命令又来了 column -t（鬼知道我为什么会记得这么多乱七八糟的命令。） 图1 有用的内置变量 NF:表示当前行有多少个字段，因此$NF就代表最后一个字段 NR:表示当前处理的是第几行 FILENAME：当前文件名 OFMT：数字输出的格式，默认为％.6g。表示只打印小数点后6 位 123456$ awk -F ':' '&#123;print NR ") " $1&#125;' demo.txt1) root2) daemon3) bin4) sys5) sync 内置函数 awk定义了很多内置函数，用awk来写shell脚本倒是一个不错的选择，但是大多数我们是用不上的，以下是常用函数 123$ echo 1 2 | awk '&#123;print $1+sqrt($2)&#125;'2.41421 随机数，先设置种子再随机 rand() 0 &lt;= n &lt; 1,srand([expr])将 rand 函数的种子值设置为 Expr 参数的值，或如果省略 Expr 参数则使用某天的时间。 123$ echo 1 | awk 'BEGIN&#123;srand()&#125;&#123;print rand()&#125;'0.929885 字符串 图2 系统常用 图3 不常用算数： 图4]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux Shell]]></title>
    <url>%2Fknowledge-base%2Fprogramming%2Flinux-shell%2Findex.html</url>
    <content type="text"><![CDATA[这个章节整理Linux命令行环境的工具的使用方法]]></content>
  </entry>
  <entry>
    <title><![CDATA[车辆编队体系研究]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fplatoon%2Findex.html</url>
    <content type="text"><![CDATA[前言 车辆编队(platoon)是指多辆车，借助于车载传感器，车载计算机，车间通信系统等手段排成列或者更复杂的结构。编队系统可以减少车间距，提高道路承载能力。另一方面，基于空气动力学的特点，编队内车辆的阻力(aerodynamic drag)能够降低，从而降低能耗[1][2]。 本文的主体框架基于[3]。 编队的优势 以编队方式形式有如下优势： 编队内的车间距更小，故而可以提升道路承载能力(road capacity)，缓解交通拥堵。 由于空气阻力降低，行驶的能耗也得到了降低，汽车排放量也减少了。 在先进技术的辅助下，编队形式也能提升交通安全，提升驾驶/乘坐的舒适性、 由于编队内的相对位置固定，车辆间的协作通信应用的效率能够改进，提升车联网的性能。 Platoon as VCPS 这里的VCPS是指Vehicular Cyber-Physical System，CPS一般译为“赛博物理系统”，这个概念着重强调计算机及网络系统，与物理世界中的传感器和促动器(Acturator)的互动与联合。汽车编队可以视为是一种赛博物理系统。 Platoon as VCPS 从VCPS的角度看待编队系统，可以发现汽车编队的运动性能(mobility)和网络性能(VANETs)是彼此耦合，互相影响的。 文章条目 多编队系统 基于Platoon的车间通信(V2V)机制设计 Reference [1] M. Amoozadeh, H. Deng, C.-N. Chuah, H. M. Zhang, and D. Ghosal, “Platoon management with cooperative adaptive cruise control enabled by vanet,” Vehicular Communications, vol. 2, no. 2, pp. 110–123, 2015. [2] Han-Shue Tan, R. Rajamani, and Wei-Bin Zhang, “Demonstration of an automated highway platoon system,” in Proceedings of the 1998 american control conference. ACC (ieee cat. No.98CH36207), 1998, vol. 3, pp. 1823–1827 vol.3. [3] D. Jia, K. Lu, J. Wang, X. Zhang, and X. Shen, “A survey on platoon-based vehicular cyber-physical systems,” IEEE communications surveys &amp; tutorials, vol. 18, no. 1, pp. 263–284, 2016.]]></content>
  </entry>
  <entry>
    <title><![CDATA[多编队系统]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fplatoon%2Fmulti-platoon.html</url>
    <content type="text"><![CDATA[综述 这里说的多编队系统是指研究道路上多个相邻的编队系统组成的系统。编队之间的互动，以及如何协调编队间互动与编队内互动是这一系统的主要挑战。这里的互动可以指通信层面，运动层面，或者是对二者进行联合设计。 Reference]]></content>
  </entry>
  <entry>
    <title><![CDATA[延时分析]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fdelay-analysis.html</url>
    <content type="text"><![CDATA[在这篇文章中，我们利用之前提到过的二维马尔可夫模型针对传输延时进行分析。这篇文章主要参考了[1]这篇文章。该文章内的马尔科夫链中的变量定义和[2]中的有点不同。我们先梳理一下[1]中马尔科夫链。 二维马尔科夫过程 对于使用IEEE802.11 DCF机制的节点的退避过程，可以用如下图所示的二维马尔科夫链表示： 二维马尔科夫链表示 其中状态变量定义为\(\{s(t), b(t)\}\)，\(s(t)\in \{0, 1\}\)代表车辆是否有包等待发送。\(b(t)\in \{0, 1,2, \dots, W_e-1\}\)代表了退避计数器的值。进而马尔科夫链的转移概率为： \[\begin{equation} \left\{\begin{array}{l}{P\{0, k | 0, k+1\}=1-p, k \in\left[0, W_{s}-2\right]} \\ {P\{0, k | 0, k\}=p} \\ {P\{0, k | 0,0\}=p\left(1-G_{t}\right) / W_{s}} \\ {P\{1, k | 0,0\}=p G_{t} / W_{s}} \\ {P\{0, k | 1, k\}=G_{s}} \\ {P\{1, k | 1, k\}=1-G_{s}}\end{array}\right. \end{equation}\] 上面的公式中除了第一行，其他情况下\(k\in \{0, 1, 2,\dots,W_s - 1\}\)。\(G_t\)和\(G_s\)为恒定，且独立的值。 \(p\)为信道被感知为繁忙的概率（probability when a busy channel is sensed）。 \(G_t\)为安全消息在非竞争段产生的概率（在此区间内改包没法马上发送），\(G_s\)为安全消息可以进行发送的概率（即在竞争段产生的概率）。由于安全消息的生成速度是均匀的，则 \[\begin{equation} G_{t}=\frac{T_{t}+T_{\mathrm{SCH}}}{T_{\mathrm{CCH}} + T_{\mathrm{SCH}}} \\ \end{equation}\] \[\begin{equation} G_{s}=\frac{T_{c}}{T_{\mathrm{C} \mathrm{CH}}+T_{\mathrm{SCH}}} \end{equation}\] 我们进一步解释一下转移概率的各行的含义： 退避计数器减一，对应感知到信道空闲 退避计数器不变，对应感知到信道繁忙 退避计数器从0到k，s(t)的值不变为0，从概率计算的形式来看，是感知到信道为繁忙，且包生成的时间在竞争段。 退避计数器从0变成k，s(t)的值从0变成1， 从概率计算的形式来看，是感知到信道繁忙，且包生成在非竞争段（这时没法立刻发送），这个包进入等待队列。 s(t)变成0，意味着原先缓存的包现在可以参与发送了。 s(t)不变，对应当前时隙仍然不允许发送。 记平稳分布为：\(b_{i, k}=\lim_{t \rightarrow \infty} P\{s(t)=i, b(t)=k\}\), \(T&#39;_{ss}\) 为平均服务时间（排队论里的概念），那么任意车辆在任意时隙里面发送的概率是 \[\begin{equation} P_{\mathrm{uns}}^{\prime}=b(0,0)\left(1-e^{-\lambda_{s} T_{\mathrm{ss}}^{\prime}}\right) \end{equation}\] 发送延时 发送延时 有如下几个部分构成： 退避延时：\(T_{\mathrm{sf}}\) 传输延时(Transmission Delay)：\(T_{st}=L / R_{d}+T_{\mathrm{DIFS}}+\delta\)，其中\(\delta\)为信道传输延时(Propagation Delay) 队列等待延时：\(T_{sq}\) 总的延时为：\(T_{\mathrm{sd}}=T_{\mathrm{sq}}+T_{\mathrm{sf}}+T_{\mathrm{st}}\)。根据上面的马尔科夫过程，我们可以得到退避延时为： \[\begin{equation} \begin{aligned} E\left[T_{\mathrm{sf}}\right] &amp;=\sum_{i=0}^{W_{s}} \frac{\left(1-G_{t}\right) p}{W_{s}} \sum_{i=0}^{W_{s}}\left(p T_{t}\right)+\sum_{i=0}^{W_{s}} \frac{G_{t} p}{W_{s}} \sum_{i=0}^{W_{s}}\left[\left(1-G_{s}\right) T_{t}\right] \\ &amp;=\frac{p T_{t}\left(1-G_{t}\right)\left(W_{s}-1\right)\left(G_{t}+p\right)}{2} \end{aligned} \end{equation}\] 对于队列等待延时部分，为了保证系统的稳定性，需要有\(\lambda_{s} T_{\mathrm{serv}}&lt;1\)，其中\(\lambda_s\)为消息生成的速率，\(T_{\mathrm{serv}}=E\left[T_{\mathrm{sf}}\right]+T_{\mathrm{st}}\)。根据Pollaczek-Khintchine定理： \[\begin{equation} T_{\mathrm{sq}}=\frac{\lambda_{s} E\left[T_{\mathrm{serv}}^{2}\right]}{2\left(1-\lambda_{s} T_{\mathrm{serv}}\right)} \end{equation}\] Reference [1] B. Liu, D. Jia, K. Lu, D. Ngoduy, J. Wang, and L. Wu, “A joint control–communication design for reliable vehicle platooning in hybrid traffic,” IEEE Transactions on Vehicular Technology, vol. 66, no. 10, pp. 9394–9409, 2017. [2] G. Bianchi, “Performance analysis of the ieee 802.11 distributed coordination function,” IEEE Journal on Selected Areas in Communications, vol. 18, no. 3, pp. 535–547, 2000.]]></content>
  </entry>
  <entry>
    <title><![CDATA[动态控制发包频率]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fdynamic-beacon-interval.html</url>
    <content type="text"><![CDATA[在基于Platoon的车间通信(V2V)机制设计:动态调节网络参数我们也提到了这种控制理念：即根据网络的情况，动态的调整网络参数。对于Beacon包传输来说，在高负载的情况下，与其所有人仍然按照原来的发送速度，进而导致严重的冲突拖慢整体性能，不如整体所有人适当调低发送速度。 这篇文章研读总结自[1]。这篇文章主要是依据车流密度情况动态调整BSM(Basic Safety Message)的发送速率，算法被称为frequency adjustment with random epochs (FARE)。 BSM的发送 WAVE的标准中并未明确规定BSM消息的频率。不过在文献研究中，典型的BSM发送频率范围包含了1Hz [2]到10Hz [3]。 BSM信息一般放在CCH上发送。考虑到在没有进行额外的跨层优化设计时，BSM应用层无法感知底层信道状态，因此一些BSM包可能在SCHI上产生。此时MAC层会将这些包压入队列，等到CCHI时发送。如果在CCHI结束时仍然未能发送出去，这个BSM消息会被丢弃。 FARE 在FARE机制中，应用会维护一整套名为的epochs的抽象时间结构，代表了BSM传输的时间线。每个epoch对应一个BSM传输。每个epoch的长度取决于BSM的传输时间（一个250Bytes的BSM包，在3Mb/s的带宽上，需要大约1ms来传输）。在确定epoch的长度以后，每个车辆选择一个epoch来传输BSM包。这里我们选择1ms作为epoch的长度，那么一个SI（同步间隔）内的，大约有92个epoch（去掉Guard Interval）。 尽管应用层并不知晓信道状态，但是因为按照WAVE规范，SI需要对齐到UTC的秒时刻，因此应用层可以通过GPS等外源时钟来将epochs和SI的起始时刻对齐。 Epochs建立起了一套应用层的时间尺度，相比于物理层和MAC层的实际时间尺度，二者观察到的现象会有一定的区别，如下图： Example of the application-layer view of the BSM transmission activities on the MAC layer 应用层和MAC层视角的主要差别在于，应用层无法区分“信道空闲”和“信道冲突”两种现象。 从应用层感知CCHI 之前我们说到了由于缺乏跨层信道，应用层无法感知到CCHI，不知道其开始和结束。对于CCHI的开始时刻，我们可以通过利用SI与UTC秒对齐的特性来发现，而CCHI的结束时刻还需要特别的机制来发现。 在WAVE标准中确定了多种CCH和SCH访问的方式，二者长度并非总是50ms 记\(\hat{E}_{\max }\)为现在已经收到的时间轴上一个SI内最右侧的BSM的Epoch，那么设定如下的BSM发送时刻决定策略： \[\begin{equation} \label{1} e \leftarrow \mathcal{R}\left[0 \ldots \hat{E}_{\max }+1\right] \end{equation}\] 其中\(\mathcal{R}\)为随机数发生器。如果节点目前还没有任何关于CCHI的信息（无法确定\(\hat{E}_{\max }\)），那么节点干脆随机选择。这种随机散布策略有助于快速找到CCHI的右侧边缘。下面的图演示了收敛速度： BSM transmitting times fast converging to the CCHI 实际的收敛速度还取决于负载情况：负载越高，收敛越快。 估计车流密度 核心设计思路是，在\(\eqref{1}\)的随机选择Epoch方式场景下，我们可以根据下面的两个观测特征来确定指定车辆通信范围内的车辆数量： 车辆成功将BSM广播给周围车辆的概率\(P_1\)，即PDR(Packet Delivery Ratio)； 车辆在连续两个CCHI内成功发送BSM的概率\(P_2\)。 从应用层的Epochs角度，即在一个SI内，收到的BSM的数量是\(E \cdot P_1\)，其中\(E \equiv \widehat{E}_{\mathrm{max}}\)为CCHI内的Epochs总数。由于从应用层无法分辨信道空闲和碰撞，光有\(P_1\)还不够。接下来考虑\(P_2\)，有\(P_2 = P_1^2\)。 假设观测车辆的通信范围内有\(V\)辆车，所有车辆的BSM发送频率为\(f = 1 / SI\)。在CCHI内竞争获胜，即成功发出去的包的数量是\(L_1 = P_1 \cdot V\)。那么连续两个CCHI内斗发送成功的包的数量是\(L_{2}=P_{2} \cdot V=P_{1}^{2} \cdot V\)。 那么车辆数量\(V\)可以通过如下方法进行估计： \[\begin{equation} \widehat{V}=L_{1}^{2} / L_{2} \end{equation}\] 由于车辆可以连续的观测多个CCHI，使用最近观测到的\(d\)个CCHI数据来进行观测可以得到，在第\(j\)个CCHI \[\begin{equation} L_{x}=\sum_{i=j-d+1}^{j} L_{x}[i] / d, x = 1, 2 \end{equation}\] 这里我们选择\(d = 5\)。 注意上面的估计方法在满载情况下会有问题 决定最佳BSM广播频率 记\(f_{\max}\)为BSM的最大允许发送速率。当车流密度比较稀疏的时候，\(f_{\max}\)为限制BSM发送速度的唯一限制。此时Epochs大部分都是空闲的。当车流密度上升时，会有多辆车在同一个Epoch进行发送，这导致冲突，BSM发送失败。为了降低冲突的概率，车辆需要降低广播的频率。 记最佳的广播频率为\(f_{\mathrm{opt}}\)，在这个发送频率下的\(L_1\)能够达到最大值。为了决定\(f_{\mathrm{opt}}\)，我们需要开率MAC特点，Epoch选择以及发送频率调控。 我们假设Epoch的的总是是\(E\)，车辆数量为\(V\)，每辆车每个周期还惨胜一个BSM包。\(V \ge E\)。如果每辆车选择Epoch是完全随机的，那么\(k \ge 0\)辆车选择了同一个Epoch的概率是\(A_{k}=e^{-\alpha} \alpha^{k} / k !\), 其中\(\alpha = V / E\)为其平均值。我们希望\(k=1\)时对应的概率尽可能的大。即最大化\(E_{1}=A_{1} \cdot E=V e^{-V / E}\)。对其微分并令其等于0得到 \[\begin{equation} E_{1}^{\prime}=e^{-V / E}(1-V / E)=0 \Rightarrow V= E. \end{equation}\] 代入\(V=E\)的情况我们可以得到\(A_1 = e^-1 \approx 36.8%\)，即只有大约三分之一的包能够无冲突地发送。\(A_0 = A_1\)，三分之一的Epoch空闲，剩余的不到三分之一产生了冲突。 不过这里的分析没有考虑竞争过程，即产生冲突的Epoch也可能发送成功的。 因此容易得到发送速率应该为\(f_{\mathrm{target}} = E / V\)。因此我们可以得到一个可以由车辆本地执行的决定\(f_{\mathrm{opt}}\)的算法，这一算法过程如下(\(\mathcal{U}_{T}\)为被观测到的在CCHI T中发送BSM数据的车辆的集合): \(L_{1} \leftarrow \sum_{i=0}^{d-1}\left|\mathcal{U}_{T-i}\right| / d\) \(L_{2} \leftarrow \sum_{i=0}^{d-1}\left|\mathcal{U}_{T-i-1} \cap \mathcal{U}_{T-i}\right| / d\) \(\widehat{V} \leftarrow L_{1}^{2} / L_{2}\) \(f_{\text { target }} \leftarrow E / \widehat{V}\) Reference [1] Y. Park and H. Kim, “Application-level frequency control of periodic safety messages in the ieee wave,” IEEE Transactions on Vehicular Technology, vol. 61, no. 4, pp. 1854–1862, 2012. [2] Tonguz*O., Wisitpongphan*N., F. Bait, P. Mudaliget, and V. Sadekart, “Broadcasting in vanet,” in 2007 mobile networking for vehicular environments, 2007, pp. 7–12. [3] D. Committee and others, “Dedicated short range communications (dsrc) message set dictionary,” SAE Standard J, vol. 2735, p. 2015, 2009.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Wireless Access in Vehicular Environments (WAVE)]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Findex.html</url>
    <content type="text"><![CDATA[WAVE的全称是Wireless Access in Vehicular Environment，是目前车联网通信的标准。 WAVE协议内容及特点 WAVE标准中的Beacon性能简化分析 IEEE802.11 DCF中Basic Access和RTS/CTS机制的理论饱和吞吐率性能差异分析 WAVE中的SCH调度机制研究状况 通信范围模型探讨 ns3中的wave模块 ns3中的Attribute系统的使用 无线技术大讲堂：这是一个知乎专栏的，里面涉及到了非常多的802.11协议内容分析 CWNP系列教材下载 延时分析 动态控制发送速率 马尔科夫链在WAVE网络性能分析中的应用 三维马尔科夫链的详细调研 一维马尔科夫过程的使用]]></content>
  </entry>
  <entry>
    <title><![CDATA[IEEE802.11 DCF中Basic Access和RTS/CTS机制的理论饱和吞吐率性能差异分析]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fperformance-of-bas-and-rts.html</url>
    <content type="text"><![CDATA[性能差异分析 在Wireless Access in Vehicular Environments (WAVE)文章的3.4章节我们梳理了对IEEE802.11 DCF机制的性能推导。通过推导的结论我们发现使用了RTS/CTS机制之后，相比于Basic Access手段，饱和吞吐率的性能有了大幅度的改进，如下图： 饱和吞吐率与节点数量的关系 注意到在3.4.4中给出的一般形式的饱和吞吐率对于Basic Access以及RTS/CTS机制是一样。两种机制的主要区别在于\(T_c\)和\(T_s\)的区别，如下图所示： \(T_c\)和\(T_s\) 考虑到ACK, RTS, CTS这些包的体积非常小，因此Basic Access和RTS/CTS机制的区别在于\(T_s\)和\(T_c\)的相对大小不同。在Basic Access中两个值非常接近，而在RTS/CTS中两个值的差别非常大。 \[\begin{equation} \label{1} S=\frac{P_sP_{tr}E[P]}{(1-P_{tr})\sigma+P_{tr}P_sT_s+P_{tr}(1-P_s)T_c} \end{equation}\] 上面的式子中，\(P_{tr}P_s=n\tau (1-\tau)^{n-1}\)随着\(n\)增加而递减。\(P_{tr}\)随着\(n\)增加而趋向于1，则分母项中，随着\(n\)升高，前两项都趋向于0，后一个趋向于\(T_c\)。可见\(T_c\)的值决定了最后下降的速度。 分母的形式其实很类似于两级lerp function，即从形状上来看，分母的取值从\(\sigma\)出发，逐渐靠近\(T_s\)，最终收拢到\(T_c\)。下图有助于理解： 上图其实是bezier曲线的原理示意图，出处是贝塞尔曲线原理（简单阐述） 混合性能 这里说的混合性能是指同时存在Basic Access和RTS/CTS的情况。具体的，如果包的大小超过了阈值\(\overline{P}\)，那么采用RTS/CTS发送，否则应用Basic Access规则。 记\(F(\cdot)\)为包大小的累积概率分布，那么\(F(\overline{P})\)就为Basic Access发送的概率，\(1-F(\overline{P})\)为使用RTS/CTS发送的概率。记: \[\begin{equation} O_{\mathrm{rts}}=T_{s}^{\mathrm{rts}}-T_{s}^{\mathrm{bas}}=\mathrm{RTS}+\mathrm{SIFS}+\delta+\mathrm{CTS}+\mathrm{SIFS}+\delta \end{equation}\] 为RTS/CTS需要付出的额外传输开销。那么很容易有: \[\begin{equation} \begin{aligned} T_{s} &amp;=T_{s}(\overline{P})=T_{s}^{\mathrm{bas}} F(\overline{P})+T_{s}^{\mathrm{rts}}(1-F(\overline{P})) \\ &amp;=T_{s}^{\mathrm{bas}}+O_{\mathrm{rts}}(1-F(\overline{P})) \end{aligned} \end{equation}\] 为了进一步推导，我们做一定的简化，忽略掉超过两个包发生碰撞的概率。那么，碰撞的可能情形就被约束到下面的三个类别： 两个RTS帧碰撞，概率(条件概率)为\((1-F(\overline{P}))^2\); 两个普通帧（Basic Access）的碰撞，概率为\(F(\overline{P})^2\)； 普通帧和RTS之间的碰撞 这涉及到三种不同的\(T_c\)：\(T^{rts/rts}\), \(T^{bas/bas}\), \(T_c^{bas/rts}\)。基于上面总结的条件概率我们可以计算平均碰撞时间如下： \[\begin{equation} \begin{aligned} T_{c}(\overline{P})=&amp;(1-F(\overline{P}))^{2} T_{c}^{\mathrm{rts} / \mathrm{rts}} \\ &amp;+2 F(\overline{P})(1-F(\overline{P})) T_{c}^{\mathrm{rts} / \mathrm{bas}}+F^{2}(\overline{P}) T_{c}^{\mathrm{bas} / \mathrm{bas}} \end{aligned} \end{equation}\] 记\(O_{h}=\left(T_{c}^{\mathrm{bas}}-P-T_{c}^{\mathrm{rts}}\right)=(H-\mathrm{RTS})\)为数据帧的Header相比于RTS的额外长度。\(\alpha=H+\mathrm{DIFS}+\delta\)。在WAVE: \(T_s\)和\(T_c\)的确定中，我们已经计算得到了： \[\begin{equation} T_{c}^{\mathrm{rts} / \mathrm{rts}}=\mathrm{RTS}+\mathrm{DIFS}+\delta=\alpha-O_{h} \end{equation}\] 为了计算RTS帧和数据帧的冲突时间，考虑到RTS的大小总是小于数据帧的大小，那么上面我们定义的\(O_h\)始终为正值。故这个平均冲突时间是由Basic Acces的数据帧的平均长度决定，从而有： \[\begin{equation} T_{c}^{\mathrm{rts} / \mathrm{bas}}=\alpha+\int_{0}^{\overline{P}}\left(1-\frac{F(x)}{F(\overline{P})}\right) d x \end{equation}\] 此处\(F(x) / F(\overline{P}), x \in(0, \overline{P})\)为Basic Access发送时的包大小的条件概率。最后，对于Basic Access的数据包之间的冲突问题： \[\begin{equation} T_{c}^{\mathrm{bas} / \mathrm{bas}}=\alpha+\int_{0}^{\overline{P}}\left(1-\frac{F^{2}(x)}{F^{2}(\overline{P})}\right) d x \end{equation}\] 最终我们可以得到整体的平均冲突时间为： \[\begin{equation} \begin{aligned} T_{c}(\overline{P})=&amp; \alpha-(1-F(\overline{P}))^{2} O_{h} \\ &amp;+2 F(\overline{P})(1-F(\overline{P})) \int_{0}^{\overline{P}}\left(1-\frac{F(x)}{F(P)}\right) d x \\ &amp;+F^{2}(\overline{P}) \int_{0}^{\overline{P}}\left(1-\frac{F^{2}(x)}{F^{2}(P)}\right) d x \end{aligned} \end{equation}\]]]></content>
  </entry>
  <entry>
    <title><![CDATA[WAVE标准中的Beacon性能简化分析]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fperformance-analysis-of-beacon.html</url>
    <content type="text"><![CDATA[在很多使用WAVE作为车联网通信标准的文献研究中[1] [2]，在遇到Beacon时通常会简化其退避过程。由于Beacon的生命周期有限，无法接受无止限的退避。在IEEE802.11 DCF中，在一轮退避完成后节点会尝试发包，如果发包失败，则会将其竞争窗口加倍。由于发送失败需要经过ACK来确认.因此广播包只能进行一轮退避。此时Beacon的发送过程可以简化为一维马尔科夫过程。 广播包的一维马尔科夫链 [3] 非马尔科夫链方法 不使用马尔科夫链的方式整理自[1]. 这篇文章主要的贡献是设计了长度可变的CCHI。 System Model 在节点访问信道前，需要侦听信道处于空闲的时间超过DIFS。如果DIFS之后信道仍然空闲，那么节点可以立即开始发送。否则，节点需要进行一段退避(_Backoff Counter_)，Backoff Counter从\([0, W-1]\)中随机取出。\(W\)被称为退避窗口(_CW_)。Backoff Counter在每一段空闲的时隙结束后减一。当Backoff Counter递减至0时，节点开始访问信道。 考虑到： Backoff Counter的初始值不会为0； Guard Interval内信道被判定为繁忙。 因此在CCHI开始所有车辆都需要进行退避。 除了上面的描述之外，这篇文章的推导还包含如下前提假设： 完美的信道条件 通信链路对称 每个车辆的通信范围固定且相通 载波侦听范围和通信范围一致 CCH完全传输时间 假设各车退避过程独立，网络内任意节点之间的的距离不超过两跳?。 考虑概率\(P(l, n, w, k)\)表示\(n\)个车辆在CCHI开头产生了Beacon包，竞争窗口大小为\(w\)，第一次发送尝试为\(l-1\)，\(k\)辆车在第\(l\)个时隙尝试传输（\(k\leq n\)），此概率值为： \[\begin{equation} \begin{aligned} P(l, n, w, k)&amp;=\left(1-\frac{l-1}{w}\right)^{n} \cdot \left( \begin{array}{c}{n} \\ {k}\end{array}\right)\left(\frac{1}{w-l+1}\right)^{k}\left(1-\frac{1}{w-l+1}\right)^{n-k} \\ &amp;= \left( \begin{array}{c}{n} \\ {k}\end{array}\right) \cdot \frac{(w-l)^{n-k}}{w^n} \\ &amp;= \left( \begin{array}{c}{n} \\ {k}\end{array}\right) \cdot \left(1 - \frac{l}{w}\right)^{n-k} \cdot \frac{1}{w^{k}}. \end{aligned} \label{P} \end{equation}\] 考虑到Backoff Counter的最大值是\(w\)，完成所有Beacon包传输需要的平均时间为 \[\begin{equation} \label{T} T(w, n)=\sum_{l=1}^{w} \left\{\begin{array}{l}{P(l, n, w, 1)\left[T_{s}+T(w-l, n-1)\right]} \\ {+\sum_{k=2}^{n} P(l, n, w, k)\left[T_{c}+T(w-l, n-k)\right]}\end{array}\right\} \end{equation}\] 其中\(T_{s}=L / R_{d}+D I F S+\delta\)的代表了一次成功的传输持续的时间。其中\(L\)表示平均包大小，\(R_d\)表示系统的传输速率，\(\delta\)表示传输延时?。\(T_{c}=L / R_{d}+E I F S+\delta\)表示发生碰撞后的持续时间。 这里\(T_c\)的计算和我们在WAVE中提到的推导里的\(T_c\)的有点不同，这里可以认为是所有包的大小一致的特殊情形。 在\(\eqref{T}\)中，求和的第一项表示的是只有一个节点选择了最早的发送时刻，此时能够成功发送。后一项表示的是超过一个节点选择在最早的发送时刻传输，导致冲突。 记节点的总数是\(N\)，退避窗口的大小是\(W\)，则\(T(W,N)\)可以通过迭代求出。 当\(W\)和\(N\)比较小时，\(T(W,N)\)会小于50ms，那么多余的CCHI被浪费了。反之，当\(W\)和\(N\)比较大时，\(T(W,N)\)会大于50ms，那么会有包无法发送而丢失掉。 CCH丢包率 我们定义\(L(W,N)\)为在一个CCHI内发生碰撞的包的数量。则 \[\begin{equation} \label{L} L(w, n)=\sum_{l=1}^{w} \left\{\begin{array}{l}{P(l, n, w, 1) \cdot L(w-l, n-1)} \\ {+\sum_{k=2}^{n} P(l, n, w, k)[k+L(w-l, n-k)]}\end{array}\right\} \end{equation}\] 根据\(\eqref{P}\)和\(\eqref{L}\)，通过迭代计算可以给出丢包率： \[\begin{equation} \label{packet-loss-rate} P(W, N)=\frac{L(W, N)}{N} \end{equation}\] 数值计算\(P(W, N)\)的值发现，丢包率即便在通常的的\(W\)和\(N\)取值内也非常高。通过提升竞争窗口可以改善这个丢包率，但是考虑到事实上CCHI的长度是有限的，而提高竞争窗口会推高\(\eqref{T}\)的值。如果将总传输时间\(T(W,N)\)值推高到50ms以上，那么50ms后续的包都会丢掉。综上可见，丢包率的改善是有上限的，且这个上限可能并不会达到100%. 马尔科夫链方法 马尔科夫链主要参考是的是[2]. Reference [1] L. Zhang, Z. Liu, R. Zou, J. Guo, and Y. Liu, “A scalable csma and self-organizing tdma mac for ieee 802.11 p/1609. X in vanets,” Wireless Personal Communications, vol. 74, no. 4, pp. 1197–1212, 2014. [2] K. A. Hafeez, L. Zhao, B. Ma, and J. W. Mark, “Performance analysis and enhancement of the dsrc for vanet’s safety applications,” IEEE Transactions on Vehicular Technology, vol. 62, no. 7, pp. 3069–3083, 2013. [3] V. Nguyen, O. T. T. Kim, C. Pham, T. Z. Oo, N. H. Tran, C. S. Hong, and E. Huh, “A survey on adaptive multi-channel mac protocols in vanets using markov models,” IEEE Access, vol. 6, pp. 16493–16514, 2018.]]></content>
  </entry>
  <entry>
    <title><![CDATA[WAVE中的SCH调度机制研究状况]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fsch.html</url>
    <content type="text"><![CDATA[WAVE协议中指定了CCH和SCH两种信道。在这个页面我们梳理一下现有的学术界对于如何调度使用SCH信道的机制研究。 在SCH上进行调度（W-HDF） 以下部分整理自[1]，这篇文章提出了一个名为W-HCF(WAVE-based Hybrid Coordination Function)的信道访问机制。该机制优化的目标是非安全类应用。 WAVE DCF机制的主要问题在于无法保证带宽和延时性能。这对于特定的应用是难以忍受的（如多媒体串流）。W-HCF机制的核心在于针对非安全类应用，区分QoS敏感和QoS不敏感的业务类型，并且针对这两种业务采取不同的SCH访问控制策略。 对于QoS不敏感的业务，W-HCF保留了WAVE标准中的特点： 简化的WBSS结构，不需要认证(Authentication)和关联(Association)过程； EDCA on SCHI 而对于QoS敏感的业务，需要一些额外的机制来保证带宽和延时性能。W-HCF提出的这些机制和WAVE完全兼容的。 对于QoS敏感的服务的提供者，其必须要知道对其提供的服务感兴趣的用户，并且有能力为这些资源预留资源。这些欲求意味着： 对服务感兴趣的用户需要显式地(explicitly)发送消息来加入WBSS； 服务的提供者需要显式地预留资源来确保相关用户访问服务时能够有无竞争的资源访问； 要有机制确保只有目标用户还在服务提供者的覆盖范围内时才进行Polling (Polling的含义见下面的过程描述第五点) 在竞争性的服务提供者之间建立协作机制，以避免无干扰的WBSS（通过使用不同的SCH信道或者是利用TDMA） W-HDF的主要过程如下： Q-WBSS初始化。在CCHI，Q-pr广播QoS-Enhanced WAVE Service Advertisements (Q-WSA) 来创建Q-WBSS。Q-WSA是对于原始WSA信息的扩展； A Gossip-based distributed CAP reservation scheme: 减少临近的Q-pr之间的干扰和冲突。这里的CAP是指controlled access period User registration and TXOP negotiation: 在SCH上，Q-users向Q-pr请求分配CAP资源； Controlled data transfer: 在SCH上，CAP阶段和竞争阶段交替。CAP的起始时间和持续时间由Q-pr控制。 基于位置的Polling：这里的Polling指由Q-pr主动，向多个用户拉取数据的过程。Q-pr会根据车辆的位置和速度来决定是否进行Polling，从而避免资源浪费（例如不要从已经不在Q-pr覆盖范围内的用户上拉取数据） 上面步骤中的缩写含义为：Q-pr: QoS Provider，Q-user: QoS User。 Q-WBSS初始化 Q-WBSS是围绕着Q-pr建立的，因此Q-WBSS的初始化实质就是Q-pr初始化的过程。Q-pr在CCH上通过EDCA的规则来尝试通过广播Q-WSA信息来占用信道。Q-WSA在原始WSA包的基础上新增了两个字段：CAP频段和4个字节的Own_SCH_Allocation字段。这一四字节字段包含两个两字节的子字段：CAP_start, CAP_duration。前者是预留的Contention-Free的CAP阶段的开始时间，后者是为了满足用户通信需求的CAP持续时间。在初始化阶段，Q-pr并不知道潜在的用户数量，因此最初的广播只包含了Q-pr自身的通信需求（主要是Beacon）。 作为广播，Q-pr在广播后不会收到任何反馈，作者在这里说可以通过多次广播来提高可靠性 Gossip-based distributed CAP reservation Reference [1] M. Amadeo, C. Campolo, and A. Molinaro, “Enhancing ieee 802.11p/wave to provide infotainment applications in vanets,” Ad Hoc Networks, vol. 10, no. 2, pp. 253–269, 2012.]]></content>
  </entry>
  <entry>
    <title><![CDATA[通信范围模型探讨]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2F%E9%80%9A%E4%BF%A1%E8%8C%83%E5%9B%B4%E6%A8%A1%E5%9E%8B%E6%8E%A2%E8%AE%A8.html</url>
    <content type="text"><![CDATA[前言 我们这里探讨对于通信模型的认识。一般来说，最简单的通信模型是截断模型，即在一定的距离范围内通信总是可靠，而超出这一范围之外丢包率变成100%. 这里我们更加细致地讨论一下更为符合实际条件的通信范围模型[1]。 System Model 在进行理论分析前有必要给出我们使用的System Model。这里的System Model与[1]中的系统模型是一致的。 注意，在这里我们整理了所有参考文章中提出的系统模型假设，不过并不是所有的假设都会用于本文的分析内容。 对于VANETS中的安全类应用，车辆会广播两种类型的信息： Warning Message (Event driven): 事件驱动的警告信息。例如前方突然发生了碰撞，周围的车辆会产生对应的warning message来警告后续的车辆； Status Message。状态信息是周期性发送的，其中包含了车辆的运行状态（位置，速度，加速度，行驶方向等）。 这里Warning message使用最高的优先级AC3(参见EDCA)，周期性播报的状态消息则使用AC0. 在我们的模型中，假设状态消息产生的速度是\(\lambda_s\)，那么同步间隔SI长度为\(1/\lambda_s\)(每个同步周期产生一个状态包). 假设所有包的大小都是一致的，为\(L\)比特。为了简化分析假设整个SI都用于传输安全信息，即CCHI=SI。每辆车会随机选择SI中的一个时隙发送状态包，warning message则随着事件的发生随机产生。 假设所有的车辆发射功率都是\(P_t\)，对于接收方来说，若接收功率达到了门限\(P_{th}\)就认为能够成功地收到数据包。由于信道衰减的随机性，接收功率也会是随机的，这意味着通信范围也是一个随机变量。通信范围的累积概率函数(CDF)\(F_R(r)\)及其期望\(E[R]\)会在后续进行推导。 变量以及缩略语表 通信范围 传输模型 VANET的信道衰减在近距离上服从Rician分布，在长距离上趋近于Rayleigh分布。通过使用Nakagami分布可以综合这两种情况。Nakagami模型的概率密度函数（PDF）如下： \[\begin{equation} \label{1} P_{z^{2}}(x)=\left(\frac{m}{P_{r}}\right)^{m} \frac{x^{m-1}}{\Gamma(m)} e^{-\frac{m x}{P_{r}}}, \quad \text { for } x \geq 0 \end{equation}\] 其中，\(x\)为接收到的信号功率，\(\Gamma(\cdot)\)为Gamma函数，\(P_{r}=P_{t} K / r^{\alpha}\)为平均接收功率，\(r\)为通信距离（米），\(\alpha\)为路径衰减指数。\(K=G_{t} G_{r}\left(C /\left(4 \pi f_{c}\right)\right)^{2}\)，其中\(C\)为光速，\(f_c=5.9 \text{GHz}\)为载波频率，\(G_t\)和\(G_r\)分别为发送者和接受者的天线增益。\(m\)为衰减系数。 当\(m=1\)时，Nakagami退化成Rayleigh分布，当\(m=(k+1)^2/(2k+1)\)时，Nakagami分布可以近似为参数为\(k\)的Rician分布（\(k\) is the ratio of power in the line of sight to the power in the non-line of sight）。 通过\(\eqref{1}\)，我们可以计算出当接收能量超过\(P_{th}\)时，通信范围的CDF： \[\begin{equation} \label{2} F_{R}(r)=1-P\left(x \geq P_{th}\right)=1-\int_{P_{th}}^{\infty} P_{z^{2}}(x) d x \end{equation}\] 将\(\eqref{1}\)代入到\(\eqref{2}\)，并记\(u=(m x) / P_r\)，CDF可以写作： \[\begin{equation} \label{3} F_{R}(r)=1-\frac{1}{\Gamma(m)} \int_{\frac{m P_{\mathrm{th}}}{P_{r}}}^{\infty} u^{m-1} e^{-u} d u \end{equation}\] 使用下面的积分变换： \[\begin{equation} \int x^{n} e^{c x} d x=\left(\frac{d}{d c}\right)^{n} \frac{e^{c x}}{c} \end{equation}\] CDF可以写成： \[\begin{equation} \label{5} F_{R}(r)=1-\frac{1}{\Gamma(m)} \sum_{i=0}^{m-1} \frac{(m-1) !}{(m-1-i) !}\left(\frac{m P_{\mathrm{th}}}{P_{r}}\right)^{m-1-i} e^{-\frac{m P_{\mathrm{th}}}{P_{r}}} \end{equation}\] 有了CDF以后，我们就可以计算通信范围的平均值\(E[R]\)了： \[\begin{equation} \begin{aligned} E[R]=\frac{1}{\alpha \Gamma(m)} \sum_{i=0}^{m-1} &amp; \frac{(m-1) !}{(m-1-i) !} \\ &amp; \times \Gamma\left(m-1-i+\frac{1}{\alpha}\right)\left(\frac{m P_{\mathrm{th}}}{P_{t} K}\right)^{-\frac{1}{\alpha}} \end{aligned} \label{6} \end{equation}\] 上面推导的是能够成功通讯的范围。对于载波侦听的范围\(E[L_{CS}]\)可以通过\(\eqref{6}\)类似的过程进行推导。这里载波侦听范围指的是节点可以感知到包（但是未必能够成功收到此包）的范围。我们认为当接收功率达到阈值\(P_{CS}\)时即可。记\(P_{CS}=\rho P_{th}\)，其中\(\rho \in (0, 1]\)。则有下面的关系： \[\begin{equation} E\left[L_{CS}\right]=\frac{E[R]}{\sqrt[\alpha]{\rho}} \end{equation}\] Reference [1] K. A. Hafeez, L. Zhao, B. Ma, and J. W. Mark, “Performance analysis and enhancement of the dsrc for vanet’s safety applications,” IEEE Transactions on Vehicular Technology, vol. 62, no. 7, pp. 3069–3083, 2013.]]></content>
  </entry>
  <entry>
    <title><![CDATA[中国中古史]]></title>
    <url>%2Fknowledge-base%2Fhistory%2F%E4%B8%AD%E5%9B%BD%E5%8F%B2%2F%E4%B8%AD%E5%8F%A4%E5%8F%B2%2Findex.html</url>
    <content type="text"><![CDATA[这里说的中古史其实不是历史学家们用的专门的概念。我这里用来指自秦朝统一后至1840年两千年时间内的历史。 秦汉 三国两晋南北朝 隋唐 五代 宋辽金 元 明 清]]></content>
  </entry>
  <entry>
    <title><![CDATA[中国近现代史部分的史料]]></title>
    <url>%2Fknowledge-base%2Fhistory%2F%E4%B8%AD%E5%9B%BD%E5%8F%B2%2F%E8%BF%91%E4%BB%A3%E5%8F%B2%2Findex.html</url>
    <content type="text"><![CDATA[中国近代史比较复杂，对于近代史认识，受到当前政治格局的影响很大，自然也有很多谬误。这里整理的材料，力图尽量为每一个史实论断提供多角度的论证依据。 以下按照时间大致分类一下。有一些纲领总括的内容单独列出。 按时间分类 晚清 北洋 民国（抗战前） 原始史料集 九一八事变前蒋张关于东北问题的讨论 常凯申微操集 民国（抗战） 民国（解放战争时期） 一共（1978年以前） 二共（1978年以后） 工程类 长江改道工程 淠史杭自流灌溉工程 中国近代史的一些有用的书籍史料 大陆方面 台湾方面 欧美方面 日韩及其他]]></content>
  </entry>
  <entry>
    <title><![CDATA[1996年朝鲜潜艇渗透事件]]></title>
    <url>%2Fknowledge-base%2Fhistory%2F%E6%9C%9D%E9%9F%A9%2F%E4%BA%8C%E6%88%98%E5%90%8E%E6%9C%9D%E9%B2%9C%2F1996%E5%B9%B4%E6%9C%9D%E9%B2%9C%E6%BD%9C%E8%89%87%E6%B8%97%E9%80%8F%E4%BA%8B%E4%BB%B6.html</url>
    <content type="text"><![CDATA[江陵潜艇渗透事件（朝鲜语：강릉지역 무장공비 침투사건／江陵地域 武裝共匪 侵透事件）是指于1996年9月朝鲜人民军特种部队为收集韩国情报，而使用鲨鱼级潜艇渗透至韩国东海岸的江陵市附近。由于渗透用的潜艇搁浅，参与行动的26名朝鲜士兵不得不弃艇，并从附近的海滩躲入附近的山林中隐藏。大韩民国国军和警察随即对他们展开时长两个多月的追捕，26名朝鲜人中仅2人存活，而韩国共有16人丧生（包括军警和百姓）、27人受伤。朝鲜的此次渗透行动虽以失败而告终，但也使外人得以一见朝鲜特种部队的训练水平和作战能力，但此次行动又使因粮食援助而渐走向缓和的朝韩关系再次走进紧张局势。 事件中搁浅的鲨鱼级潜艇 韩国军队登上朝鲜间谍潜艇 韩军组织兵力开始追捕朝鲜潜艇上的特工人员 9月18日约17时，韩国士兵到达潜艇搁浅处西南8公里的一座330米高的山顶空地上，发现11名朝鲜特工的尸体。 朝鲜11名特工自杀现场，其中的10具尸体肩并肩，排列成一条直线，而另外一具尸体（海军部金东源上校）在不远处的另一边，上校的手枪还放在枪套里。这些身亡的朝鲜人都穿便装和白网球鞋。 被俘虏朝鲜间谍潜艇舵手李光素 进一步阅读： 朝韩秘密战：96年朝鲜特种部队对韩国秘密潜入 维基百科：江陵潜艇渗透事件]]></content>
  </entry>
  <entry>
    <title><![CDATA[基于Platoon的车间通信(V2V)机制设计]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fplatoon%2Fplatoon-v2v.html</url>
    <content type="text"><![CDATA[编队内通信机制 为了维持编队结构，编队内部的成员需要周期性的交换其运动参数，即Beacon message dissemination。目前车联网通信的标准是WAVE。这里我们简要叙述一下WAVE的核心特点。 我们需要关注的WAVE的最为核心的两个标准是IEEE802.11p和IEEE1609.4。其中，前者规定了MAC层和物理层的标准，后者提供了多信道仿真的规范。WAVE在物理层上拥有7个信道，包括一个控制信道CCH和六个服务信道SCH。CCH上不能用于发送IP包。一般而言，控制帧和安全相关的重要信息在CCH上传输，而SCH用于传输非安全信息。依照IEEE1609.4的规定，信道访问时间被切分为100ms长的同步间隔SI，SI内部又分为50ms的CCH访问时间和50ms的SCH访问时间。 由于通信资源有限，当车流密度增大时，信道会出现拥堵，导致通信的可靠性(广播效率，丢包率)下降，进而威胁到行程安全。由于CCH信道只有一个且用于传输重要的控制和安全信息，所以研究者一般关注CCH上的通信性能可靠性。 另一方面，当车流密度很低时，CCH信道的资源会限制，不利用充分的信道利用。 以下是解决这些问题的常见策略： 引入非竞争协议（如TDMA）来保证Beacon性能 调节网络参数来优化性能（如调整Beacon间隔，竞争窗口大小等） 引入竞争协议 引入非竞争协议后，汽车一般会被分簇，在簇内由簇头来进行同步和通信资源分配，从而确保消息在发送时，发送者对于信道的独占，这样可以最大程度地保证消息发送的可靠性。不过，这种机制的缺陷还是很明显的： 协同和资源分配的机制一般比较复杂 引入了额外的Overhead开销 在大规模网络环境下难以使用，例如涉及到多跳问题时，TDMA的同步和资源分配机制的实现复杂度会远远高于单跳场景。很多文章都是假定簇的大小不会超过单跳范围来规避这个问题。 在大规模网络环境下，另一个问题是时隙资源不够划分之后采用如何策略来保持性能和网络公平性 动态调节网络参数 这类方法通常不需要对WAVE原有的协议作出大的修改，也不需要同步和协同，可以进行本地决策。不过其缺点在于为了得到网络环境与待调节的网络参数的关系，需要使用非常复杂的数学模型工具。 基于具体业务形态的设计 很多研究都是着眼于提升网络的整体性能，而非聚焦到具体的业务场景。例如在编队场景中，为了改善网络的性能，可以考虑编队的拓扑结构。这一方面的研究还比价少，不过这类研究也比较困难，因为车联网中的具体业务还很少，如何构合理地构建业务场景其实是缺乏一个坚定的共识的。 编队间通信机制 车里编队间的通信问题是一个更加宏观的问题。在编队内部我们可以拥有一个非常稳定的拓扑结构，因而可是实现一些需要很高的协同性支持的机制。而在编队间通信问题上，我们就需要处理一些传统车联网场景关注的问题，如VANET connectivity以及链路质量。同时，数据分发过程中的路由问题也需要考虑。 VANET connectivity 目前对于车联网中车间通信的网络连接性的问题还是主要围绕着自由车辆（即非编队车辆）进行[1]，一般的结论是随着车流量的增加VANET的连通性能够得到改善。[2]中讨论了基于编队系统的车联网连通性问题。作者从VCPS的角度来讨论这个场景下的问题，这意味着对于运动和网络性能的联合分析。这也是分析网络连通性的通常做法。 双向道路上的多编队系统示意图 Platoon Dynamics 在[3]中发现，在采用predeccessor-following的控制策略，即每辆车只知道前方车辆的运动参数的情况下，越接近编队尾部的车辆的运动扰动就会越大。因此，编队内的车辆除了需要知道前方车辆的运动参数以外，还需要了解编队Leader的状态l，即predeccessor-leader策略[4]，方能维持一个比较稳定的车间距。Leader的状态可以通过VANET通信来获取。这一思路延续下来的产物是CACC[5]。 Architecture 这里介绍的是[2]中提出的架构。 基于platoon-based VCPS的角度，我们可以将问题拆解成下面两个过程： networking/communication process; the platoon mobility process. 这里要讨论的架构的主要作用，就是描述这两个过程的运作，及两者的相互作用。这里提到的相互作用可以通过下面两个例子来说明： 考虑碰撞预警应用，其中每辆车周期性的发送自己的运动信息，提醒周围的车辆避免碰撞。当编队规模小，编队间距大的时候，通信过程中的冲突和碰撞少，因此延时和丢包率性能好。反之，如果编队规模大，编队间距小，则通信情况会恶化。 考虑CACC系统，CACC依赖VANET来交换周围车辆的运动信息。这里CACC可以建模成网络控制的控制系统。当丢包率提升时，控制系统的可靠性也会下降[6]。 Architecture for platoon-based VCPSs Mobility Specification 自由车辆 我们考虑双向一车道的场景，即不存在超车的场景。编队系统由自由随机运动的交通流(Individual Random Trafic Flow)构建而来。为了建模这个自由随机运动的场景，我们选择Time Headway这个统计量来作为描述车流分布的基础统计量。 Time Headway定义为同向行驶的两辆相邻的车通过同一个观察点的时间差。一般认为Time Headway是独立同分布的随机变量。对于Time Headway的研究非常早了，也有非常多的模型可以使用。其中比较经典的是指数分布模型，正则分布模型，Gama分布，Log-normal分布。[7]中提出，在车流量大约在700到1700 (vph)之间时，Log-normal模型的比较适用。并且，在NGSIM Trajectory Data数据集中，Time Headway也是服从Log-normal分布的。因此在这里我们采用Log-normal分布来描述Time Headway: \[\begin{equation} f\left(t_{h} ; \mu, \sigma, \tau\right)=\frac{1}{\sqrt{2 \pi} \sigma\left(t_{h}-\tau\right)} \exp \left(-\frac{\left(\log \left(t_{h}-\tau\right)-\mu\right)^{2}}{2 \sigma^{2}}\right), \quad t_{h}&gt;\tau \end{equation}\] 其中，\(t_h\)是Time Headway，\(\tau\)为Time Headway的最小值，\(\mu\)为规模参数(Scale Parameter)，\(\sigma\)为形状参数(Shape Parameter)。根据这个分布可以得到均值和方差： \[\begin{equation} \mu\left(T_{h}\right)=\tau+e^{\mu+\frac{1}{2} \sigma^{2}} \end{equation}\] \[\begin{equation} \sigma^{2}\left(T_{h}\right)=e^{2 \mu+\sigma^{2}}\left(e^{\sigma^{2}}-1\right) \end{equation}\] 在交通流的稳定状态下，假设车辆速度大致相等且为常数\(V_{stb}\)，那么可以得到Distance Headway: \[\begin{equation} s_{h} \approx v_{s t b} t_{h} \end{equation}\] 显然，\(s_{h}\)也是服从Log-normal分布的。另外，我们假设结成编队以后，在一个编队内部的车辆的速度是相同的，为\(v_{stb}\)。 编队内运动 上面考虑的是自由车辆模型，考虑车辆组合成编队的情况。首先作如下的符号定义： 符号定义 其中： \(P^i\)表示第i个编队 \(C_j^i\)表示在第i个编队中第j辆车。 \(s_j^i\)为编队内的车辆\(C_{j-1}^{i}\)和\(C_{j}^{i}\)的间距 \(S_i\)为编队\(P^{i-1}\)和\(P_i\)之间的距离。 为了简便，在后面的讨论中只涉及单编队时我们隐去\(i\)上标。完整的符号表如下： 变量查询表 编队内部的运动模型最常用的是car-following model，可以有效地描述ACC-equipped编队运动[8]。在这里我们认为除了Leader之外所有的车辆都遵从car-following model。具体的，我们选择Intelligent Driver model(IDM)[9]: \[\begin{equation} \label{5} s_{j}^{*}(t)=s_{0}+v_{j}(t) T_{0}+\frac{v_{j}(t) \Delta v_{j}(t)}{2 \sqrt{a b}} \end{equation}\] \[\begin{equation} \label{6} a_{j}(t)=a\left[1-\left(\frac{v_{j}(t)}{v_{0}}\right)^{4}-\left(\frac{s_{j}^{*}(t)}{s_{j}(t)}\right)^{2}\right] \end{equation}\] 其中\(s^*_j(t)\)为与前车的目标间距。根据\(\eqref{5}\eqref{6}\)，可以推导出稳定状态（即\(a_j(t)\)为0）的车间距: \[\begin{equation} s_{s t b}=\frac{s_{s t b}^{*}}{\sqrt{1-\left(\frac{v_{s t b}}{v_{0}}\right)^{4}}}=\frac{s_{0}+v_{s t b} T_{0}}{\sqrt{1-\left(\frac{v_{s t b}}{v_{0}}\right)^{4}}} \end{equation}\] 对于编队的Leader，我们则假定他们的行驶速度处于稳定状态，即速度为恒定为\(v_{std}\)。 Networking specification 假设所有车辆的通信距离相通，为\(R\)。在网络连通性问题上，只考虑通信距离这一最主要因素。只要辆车间距小于\(R\)，两者之间的通信就被认为是是可靠的。 在[2]中，作者还进一步修改了MAC层的行为： 对于单播包(Unicast)，当发送尝试访问信道时，若信道繁忙，将发送过程推迟一段时间，这段时间由竞争窗口决定（即一轮backoff）。如果没有收到ACK，那么将竞争窗口加倍； 对于广播报，不进行重传，只进行一轮backoff。 网络拓扑方面做出如下假设：编队内的车辆可以直接进行通信，Leader负责管理编队，同时扮演网关的功能（接收前方编队的消息并转发给编队成员）。编队的Leader可能被选为Message Carrier来转发来自对向行驶的车辆信息。编队尾部的车负责和后方的编队通信。 拓扑结构 基于上述拓扑，设定对应的车辆通信行为规则： 编队内：所有消息可以直达 编队间：如果编队之间可以进行通信（即前一个编队的尾部车辆可以和后一个编队的头部车辆通信），那么直接由尾部车辆向后方广播消息即可。如果编队之间不能直接通信，那么尾部车辆会先从对向车道中选择距离后方编队最近的车辆来转发信息。如果这样的转发者也无法直接和目的节点通信，那么他会继续向其前方边度转发消息。直到无法继续转发或者被最终目的节点收到为止。这个过程如下图所示： 编队间信息传递过程示意图 Connectivity Analysis 连通性分析的核心在于得到编队间距离的分布。 编队间距离分布 为了简化分析，假设所有编队的组成都是一样的。即拥有相同的编队大小和IDM参数（此时我们可以再次略去编队上标号）。基于“符号定义”那张图，编队间距可以表示为： \[\begin{equation} S=S_{L}-L \end{equation}\] 进而有如下引理： Lemma1: Assume all platoons are formed uniformly and controlled by IDM, inter-platoon spacing is lognormal distributed in the traffic steady state with all platoon leaders driving at the same velocity \(v_{stb}\). (证明过程略) 基于这个定理即证明过程的推导可以得到下面的关系： \[\begin{equation} f_{S_{L}}(x)=\frac{1}{\sqrt{2 \pi} \sigma_{D}(x-L)} \exp \left(-\frac{\left(\log (x-L)-\mu_{D}\right)^{2}}{2 \sigma_{D}^{2}}\right), \quad x&gt;L \end{equation}\] \[\begin{equation} f_{S}(x)=\frac{1}{\sqrt{2 \pi} \sigma_{D} x} \exp \left(-\frac{\left(\log (x)-\mu_{D}\right)^{2}}{2 \sigma_{D}^{2}}\right), \quad x&gt;0 \end{equation}\] 编队间通信延时 相邻编队的时隙重叠问题 若编队内采用了TDMA的方式进行通信，那么相邻的编队之间的时隙可能发生重叠。在[10]中，作者提出了一种解决这一问题的方法，流程如下： 相邻编队的时隙分配机制设计 在[10]中，作者考虑了编队和自由车辆同时出现的场景，其中编队内发送Beacon时采用TDMA的方式，编队时隙位于CCHI的头部，自由车辆在这一段时间内不允许发送。如果相邻的编队的距离靠的太近（如上图(a)所示)，那么就可能发生时隙碰撞。在这个场景下，如上图(b)中显示，编队A和编队B的时隙分配发生了重叠。重叠时隙内的汽车发送时，会由于CSMA的退避机制导致延时增长以及碰撞。 另一个潜在的问题是隐藏终端问题。即便两辆车彼此之间不会感知到对方，但是在两者通信范围的重叠区域，两者的包会发生冲突，从而无法被重叠区域内的车辆收到。如同上图(c)中的情形，尽管A0和B0两两者互相无法感知对方，如果两者同时发包，中间重叠区域的A1 ~ A4都无法收到。 为了解决这两个问题，作者提出了一种Self-Configuring的时隙分配方式。编队的Leader需要首先确定是否在相邻的编队间出现了时隙重叠，这个确认过程如下：在每个CCHI，编队的Leader会广播一个包含了时隙分配信息的包。如果编队成员正确地收到了此包，那么他们遵循Leader的安排在对应的时隙发包。此时，在正常情况下，Leader应该受到所有成员发送的Beacon。反之，如果Leader在连续若干个CCHI（至少两个）内都发生了Beacon丢包，Leader就会推定这种丢包现象是由于时隙重叠导致的。 在Leader确认发生了时隙重叠以后，Leader会自适应地重新安排TDMA时隙，暂时选择重叠的时隙的下一个时隙。当没有重叠的时隙安排时，Leader会重置到最初的时隙安排。 上一段话中描述的重新安排重叠时隙的方式翻译自原文，不过我觉得这里有点问题： 时隙重叠是对称的，即A编队和B编队的时隙分配发生重叠时，双方的Leader都能检测到冲突，双方同时开始调整，反而使得原来的重叠时隙空出来。 “选择重叠的时隙的下一个时隙”这个做法也含糊。按照情况分析，应该是将时隙序列整体往后移动一个时隙的长度，但是发生重叠的时隙可能不止一个，而且重叠的时隙并不一定连续，那如何处理呢？ 我对这里的这个机制持怀疑态度，作者在文章中也并未从理论和仿真的角度验证这个机制的有效性。出于严谨，读者最好参阅原文中的Section V-C 我们还需要考虑下面的两个问题： 当两个编队A和B同向行驶且距离较近时，前方的编队A保持其时隙结构不变，后面的编队B将其时隙延迟到A的时隙之后（如上图(e))来避免碰撞和隐藏中断问题。这是因为在前车数据的重要性要比后车的重要性高。另一个原因是后方编队的Leader检测时隙重叠的速度更快（例如前方编队的Leader不会受到隐藏终端问题的影响）。 当编队A和B是反向行驶交会时，当两个Leader的间距小于通信距离，Leader发送的包会发生冲突。根据文章中的机制设计，在CCH信道上编队的TDMA时隙结束后的CSMA通信过程中，Leader还有一个机会发送Beacon包。此时，哪方先收到了对方的Beacon，哪方延后其时隙安排。 用混合协议解决编队间通信 这里的混合协议是指TDMA和CSMA的混合协议。 Reference [1] S. Yousefi, E. Altman, R. El-Azouzi, and M. Fathy, “Analytical model for connectivity in vehicular ad hoc networks,” IEEE Transactions on Vehicular Technology, vol. 57, no. 6, pp. 3341–3356, 2008. [2] D. Jia, K. Lu, and J. Wang, “On the network connectivity of platoon-based vehicular cyber-physical systems,” Transportation Research Part C: Emerging Technologies, vol. 40, pp. 215–230, 2014. [3] P. Seiler, A. Pant, and K. Hedrick, “Disturbance propagation in vehicle strings,” IEEE Transactions on automatic control, vol. 49, no. 10, pp. 1835–1842, 2004. [4] R. Rajamani, S. Choi, J. K. Hedrick, and B. Law, “Design and experimental implementation of control for a platoon of automated vehicles,” in Proceedings of the asme dynamic systems and control division (1998), 1998. [5] P. Fernandes and U. Nunes, “Platooning with ivc-enabled autonomous vehicles: Strategies to mitigate communication delays, improve safety and traffic flow,” IEEE Transactions on Intelligent Transportation Systems, vol. 13, no. 1, pp. 91–106, 2012. [6] C. Lei, Van EenennaamE., W. K. Wolterink, G. Karagiannis, G. Heijenk, and J. Ploeg, “Impact of packet loss on cacc string stability performance,” in 2011 11th international conference on its telecommunications, 2011, pp. 381–386. [7] D.-H. Ha, M. Aron, and S. Cohen, “Time headway variable and probabilistic modeling,” Transportation Research Part C: Emerging Technologies, vol. 25, pp. 181–201, 2012. [8] A. Kesting, M. Treiber, and D. Helbing, “Enhanced intelligent driver model to access the impact of driving strategies on traffic capacity,” Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences, vol. 368, no. 1928, pp. 4585–4605, 2010. [9] M. Treiber, A. Hennecke, and D. Helbing, “Congested traffic states in empirical observations and microscopic simulations,” Physical review E, vol. 62, no. 2, p. 1805, 2000. [10] B. Liu, D. Jia, K. Lu, D. Ngoduy, J. Wang, and L. Wu, “A joint control–communication design for reliable vehicle platooning in hybrid traffic,” IEEE Transactions on Vehicular Technology, vol. 66, no. 10, pp. 9394–9409, 2017.]]></content>
  </entry>
  <entry>
    <title><![CDATA[Wireless Access in Vehicular Environments (WAVE)]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fwave.html</url>
    <content type="text"><![CDATA[WAVE的全称是Wireless Access in Vehicular Environment，是目前车联网通信的标准。 WAVE与其他车联网通信中的技术/标准之间关联 在车联网研究中常见的其他技术关键词还包括: DSRC IEEE802.11p IEEE1609.x 物理层特点 WAVE在物理层使用IEEE802.11p的标准。其物理层的一些关键信息如下。 信道划分 Slot Allocation WAVE使用的频段为5.85GHz至5.925GHz。这一频段被进一步划分为7个信道，包括1个控制信道CCH (Control CHannel), 和6个服务信道SCH(Service CHannel)，具体的信道划分如下所示: FCC规定的WAVE信道划分 5.850GHz - 5.855GHz 部分为保留部分(reserved) 信道178为CCH控制信道，带宽为10MHz 信道172, 174, 176, 180, 182, 184为SCH服务信道，带宽都为10MHz 信道174和176，信道180和182可以合并为20MHz带宽的信道 信道172和184，即最外侧的两个信道用于传输与生命财产关联的安全信息。特别的，根据FCC 06-110，信道172用于V2V的安全信息传输，信道184则是高发射功率，长距离通信，用于公共安全信息的传输，例如避免路口碰撞事故。 WAVE协议规定了SCH和CCH的划分，但是对于在不同SCH的不同业务规则的要求不是强制的。 信道类型 CCH-控制信道 CCH信道只有一个，位于整个WAVE频谱的居中位置，带宽为10MHz。 CCH信道上禁止发送IP消息，主要用来发送一些至关重要要的信息（常常是安全相关的），以及服务广告(Service advertising)消息WSA(WAVE Service Advertisement). SCH-服务信道 SCH信道共六个，主要用来发送与基于IPv6(或者WSMP)的非安全信息。SCH信道调度使用机制的研究参见WAVE中的SCH调度机制研究状况 关于信道的业务类型 WAVE协议并未对于各个信道上运行的业务的具体类型做出具体的强制要求。目前来看除了禁止在CCH上发送IP协议包以外，并未有其他更多的强制要求。例如，WAVE标准并未划分专门的安全信道。前文提到CCH上会发送安全相关的信息，SCH主要用来发送非安全信息，但是在实际使用中SCH上仍然可以用啦发送安全信息。在美国172信道甚至被视为安全信息的专用通道。管理信息同样也可以在SCH上传输。 信道协调(Channel coordination)与时间同步(Time Synchronization) WAVE中的多信道访问以IEEE1609.4为标准。 信道协调 在使用WAVE进行通信时，时域和频域资源都进行了划分。WAVE设备可以在不同的信道上切换(Alternative radio channel access)。这使得单设备节点可以在SCH信道上交换信息的同时，可以监听CCH信道。 多信道访问通过共同点时间基准来进行协调。具体而言，WAVE规定由一个CCH间隔(CCHI)，跟着一个SCH间隔(SCHI)组成一个同步间隔SI。在CCHI，所有节点在CCH上通信；在SCHI，节点在指定的SCH上进行通信。在CCHI和SCHI开头设置了一段保护间隔(GI)。在保护间隔内，设备在进行信道切换，被认为无法接收数据包。 根据IEEE 1609.4-2010标准，CCHI和SCHI的长度均为50ms，保护间隔为4ms，如下图所示 Channel Interval Structure 标准允许将信道间隔（CI）设置为可变的长度，但是并没有给出对应的实现机制。 上述的接入方式被称为Alternating channel access，除此之外，还包含了continuous channel access, immediate access, extended access。其中，immediate access允许设备在WSA消息中识别出一个应用请求时，立刻切换到SCH信道。extended access则允许设备延长访问SCH的时间。 More Channel Accessing Schemes 装备有多个通信设备的节点可以并行地访问CCH和SCH 时钟同步 各个节点的时钟同步到UTC时间的标准秒（这点在上图得到了反映）。UTC时间可以由GPS给出。 IEEE802.11-2012标准中的Timing Advertisement frame可以用于节点间的时钟同步。 注意，严格的时钟同步对于通信来说并非是必须的。信道协调只需要精确到1s的边界就可以了。不过严格的时钟同步可能对于安全目的来说是必须的。 MAC层特点 WAVE的MAC层的核心DCF(Distributed Coordination Function)技术，DCF是基于指数退避算法的CSMA/CA机制，这一机制的内容可以从以下几方面来讨论: 指数退避机制 需要发送包的节点监听信息，如果信道空闲的时间超过了DIFS (Distributed Interframe Space)，那么节点开始发送，否则如果信道繁忙，则继续保持监听信道。 当节点得以占用信道准备发送时，节点会在发送前进行一个随机的退避（Collision Avoidance），来减少和其他节点冲突的概率。另一方面，为了避免信道长时间被特定的节点占用（信道被长时间占用的现象被称为Channel Capture），一个节点在两次发包之间也要有一个随机的退避。 出于性能原因，CSMA采用了离散的退避时间。紧跟在DIFS之后的时间被划分为多个时隙，每个节点只能在每个时隙的开始的阶段发送数据包。时隙的大小\(\sigma\)，等于每个节点探测到另一个节点发送的包需要的延时。这一参数取决于物理层，包含传输延时，TX/RX切换时间，以及通知MAC层信道状态需要的时间。 在每个包传输时，退避时间在\((0, \omega-1)\)中随机选出，其中\(\omega\)被称为竞争窗口(Contetion Window)。竞争窗口的大小与传输失败的次数有关。初始时\(\omega=CW_{min}\)。每经过一次传输失败，竞争窗口的大小加倍，直到达到最大值\(CW_{max}\)。 退避的状态由一个退避计数器(backoff counter)来控制。在开始退避时，为退避计数器随机分配一个退避窗口范围内的整型值。之后每一个时隙，如果信道空闲退避计数器就递减。当检测到信道繁忙时，退避计数器的递减过程会停止。当信道再次变得空闲时，退避计数器需要检测信道空闲超过DIFS之后才会再次开始递减。当计数器递减至0时，节点会尝试发送。如果失败，竞争窗口会加倍。并重复前述过程。 ACK CSMA中并不依赖对于自己的传输的监听来检测碰撞。因此引入了ACK机制来通知包发送成功（显然只有D2D方式的通信才会有ACK，在广播包不会产生ACK）。这种机制被称为是Basic Access。接收端在收到包之后经过一段SIFS（Short Inter-Frame Space）立即发送ACK。SIFS比DIFS要短，因此在ACK发送前不会有节点能够占用信道。如果在一定事件后发送节点仍然没有收到ACK，则判断此包丢失。 RTS/CTS RTS/CTS的全称是Request To Send / Clear To Send。这套机制的作用是两方面的： 减少在传输较大体积的包过程中的冲突 解决隐藏终端问题 RTS/CTS的工作过程如下。节点在发送数据包之前，先向目标节点发送一个RTS请求，目标街点收到RTS之后判断当前是否能够进行RTS中请求的包传输，如果可以，目标节点会响应一个CTS。发送者在收到CTS之后才获准发送数据包。RTS和CTS中包含了待传输的包的长度信息，这些信息可以被周围的节点截图，从而更新其Network Allocation Vector (NAV)。 MAC层性能的理论推导 针对MAC的层的性能推导，基本源自于下面Performance analysis of the IEEE 802.11 distributed coordination function[1]. 这篇文章给出了在一定的驾驶条件下DCF机制的饱和吞吐率 饱和吞吐率 一般而言，随机接入协议的一个共同问题是，随着业务量的上升，系统的整体throughput会逐渐上升至maximum throughput，之后继续提高业务量，系统整体的吞吐率并不会继续上升，反而会下降。因此，在实际场景中，系统不可能长时间的保持在最大吞吐率的水平。最大吞吐率也不太适合用作评估接入机制性能的指标。 随着业务量的进一步上升，吞吐率会进入一个比较稳定的水平。这个水平被称为饱和吞吐率（Saturation Throughput） 饱和吞吐率 假设条件 完美的信道条件 不考虑隐藏终端问题 不考虑Channel capture 节点数量固定，且达到满载，即，在一个包发出去之后，总有另一个包等待发送 包传输概率 节点数量为\(n\)，在饱和的情况下，每个节点在每次传输成功以后都可以立即生成一个数据包以供发送。每个包在开始发送前都需要经历一个随机的退避。我们定义\(b(t)\)为节点的退避计数器状态，\(t\)和\(t+1\)表示连续的两个时隙的起始。这里的“时隙”与前面的定义不同，在前文中我们提到过，在信道状态为busy时，退避计数器的递减过程是停止的。我们在这里不将这些部分的时间纳入时隙中，时隙被定为退避计数器相邻两次递减的时间差，这意味着，slot times和系统的时钟是不同步。两个连续的时隙的起始时刻相差，并不总是​\(​\sigma\)，而且可能包含一个完整的发送过程。 由于退避计数器与传输历史有关，那么随机过程\(b(t)\)显然是非马尔科夫的。记 \[ W=CW_{min} \\ CW_{max} = 2^mW \] 然后记： \[ W_i=2^iW \] \(i\in(0,m)\)被称为退避阶段(backoff stage)。我们记\(b(t)\)为表述退避阶段在\(t\)时刻取值的随机变量。我们的一个核心的近似是一个核心的近似是，假设在对于每一次传输尝试，无论重传次数如何，每个包的碰撞概率都是 constant and independent 的，此概率值为​\(p\)​。直观的来看，这个假设在​\(W\)和\(n\)增加时会更加精确。这一概率值又可以被称为条件碰撞概率（conditional collision probability），即此概率为待发送包观察到的碰撞概率。 一旦独立性得到满足，且​\(p\)​是一个常数值，我们可以把一个二元随机过程​\(\{s(t),b(t)\}\)建模成离散时间的马尔科夫链。其状态转移图为 马尔科夫链状态转移图 概率转移矩阵中的非零元素为： \[ \left\{ \begin{array}{ll} P\{i, k | i, k + 1\} = 1 &amp; k\in(0, W_i - 2), i\in(0, m) \\ P\{0, k | i, 0\} = (1 - p) / W_0 &amp; k\in(0, W_0 - 1), i\in(0, m) \\ P\{i, k|i-1, 0\} = p / W_i &amp; k\in(0, W_i - 1), i\in(1, m) \\ P\{m, k | m, 0| = p/W_m &amp; k\in(0,W_m -1) \end{array} \right. \] 第一个等式代表在每个slot time的开头要递减backoff counter. 第二个等式代表在一次成功的传输以后，紧随一个新的packet 第三个等式代表退避完成之后信道仍然无法占用增加backoff stage。 第四个等式也是代表退避完成之后信道仍然无法占用，不过backoff stage已经最大 记\(b_{i,k}=\lim_{t\to\infty}P\{s(t)=i, b(t)=k\}, i\in(0, m), k\in(0, W_i-1)\)代表了马尔科夫链的稳态分布，下面给出该马尔科夫链的闭式解： 首先: \[ b_{i-1}\cdot p=b_{i,0} \to b_{i_0}=p^ib_{0,0},\ \ 0&lt;i&lt;m \\ b_{m-1,0}=（1-p)b_{m,0}\to b_{m,0}=\frac{p^m}{1-p}b_{0,0} \] 马尔科夫链的规律，对于每个\(k\in(1,W_i-1)\) \[ b_{i,k}=\frac{W_i-k}{W_i}\cdot \left\{ \begin{array}{ll} (1-p)\sum_{j=0}^{m}b_{j,0} &amp; i=0 \\ p \cdot b_{i-1,0} &amp; 0 &lt; i &lt; m \\ p \cdot (b_{m-1, 0} + b_{m,0}) &amp; i=m \end{array} \right. \] 在平稳情况下，考虑\(\sum_{i=0}^{m}b_{i,0}=b_{0,0}/(1-p)\)，则有 \[ b_{i,k}=\frac{W_i-k}{W_i}b_{i,0},i\in(0,m),k\in(0,W_i-1) \] 经过上面的推导，我们可以把\(b_{i,k}\)表达为\(b_{0,0}\)的函数，同时通过概率的正则化条件可以求解\(b_{0,0}\)： \[ 1=\sum_{i=0}^{m}\sum_{k=0}^{W_i-1}b_{i,k}=\sum_{i=0}^{m}b_{i,0}\sum_{k=0}^{W_i-1}\frac{W_i-k}{W_i}=\sum_{i=0}^{m}b_{i,0}\frac{W_i+1}{2}\\ =\frac{b_{0,0}}{2}\left[W\left(\sum_{i=0}^{m-1}(2p)^i+\frac{(2p)^m}{1-p}\right) + \frac{1}{1-p}\right] \] 故 \[ b_{0,0}=\frac{2(1-2p)(1-p)}{(1-2p)(W+1)+pW(1-(2p)^m)} \] 然后我们可以得到一个节点在任意时刻尝试发送的概率 \[ \tau=\sum_{i=0}^{m}b_{i,0}=\frac{b_{0,0}}{1-p}=\frac{2(1-2p)}{(1-2p)(W+1)+pW(1-(2p)^m)} \] 注意\(m=0\)是0时，即即退避的窗口是固定的时候， \[\tau=\frac{2}{W-1}\] 注意到\(p\)的含义其实是，在一个时隙中一个节点正在发送时，剩下的\(n-1\)个节点至少有一个在发送，则 \[ p=1-(1-\tau)^{n-1} \] 这里的\(\tau\)和\(p\)构成了一种非线性方程组，可以用数值方法求解。 吞吐率计算 记\(S\)为归一化的系统吞吐率，定义为信道中用于传输数据的时间的比例。在一个随机选取的时隙上，记\(P_{tr}\)为至少有一个节点尝试发送的概率，则 \[ P_{tr}=1-(1-\tau)^n \] \(P_s\)表示传输成功的概率，则 \[ P_s=\frac{n\tau(1-\tau)^{n-1}}{P_{tr}}=\frac{n\tau(1-\tau)^{n-1}}{1-(1-\tau)^n} \] 我们可以把\(S\)表示成 \[ S=\frac{E[\text{payload information transmitted in a slot time}]}{E[\text{length of a slot time}]} \] 记包的平均传输时间是\(E[P]\)，俺么在一个slot time里面用于传输的平均时间长度是\(P_{tr}P_{s}E[P]\)。slot time的平均大小是 \[ (1-P_{tr})\sigma+P_{tr}P_sT_s+P_{tr}(1-P_s)T_c \] 其中，\(T_s\)是信道检测为繁忙后的平均slot time长度（其内部包含了一整个包传输的时间），\(T_c\)为信道发生碰撞以后被识别为繁忙的时间。那么 \[ S=\frac{P_sP_{tr}E[P]}{(1-P_{tr})\sigma+P_{tr}P_sT_s+P_{tr}(1-P_s)T_c} \] 注意上面的推导过程中我们其实并未指定特定的接入机制。对于特定的接入机制，我们只需要确定与之相关的\(T_s\)和\(T_c\)。 \(T_s\)和\(T_c\)的确定 只考虑存在ACK机制下， \[ \left\{\begin{array}{l} T_{s}^{bas}=H+E[P]+SIFS+\delta+ACK+DIFS+\delta\\ T_c^{bas}=H+E[P^*] + DIFS +\delta \end{array}\right. \] 其中\(H=PHY_{hdr}+MAC_{hdr}\)为物理层和MAC层的帧头传输时间。\(\delta\)是传输延时，\(E[P^*]\)是the average length of the longest packet payload involved in a collision. 如果所有的包的大小都是一样的，那么\(E[P^*]=P\)。在更一般的情况下所有包的大小可以被认为是独立同分布的。记这个分布为\(F(\cdot)\)，则 \[ \begin{aligned} E[P^*] &amp;=E[E[\max(P_1,\dots,P_k|k]]\\ &amp;=\frac{\sum_{k=2}^{n}\left(\begin{array}{c}n\\k\end{array}\right)\tau^{k}(1-\tau)^{n-k}\int_{0}^{P_{max}}(1-F(x))^kdx}{1-(1-\tau)^n-n\tau(1-\tau)^{n-1}} \end{aligned} \] 如果忽略三个或者更多包碰撞的情况，那么上面的式子可以简化为： \[ E[P^*]=\int_0^{P_{max}}(1-F(x)^2)dx. \] \(T_c\)是由未参与到碰撞中的节点感知到的信道繁忙时间，我们忽略了两个或者更多个的碰撞节点在感知信道前需要等待ACK超时这个因素，所以实际中的\(T_c\)要不这里给出的计算结果要大。 再考虑在RTS/CTS机制下： \[ \left\{ \begin{array}{l} T_s^{rts}=RTS+SIFS+\delta+CTS + SIFS + \delta + H + E[P] + SIFS + \delta+ACK+ DIFS + \delta \\ T_c^{rts} = RTS + DIFS + \delta \end{array} \right. \] 对于Beacon包的特殊分析 很多文献中对于Beacon包的发送过程做了简化，即发送过程中只进行一轮退避，没有退避窗口的指数增长过程。此时Beacon包的发送状态成为一维马尔科夫过程。这部分问题参见：WAVE标准中的Beacon性能简化分析 结果分析 饱和吞吐率与节点数量的关系 从上图中我们可以发现，对于Basic Access方式，饱和吞吐率和节点数量呈负相关，也即和节点密度呈负相关。这意味着节点数量越少，饱和吞吐率越高。相反，对于RTS/CTS机制而言，在节点密度达到一定的程度以后，饱和吞吐率就和节点数量无关了。 这个性能差异我们在IEEE802.11 DCF中Basic Access和RTS/CTS机制的理论饱和吞吐率性能差异分析这篇文章中进行了详细的分析。 Reference [1] G. Bianchi, “Performance analysis of the ieee 802.11 distributed coordination function,” IEEE Journal on Selected Areas in Communications, vol. 18, no. 3, pp. 535–547, 2000.]]></content>
  </entry>
  <entry>
    <title><![CDATA[一维马尔科夫过程的使用]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fmarkov%2F1D-markov.html</url>
    <content type="text"><![CDATA[前言 一维马尔科夫链主要应用于广播消息的性能分析。在广播通信中，不存在ACK机制，因此发送者无法判断发送是否，因此也就无法增加退避窗口并且发起重传，传统的二维马尔科夫链中的二元状态变量中的backoff stage失去意义，因此只需要用backoff counter这一个变量即可表征广播接入信道的过程。 这里整理的一维马尔科夫过程的研究主要来自于[1]，同时包含饱和以及不饱和场景的性能分析。 一维马尔科夫链 网络结构为的单跳Adhoc网络，节点总数为\(n\)。传输环境为：a two-ray propagation model with no hidden terminal or capture effects，即所有的包丢失都是由于碰撞(Collision)导致的。假设每个节点每次只能缓存一个数据包，且包的到达过程为到达率为\(\lambda\)的Poisson过程， 非饱和状态下的一维马尔科夫链状态转移图 如上图所示，退避窗口为\(W\)，意味着退避状态一共有\(W\)个，以及一个额外的Idle状态（记为\(I\)）。同时记包的到达概率为\(q\)，信道繁忙的概率为\(q_b\)，则有下面的概率转移矩阵： \[\begin{equation} \left\{\begin{array}{l}{P\{I | I\}=1-q} \\ {P\{k | I\}=q / W} \\ {P\{k | I+1\}=1-p_{b}} \\ {P\{k | k\}=p_{b}} \\ {P\{I | 0\}=1}\end{array}\right. \end{equation}\] 下面求解稳态分布\(b_k (k \in [0, W - 1])\)（Idle状态的稳态概率为\(b_I\)），我们通过转移概率可以得到如下的方程： \[\begin{equation} b_I = \frac{1}{q}b_0 \end{equation}\] \[\begin{equation} b_{k}=\frac{(W-k) q}{W\left(1-P_{b}\right)} b_{I}=\frac{(W-k)}{W\left(1-P_{b}\right)} b_{0} \quad k \in[1, W-1] \end{equation}\] \[\begin{equation} b_{I}+b_{0}+\sum_{k=1}^{W-1} b_{k}=1 \end{equation}\] 当backoff counter为0时节点开发发送，则\(b_0\)为传输概率(transmission probability) \(\tau\)。通过上面的三个公式组成的方程，我们可以得到： \[\begin{equation} \label{tau} \tau=b_{0}=\left(\frac{1}{q}+1+\frac{(W-1)}{2\left(1-P_{b}\right)}\right)^{-1} \end{equation}\] 在得到传输概率以后，通过经典文章[2]我们可以计算吞吐率性能。不过我们在这里的模型中增加了Idle状态，因此分析会有一点不同。 记\(P_b\)为信道繁忙的概率，\(P_s\)为传输成功的概率，则： \[\begin{equation} \label{Pb} \begin{aligned} P_{b} &amp;=1-(1-\tau)^{n-1} \\ P_{s} &amp;=n \tau(1-\tau)^{n-1} \end{aligned} \end{equation}\] 按照[2]的方法，将两次backoff状态之间的间隔定义为一个slot（virtual slot），则virtual slot可能包含一个空的slot，一次冲突，或者一次成功的发送。那么有： \[\begin{equation} \text {SlotTime}=(1-\tau)^{n} \sigma+\left(1-(1-\tau)^{n}\right) T \end{equation}\] 由于在广播中，没有RTS/CTS，也没有ACK，那么一次冲突和一次成功发送占用信道的时间是一样的： \[\begin{equation} T=\frac{H+E[P]}{R}+D I F S+\delta \end{equation}\] 这里\(H\)为物理层帧头和MAC层帧头的大小，\(R\)为发送速率。由于我们假定包的生成过程是Poisson过程，则 \[\begin{equation} \label{q} q=1-e^{-\lambda S l o t T i m e} \end{equation}\] 通过联立求解\(\eqref{tau}, \eqref{Pb}, \eqref{q}\)非线性方程组，我们可以得到归一化吞吐率性能 \[\begin{equation} S=\frac{P_{s} E[P]}{S l o t T i m e} \end{equation}\] 上面描述的是非饱和状态下的性能计算过程，但是当\(\lambda\)趋近于无穷大，即\(q\)趋向于1时，即可以得到饱和场景下的通信性能。 Reference [1] J.-P. Wang, M. Abolhasan, D. R. Franklin, and F. Safaei, “Characterising the behaviour of ieee 802.11 broadcast transmissions in ad hoc wireless lans,” in 2009 ieee international conference on communications, 2009, pp. 1–5. [2] G. Bianchi, “Performance analysis of the ieee 802.11 distributed coordination function,” IEEE Journal on Selected Areas in Communications, vol. 18, no. 3, pp. 535–547, 2000.]]></content>
  </entry>
  <entry>
    <title><![CDATA[ns3中的Attribute系统的使用]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fns3%E4%B8%AD%E7%9A%84wave%E6%A8%A1%E5%9D%97%2Fns3%E4%B8%AD%E7%9A%84Attribute%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8.html</url>
    <content type="text"><![CDATA[ns3中的Attribute及相关系统的设计非常有意思，其意义在于为仿真中的极其复杂的模块架构中，提供了一种非常方便的解耦的属性访问（读写）方法。例如，在一个复杂的设计WAVE的性能仿真中，若要修改某个节点的CSMA竞争窗口大小。没有Attriubute系统的情况下，想要通过层层指针获取底层对象再进行修改，会对代码的模块化设计和代码的复杂度带来灾难性的硬性。相反，在Attribute系统下，我们只需要提供CSMA竞争窗口的路径(path)就可以直接修改对应的属性。 1Config::Set ("/NodeList/0/$ns3::Node/DeviceList/0/$ns3::WaveNetDevice/MacEntities/172/$ns3::OcbWifiMac/BE_Txop/$ns3::QosTxop/MinCw", UintegerValue (15)); 下面我们来梳理一下Attribute使用中的一些要点。 Attribute的创建 Attribute的创建是在TypeId中进行的。Attribute系统的实现有赖于Object系统，这意味着你如果要在你的类中自定义Attribute，需要让你的类继承自Object基类。我们通过TypeId::AddAttribte这个函数来定义属性。例如上面提到的MinCW，其创建过程如下： 1234567891011static TypeId tid = TypeId ("ns3::Txop") .SetParent&lt;ns3::Object&gt; () .SetGroupName ("Wifi") .AddConstructor&lt;Txop&gt; () .AddAttribute ("MinCw", "The minimum value of the contention window.", UintegerValue (15), MakeUintegerAccessor (&amp;Txop::SetMinCw, &amp;Txop::GetMinCw), MakeUintegerChecker&lt;uint32_t&gt; ()) // ... ; 这个函数有五个参数，分别是： 属性的名称，这个名称是我们后续构建Attribute Path时使用的名称； 属性的描述； 属性的默认值。注意这里不能传入Primitive Value，而是需要使用特定的类进行打包。如uint_t需要通过UintegerValue类来打包； 属性的访问器，这里决定了的具体的属性值如何存储和访问。可以使用Getter，Setter函数范式，也可以直接使用类的成员变量。 属性的格式检查器，我们可以通过这个类来规定属性的格式 Attribute的结构（路径组成） Attribte使用中最大的一个困难在于，我们如何确定Attribute的路径呢？ Attribute的路径，是各个模块内部的层级关系（hierarchy）的反映。我们以开头的例子中使用的路径为例： 1/NodeList/0/$ns3::Node/DeviceList/0/$ns3::WaveNetDevice/MacEntities/172/$ns3::OcbWifiMac/BE_Txop/$ns3::QosTxop/MinCw 每一个斜杠/代表了一个层级，或者是一个操作。这里，一个层级，对应的是对象与对象成员的关系。例如这里面的DeviceList，是Node的成员变量。 123456789101112131415TypeIdNode::GetTypeId (void)&#123; static TypeId tid = TypeId ("ns3::Node") .SetParent&lt;Object&gt; () .SetGroupName("Network") .AddConstructor&lt;Node&gt; () .AddAttribute ("DeviceList", "The list of devices associated to this Node.", ObjectVectorValue (), MakeObjectVectorAccessor (&amp;Node::m_devices), MakeObjectVectorChecker&lt;NetDevice&gt; ()) // ... ; // ...&#125; 这个很好理解。操作一般就要复杂一些。这里的操作可以大致分为两类： 索引(indexing/mapping) 类型转换(casting) indexing/mapping 在定义Attribute时，可以将Attribute定义为Vector或者Map类型。例如Node的DeviceList这个Attribute就是一个Vector。在构建Attribute Path时，紧跟在Node后面我们需要添加一个索引项来表明我们要访问的具体是哪个成员。利用通配符*指定选中所有的成员。这里的例子包括上面路径的/NodeList/0还有DeviceList/0等等部分。 casting 一般来说，定义Attribute时，我们指定的类型可能是特定的基类，例如上面Node的Attribute定义中，其DeviceList中的成员就是NetDevice这个基类。再具体的子类中，其Attribute定义可能各不相通。为了访问特定的子类的Attribute，我们要将其转化成对应的子类。以开头的例子为例，casting操作的标识是$。DeviceList/0/$ns3::WaveNetDevice/MacEntities中，我们取出每个Node的第0个Device，并将其转化成ns3::WaveNetDevice类型，然后访问MacEntities这个Attribute。 查询方法 尽管知道了Attribute Path的构建方法，但是实际书写起来还是非常复杂，我们可以用一个简单的工具ConfigStore来查询仿真中具体有哪些Attribute。 参考下面的样例修改你的代码： 1234567891011121314int main (...)&#123; CommandLine cmd; cmd.Parse (...); ConfigStore config; config.ConfigureDefaults (); ... topology creation config.ConfigureAttributes (); Simulator::Run ();&#125; 然后按照下面的样子运行你的仿真 1./waf --run "scratch/myprogram --ns3::ConfigStore::Mode=Save --ns3::ConfigStore::Filename=config.txt" 然后在config.txt文件中我们可以查看仿真中所有涉及的Attribute的路径及具体取值。 注意只有在程序中使用过（读/写）才会在此处输出。 Further Reading HOWTO determine the path of an attribute or trace source HOWTO use the ConfigStore Configuration and Attributes]]></content>
  </entry>
  <entry>
    <title><![CDATA[三维马尔科夫链的详细调研]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fmarkov%2F3D-markov.html</url>
    <content type="text"><![CDATA[参考文章及其系统模型 在马尔科夫链在WAVE链路层网络性能分析中的应用中我们提到了三维马尔科夫链的使用。相比于经典的[1]中提出的二维马尔科夫链，三维马尔科夫链新增的一维主要是为了解决EDCA机制下不同优先级的队列并存的问题。 Contribution 下面的内容以[2]为基干进行讨论。这篇文章的主要贡献是讨论网络连通性与饱和吞吐率性能之间的关系。具体贡献是如下三个方面： 作者提出了一种Connectivity-aware MAC protocol，支持多信道标准（1609.4），为编队场景设计； 使用了多优先级的马尔科夫模型来研究网络连通概率与饱和吞吐率之间的关系； 提出一种多信道的资源调度策略，可以动态的调整CCHI和SCHI的长度来改善系统吞吐性能。 System Model 文章使用的System Model是比较简单和经典的场景：无干扰情况下的单向高速公路交通流，单车道，从而避免超车这种复杂行为。 System Model 道路上车辆总数为\(N\)，在高速公路上随机分布。道路总长为2000m。假设存在\(K\)辆普通车辆，\(M\)个编队。每个编队被视为一个单独的车辆。在编队内部，编队成员直接连接，所有的成员可以直接同编队的Leader通信。编队成员将自己的安全和非安全消息发送给编队Leader，然后Leader代表整个编队去竞争CCH的使用。记\(p\)为网络中编队的比例，即任何一个通信单位是一个编队的概率为： \[\begin{equation} p=M / N=M /(K+M) \label{1} \end{equation}\] 即\(R_1\)和\(R_2\)分别为普通车辆与编队Leader的通信范围，且\(R_1 &lt; R_2\)。假设\(R_2\)足够大到可以覆盖整个编队，且编队的长度小于\(R_2 - R_1\)。这一假设其实就是阻止了编队内部成员和外部普通车辆的直接通信。 车辆在高速公路上的分布服从泊松分布，所有车辆都在RSU的通信范围内。记\(\rho\)为交通密度，那么在\(x\)米长度的道路上出现的车辆的数目为\(k\)的概率为： \[\begin{equation} f(k, x)=\frac{(\rho x)^{k} e^{-\rho x}}{k !}, k \geq 0 \end{equation}\] 令\(X\)为表示车间距的随机变量。则其分布可以表示成： \[\begin{equation} \operatorname{Pr}\{X \leq x\}=h(x)=1-e^{-\rho x} \end{equation}\] 连通概率分析 记\(X_{i} \quad(i=1,2, \ldots, N-1)\)代表相邻两辆车的车间距分布。当车间距不超过通信范围时，即\(X_i \le R\)时，认为两辆车连通。记\(P_c\)为VANET的整体连通概率，即： \[\begin{equation} P_{c}=\operatorname{Pr}\left\{X_{1} \leq R, X_{2} \leq R, \ldots, X_{N-1} \leq R\right\} \end{equation}\] 这里\(X_i\)是独立同分布的。所以 \[\begin{equation} \begin{aligned} P_{c} &amp;=\prod_{i=1}^{N-1} P_{r}\left\{X_{i} \leq R\right\} \\ &amp;=\prod_{i=1}^{N-1}\left[(1-p) * P_{r}\left\{X_{i} \leq R_{1}\right\}+p * P_{r}\left\{X_{i} \leq R_{2}\right\}\right] \end{aligned} \end{equation}\] 代入System Model中的泊松分布模型，有 \[\begin{equation} P_{c}=\left[(1-p)\left(1-e^{-\rho R_{1}}\right)+p\left(1-e^{-\rho R_{2}}\right)\right]^{N-1} \label{6} \end{equation}\] 根据\(\eqref{6}\)， \[\begin{equation} p=\frac{1-e^{-\rho R_{1}}-P_{c}^{\frac{1}{N-1}}}{e^{-\rho R_{2}}-e^{-\rho R_{1}}} \end{equation}\] MAC Protocol 在作者提出的MAC协议中，CCHI被进一步划分成SAFety Interval (SAFI), WSA Interval (WSAI)和ACK Interval (ACKI)。如下图： The framework of the connectivity-aware MAC protocol 首先，在CCHI的开头，所有车辆在SAFI广播优先级最高的安全信息。在WSAI阶段，所有提供服务的车辆竞争式地访问信道以广播WSA包。WSAI被划分为若干时隙，在每个时隙的开头，如果信道是空闲的，则服务提供者尝试发送WSA包。在ACKI阶段，收到了安全消息的车辆，以及对WSA中包含的服务感兴趣的车辆，会发送ACK。为了避免重复发送，当之前已经有节点响应了对特定安全消息或WSA服务的ACK的话，后续的车辆不会再次进行响应。为了维护网络公平性，在每个ACKI内节点发送ACK的顺序会随机分配。 WSA与对应的ACK，构成了一套SCH资源预留机制。在CCHI结束时，已经成功预留了SCH资源的车辆切换到对应的SCH信道，进行无冲突的信息传输。 前面我们提到，对于编队系统，编队的Leader需要代表整个编队进行CCH竞争。因此，考虑到网络公平性，来自编队的WSA消息（WSAP）相比于普通车辆的WSA消息（WSAO）应当拥有更高的优先级。 在上图描绘的MAC协议中，SAFI的长度和ACKI的长度与车辆数量成正比。而WSAI的长度，需要通过对应的多优先级马尔科夫模型来计算。 马尔科夫模型分析 在上一个部分我们提到，处于网络公平性的考虑，来自编队的WSA消息要拥有更高的优先级。这里的优先级控制通过EDCA机制来完成。在EDCA中，不同的优先级体现在不同长度的Aribitration Inter-Frame Space (AIFS)上。这里我们认为WSAP的AIFSN为2, WSAO的AIFSN为3。 此处的马尔科夫链采用了典型的假设： 理想信道条件（no hidden terminal and capture); 节点满载，即任何时候都有包等待发送 包的传输概率和碰撞概率是独立的 状态变量与状态转移 马尔科夫链的状态变量被定为： \(s(i, t)\)：backoff stage \(b(i, t)\): value of backoff timer \(v(i, t)\): active stat of the backoff procedure 这里\(i\)表示包的类别。1表示WSAP，2表示WSAO。令\(L_i\)为类别\(i\)的最大退避阶段，\(W_{i, m}\)为类别\(i\)在第\(m\)个退避阶段的竞争窗口(CW)大小。那么有\(s(i, t) = m, (0 \le m \le L_i), b(i, t) \in (0, W_{i, m})\)。当\(v(i, t) = 0\)时，退避过程被冻结，即\(b(i, t)\)的值保持不变。反之，当\(v(i, t) = -1\)时，退避过程正常进行。在定义了上述状态变量之后\(\{s(i, t), b(i, t), v(i, t)\}\)，我们可以画出状态转移图。 The Markov chain model of the WSAP transmission 上图为WSAP的状态转移图。在这个优先级设置下，在每个时隙退避计数器都会减1，即\(v(i, t) = -1\)。即\(p_1\)为碰撞概率。则转移概率为： \[\begin{equation} \left\{ \begin{array}{ll} \operatorname{Pr}\{(j+1, k,-1) |(j,-1,-1)\}=p_{1} / W_{1, j+1}+1, &amp; 0 \leq j \leq L_{1}-1,0 \leq k \leq W_{1, j+1} \\ \operatorname{Pr}\{(j, k-1,-1) |(j, k,-1)\} =1, &amp; 0 \leq j \leq L_{1}, 0 \leq k \leq W_{1, j} \\ \operatorname{Pr}\{(0, k,-1) |(j,-1,-1)\} =\left(1-p_{1}\right) /\left(W_{1,0}+1\right), &amp; 0 \leq j \leq L_{1}-1,0 \leq k \leq W_{1,0} \\ \operatorname{Pr}\left\{(0, k,-1) |\left(L_{1},-1,-1\right)\right\} =1 /\left(W_{1,0}+1\right), &amp; 0 \leq j \leq L_{1}, 0 \leq k \leq W_{1,0} \end{array} \right. \label{8} \end{equation}\] 从这个状态转移图和转移概率计算来看，这里的退避发送行为和我们在WAVE里面提到的退避过程不太一样。这里在达到最大退避窗口后，会重置退避窗口大小，即为Reset backoff stage The Markov chain model of the WSAO transmission 上图是WSAO的状态转移图。当\(v(i, t) = 0\)时，退避计数器会停止递减。令\(p_2, p_{2, \text{idle}}\)和\(p_{2, 0}\)分别为WSAO传输失败，WSAO发送遇到空闲信道，遇到繁忙信道的概率。转移概率为： \[\begin{equation} \left\{ \begin{array}{ll} \operatorname{Pr}\{(j+1, k, 0) |(j, -1,-1 ) \}=p_{2} /\left(W_{2, j+1}+1\right), &amp; 0 \leq j \leq L_{2}-1,0 \leq k \leq W_{2, j+1} \\ \operatorname{Pr}\{(j, k-1,-1) |(j, k,-1)\} =p_{2, \text {idle}}, &amp; 0 \leq j \leq L_{2}, 0 \leq k \leq W_{2, j-1} \\ \operatorname{Pr}\{(j, k, 0) |(j, k,-1)\} =1-p_{2, \text {idle}}, &amp; 0 \leq j \leq L_{2}, 0 \leq k \leq W_{2, j-1} \\ \operatorname{Pr}\{(j, k, 0) |(j, k, 0)\} =p_{2,0}, &amp; 0 &lt; j \leq L_{2}, 0 \leq k \leq W_{2, j-1} \\ \operatorname{Pr}\{(j, k-1,-1) |(j, k, 0)\} =1-p_{2,0}, &amp; 0 \leq j \leq L_{2}, 0 \leq k \leq W_{2, j-1} \\ \operatorname{Pr}\{(0, k, 0) |(j,-1,-1 ) \}=\left(1-p_{2}\right) /\left(W_{2,0}+1\right), &amp; 0 \leq j \leq L_{2}-1,0 \leq k \leq W_{2,0} \\ \operatorname{Pr}\left\{(0, k,-1) |\left(L_{2},-1,-1\right)\right\} =1 /\left(W_{2,0}+1\right), &amp; 0 \leq j \leq L_{2}, 0 \leq k \leq W_{2,0} \end{array} \right. \label{9} \end{equation}\] 稳态分布 求解\(\eqref{8}\)和\(\eqref{9}\)，可以求得稳态分布。WSAP的传输概率\(p_i\)和WSAO的传输概率\(p_j\)为： \[\begin{equation} \left\{ \begin{array}{l} { p_{i}=\frac{1-p_{1}^{L_{1}+1}}{\sum_{j=0}^{L_{1}} w_{1, j} \ / 2 * p_{1}^{j}\left(1-p_{1}\right)+2\left(1-p_{1}^{L_{1}+1}\right)} } \\ { p_{j}=\frac{1-p_{1}^{L_2+1}}{\sum_{j=0}^{L_{2}} w_{2, j} \ / 2 * p_{2}^{j}\left(1-p_{2}\right)+1-p_{2}^{L_{2}+1}} } \end{array} \right. \label{10} \end{equation}\] 根据[3]的结论，最大吞吐率可以在信道的空闲状态的平均持续时间和繁忙状态的平均持续时间相等时达到，即 \[\begin{equation} \label{11} E[i d l e]=E[c o l l] \Rightarrow p_{i d l e} * T_{i d l e}=p_{c o l l} * T_{c o l l} \end{equation}\] 其中: \(p_{i d l e}\)为信道为信道空闲的概率； \(p_{c o l l}\)为信道发生碰撞的概率； \(T_{i d l e}\)为空闲时隙的长度 \(T_{c o l l}\)为CCH上发生碰撞时持续的时间。 进一步，记信道繁忙概率为\(p_{busy}\)，包成功发生的概率为\(p_{succ}\)，则\(p_{coll} = p_{busy} - p_{succ}\)，然后我们有下面的方程组： \[\begin{equation} \left\{\begin{aligned} p_{1} &amp;=1-\left(1-p_{i}\right)^{M-1} *\left(1-p_{j}\right)^{K} \\ p_{2} &amp;=1-\left(1-p_{i}\right)^{M} *\left(1-p_{j}\right)^{K-1} \\ p_{i d l e} &amp;=\left(1-p_{i}\right)^{M-1} *\left(1-p_{j}\right)^{K-1} \\ p_{b u s y} &amp;=1-p_{i d l e}=1-\left(1-p_{i}\right)^{M-1} *\left(1-p_{j}\right)^{K-1} \\ p_{s u c c} &amp;=M * p_{i} *\left(1-p_{i}\right)^{M-1} *\left(1-p_{j}\right)^{K} \\ &amp;+K * p_{j} *\left(1-p_{i}\right)^{M} *\left(1-p_{j}\right)^{K-1} \end{aligned}\right. \label{12} \end{equation}\] 记\(T_{SAF\_pkt}, T_{WSA\_pkt}, T_{ACK\_pkt}, T_{SIFS}\)分别为发送安全消息，WSA消息，ACK消息的时间以及SIFS的长度。为了简化分析，我们令\(T_{coll}\)为最大碰撞时间，即上一个WSA包的最后一个比特和下一个WSA包的第一个比特发生了碰撞。那么有： \[\begin{equation} \left\{\begin{aligned} T_{i d l e} &amp;=a S l o t T i m e \\ T_{c o l l} &amp;=2 * T_{W S A \_p k t}+T_{S I F S} \\ T_{s u c c} &amp;=T_{W S A_{-} p k t}+T_{S I F S} \end{aligned}\right. \label{13} \end{equation}\] 根据公式\(\eqref{10}-\eqref{13}\)，可以求解出\(p_i\)和\(p_j\)。 Reference [1] G. Bianchi, “Performance analysis of the ieee 802.11 distributed coordination function,” IEEE Journal on Selected Areas in Communications, vol. 18, no. 3, pp. 535–547, 2000. [2] C. Shao, S. Leng, B. Fan, Y. Zhang, A. Vinel, and M. Jonsson, “Connectivity-aware medium access control in platoon-based vehicular ad hoc networks,” in 2015 ieee international conference on communications (icc), 2015, pp. 3305–3310. [3] J. Mao, Y. Mao, S. Leng, and X. Bai, “Performance optimization for ieee 802.11 with qos differentiation supporting,” Journal of Software, vol. 21, no. 11, pp. 2866–2882, 2010.]]></content>
  </entry>
  <entry>
    <title><![CDATA[马尔科夫链在WAVE链路层网络性能分析中的应用]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fmarkov%2Findex.html</url>
    <content type="text"><![CDATA[本文整理自[1]。这篇文章关注的是多信道MAC，即IEEE802.11p + IEEE1609.4。具体而言，主要研究下面几个方面: 饱和以及非饱和情况下数据传输性能； 多维马尔科夫链（最多三维）在MAC协议中的使用； 马尔科夫链模型和真是的应用需求对比，以改善现存的分析模型和协议设计。 现有通信机制/标准简述 为了构建车联网通信系统，每辆车都装备了On-Board Units (OBUs)，路边设置有Road Side Units (RSUs)作为基础设施支持。因此车联网通信可以划分为Vehicle-to-Vehicle(V2V)，Vehicle-to-Infrastructure(V2I)两个类别。 WAVE协议中，总共75MHz的带宽被划分为7个信道（1个控制信道CCH和6个服务信道SCH），每个信道10MHz带宽，外加5MHz的保护间隔。同时WAVE还在时间维度上将信道访问过程划分为CCH Interval和SCH Interval，每个50ms。 车联网中典型业务的网络性能要求如下图。 DSRC data traffic requirement [2] 学界现有的多信道MAC方案 IEEE 1609.4规范中给出的多信道方案的问题在于，固定的CCHI，SCHI长度无法适应多变的交通流场景。例如在低密度场景下，CCHI上空闲资源比较多，而高密度场景下，CCHI的长度不够发完所有的安全广播。有很多多信道MAC机制着眼于解决这一问题，见下图： Comparison of adaptive multi-channel MAC protocols 通过利用适当的理论模型（主要是马尔科夫链），MAC协议可以计算CCH上完成SCH调度需要的时间，进而动态的调整CCHI的长度，从而将原本空闲的CCHI资源让渡给SCH使用。类似的机制的主要过程如下： 安全信息拥有最高的优先级，照常发送 计算完成所有WSA包发送需要的时间 动态调整CCHI和SCHI的长度 该使用Markov模型的动态MAC机制不仅仅可以确保安全消息的延时，同时可以优化非安全消息的QoS MAC协议必须动态地调整其自定义系统参数来适应多变的网络环境。 大多数运用马尔科夫模型MAC协议都有如下的架设 理想信道（no hidden terminal and capture） 网络中的节点数量固定，为\(n\) 包的碰撞概率为常数，且对于每辆车而言都是相同的 非饱和条件下，包到达的过程为泊松过程 基于上述假设，离散时间马尔科夫链就可以用于802.11 DCF的性能分析，并用于计算CCHI的最佳长度。 另外，我们还总结了多信道MAC协议的一些研究趋势： IEEE802.11p EDCA的马尔科夫链分析：所有现存的自适应多信道MAC方法都使用了马尔科夫链来分析DCF性能。不过，EDCA部分的马尔科夫链模型表达方面研究还不多。EDCA和DCF的主要区别阿在于EDCA对于每一种不同的Access Category (AC)规定了不同的竞争窗口大小和仲裁间隔(Arbitration Inter-frame Space)。 自适应多信道MAC协议的精确马尔科夫模型：如同上面提到的，使用马尔科夫链进行性能分析的MAC协议大多假设了理想的信道条件。这一假设在真实的车联网场景下是不成立的。一些近期的工作，如FCM-MAC考虑了隐藏终端的问题[3]。 自适应多信道MAC协议中的灵活控制器方案(Flexible Controllers)：已经计算出了最佳的CCHI之后，这一信息需要被RSU或者簇头车辆广播出去。CAMAC提出了使用编队结构来实现改信息广播的功能。 簇头选择问题：在一个网络分簇中，簇头是由“寿命”制约的，当簇头车辆离开了分簇时，如何选择新的簇头是需要解决的问题。 ACK Interval: 这一研究趋势是指将ACK包放到独立的ACK Interval中发送。 马尔科夫链模型与动态CCHI [4]这篇文章应该是最早提供了一整套完整的使用马尔科夫链来进行DCF性能分析的方法论。这篇文章讨论的是满载场景（即每个车辆总是有一个包等待发送）下饱和吞吐率(saturated)与竞争窗口，以及其他要素之间的关系。但是在实际场景中，一般不会进入满载的情况。因此有很多文章通过增加一个额外的状态随机变量来扩展了[4]中的马尔科夫模型。这使得马尔科夫链模型从二维变成三维。 这里我们讨论两种典型的业务：安全信息与WSA包。 安全信息的特点在于延时敏感，以及缺少ACK。 WSA的情况要复杂一些，我们这里梳理一下WSA的工作过程。WSA的作用是SCH服务提供者声明其所能提供的服务的广播报。WSA在CCHI上传输，其中包含了广播者提供的服务的所有信息以及使用这一服务（即加入此BSS）必要的网络参数，例如BSS的ID，Provider Service ID，使用的SCH信道，时隙信息，EDCA参数等等。WSA要求对此服务感兴趣的节点发送ACK（在有一些研究中，所有的ACK都集中到专门的ACK Interval中发送） 一维马尔科夫链 由于安全消息天然是广播的，没有重传过程，因此可以用一维马尔科夫链来建模。竞争窗口记为\(W_e\)，始终是固定的。马尔科夫链的状态变量为\(\left\{k:k \in [0, W_e - 1]\right\}\)。令\(\lambda_e\)表示安全信息到达速度。马尔科夫链的平稳分布为\(b_{0,\emptyset}\)(信道空闲的概率)，\(b_{e, k}\)(处于退避状态\(k\)的概率)。令\(P_{i|j}\)为转移概率\(\{\operatorname{Pr}\{b(t+1)=i | b(t)=j\}\) 一维马尔科夫链。图中的Idle状态是在非饱和状态下才有的，如果在饱和状态下，即\(\lambda_e \to \infty\)，则不存在Idle状态 二维马尔科夫链 令\(s(t)\)和\(b(t)\)分别为代表WSA包在时隙\(t\)的退避阶段以及退避计数器的值的随机变量。令状态\(I_{s, \emptyset}\)代表WSA队列为空。最大重传次数为\(m\)，竞争窗口在第\(i\)个阶段为\(W_{s, i}, (i \in [0, m])\)。在第一次传输尝试时，退避窗口被设置为最小值\(W_{s, 0}\)。当检测到碰撞时，竞争窗口加倍，并且开始重传。一个重要的假定是\(s(t)\)，即退避的阶段，与是否发生碰撞是独立的。二维过程\(\{s(t), b(t)\}\)可以建模成二维马尔科夫链。根据在达到最大退避窗口时的不同行为，我们可以划分两个不同的类别： remaining maximal backoff stage: 即达到最大的竞争窗口后，直到发送成功前，始终保持最大竞争窗口； reset backoff stage: 即达到最大的竞争窗口后，立即重置竞争阶段\(s(t)\)。 二维马尔科夫过程 记转移概率为\(P_{i, k | j, l} = \{\operatorname{Pr}\{s(t+1)=i, b(t+1)=k | s(t)=j, b(t)=l\}\)。平稳分布为 \[\begin{equation} b_{s, i, k}=\lim _{t \rightarrow \infty}\{s(t)=i, b(t)=k\}, 0 \leq i \leq m, 0 \leq k \leq W_{s, i} - 1 \end{equation}\] 三维马尔科夫链 将CCHI上传输的包的类型分为三类：安全消息，WSA消息，控制消息。其中安全消息使用一维马尔科夫链，对于后两者，控制消息拥有更高的优先级，使用EDCA中的AC1，WSA使用AC2。 在三维马尔科夫链中，类似二维的情况，我们用\(s(i, t)\)和\(b(i, t)\)来分别表示退避阶段和退避计数器的值。这里的\(i\)表示EDCA类别，即\(i \in AC1, AC2\)。用\(v(i, t)\)表示退避过程的冻结状态(Freezing state)。综上，三维随机变量\(\{s(i, t), b(i, t), v(i, t)\}\)可以表示成三维马尔科夫变量。由于控制消息拥有更高的优先级，那么控制帧就不会处于Freezing状态，即\(v(i, t) = -1\)。此时AC1的马尔科夫链的结构和上一个部分我们提到的二维马尔科夫链的形态非常类似，如下图： Markov chain used for packet transmission analysis using AC1. 考虑\(v(i, t)\)状态。如果包遇到一个空闲的时隙，那么\(v(i, t)\)会从0变成-1。否则，如果遇到了一个繁忙的时隙，\(v(i, t)\)则会维持0不变。因此，AC2的马尔科夫链可以表示为： Markov chain used for packet transmission analysis using AC2. Reference [1] V. Nguyen, O. T. T. Kim, C. Pham, T. Z. Oo, N. H. Tran, C. S. Hong, and E. Huh, “A survey on adaptive multi-channel mac protocols in vanets using markov models,” IEEE Access, vol. 6, pp. 16493–16514, 2018. [2] A. M. Abdelgader and W. Lenan, “The physical layer of the ieee 802.11 p wave communication standard: The specifications and challenges,” in Proceedings of the world congress on engineering and computer science, 2014, vol. 2, pp. 22–24. [3] Y. Yao, K. Zhang, and X. Zhou, “A flexible multi-channel coordination mac protocol for vehicular ad hoc networks,” IEEE Communications Letters, vol. 21, no. 6, pp. 1305–1308, 2017. [4] G. Bianchi, “Performance analysis of the ieee 802.11 distributed coordination function,” IEEE Journal on Selected Areas in Communications, vol. 18, no. 3, pp. 535–547, 2000.]]></content>
  </entry>
  <entry>
    <title><![CDATA[常凯申微操集]]></title>
    <url>%2Fknowledge-base%2Fhistory%2F%E4%B8%AD%E5%9B%BD%E5%8F%B2%2F%E8%BF%91%E4%BB%A3%E5%8F%B2%2F%E6%B0%91%E5%9B%BD%2F%E5%8E%9F%E5%A7%8B%E5%8F%B2%E6%96%99%E9%9B%86%2F%E5%B8%B8%E5%87%AF%E7%94%B3%E5%BE%AE%E6%93%8D%E9%9B%86.html</url>
    <content type="text"><![CDATA[抗战前 在贵州追剿红军期间，蒋中正给十六军军长李韫珩下达手令，让其不要听薛岳的，按蒋中正的手令行动 李俊张抱冰兄。兄部本晚务望赶到安南以北地区，明晚赶到安南与普安间之新庄。务限廿三日前达到盘县。薛主任在前方恐不明全般情况，故兄处以后以中之命令为准。 手令内容 1 手令内容 2 1931年8月21日，蒋下手令给熊式辉，详细指导布置如何进行烧杀： 对匪巢只有焚烧，乃能解决，请派飞机设法暂停轰炸，而专用火油在欲烧之区域内，使皮带或者分水壶分布火油。如此分划区域，每区约焚二三日，使匪恐慌，不能立足。 手令内容 3 手令内容 4 抗战 九一八后半个多月后的10月7日，日军军舰开到镇江，蒋公致电叶楚伧，要当地警局负责给日军买菜，并负责送货到船： 日海军明日又来镇江，增加一艘。请注意，如其水兵上岸买菜等事，最好分与其交涉，由当地警局为其代买送船，以免纠纷。 手令内容 5 抗战后]]></content>
  </entry>
  <entry>
    <title><![CDATA[长江改道工程]]></title>
    <url>%2Fknowledge-base%2Fhistory%2F%E4%B8%AD%E5%9B%BD%E5%8F%B2%2F%E8%BF%91%E4%BB%A3%E5%8F%B2%2F%E7%8E%B0%E4%BB%A3%2F%E5%B7%A5%E7%A8%8B%2F%E9%95%BF%E6%B1%9F%E6%94%B9%E9%81%93%E5%B7%A5%E7%A8%8B.html</url>
    <content type="text"><![CDATA[原文出处（来自知乎-马前卒的回答） “万里长江，险在荆江”，荆江是长江中游的一段，上起湖北枝城，下迄湖南城陵矶。长江从三峡奔腾而下，进入“荆江”河段后水流湍急，走向摆动不定，导致河流蜿蜒曲折，仅从藕池口至城陵矶之间直线距离只有80公里，长江河流长度却达247公里，其间大弯小曲不下20余处。而监利县上车湾长江段（即环绕湖南华容集成垸河段），水道环绕则要四十多公里，而陆地4公里就可达到彼端。因此荆江又有“九曲回肠”之称。这样弯曲的河道既不利于航行，又由于水流不畅，洪水期极易泛滥成灾。 早在1936年我国水利专家章锡绶先生就提出“扬子江之患，荆河为甚，而上车湾实荆河之最险处，宜速积极开凿对岸之引河，以作根本之解决。”否则 荆江堤防若溃决，长江一泻千里，江汉平原将尽成泽国，而汉口市场，亦遭池鱼之叹。 章锡绶先生在长江上车湾河段实施裁弯截直工程的提议，经当时国内水利专家们和美国水利总工程师史笃培等详细研究，实地勘估，都认为确有必要实施，并制定了详细的工程方案和预算报告呈送至国民政府。但因当时国家处于连年内乱外患，对这一长江改道工程在国民党政府手中一直未能解决。 三十二年后，章锡绶先生提出的这个荆江裁弯治理的蓝图，终于在新中国政府手中得以实施。1968年底，国家正式批准实施长江上车湾河段改道工程。该工程是从湖南华容县境的长江天字一号段起，向南至洪山头段为止，开挖出5公里长、宽100多米、约20米深的人工河道，将这一段长江进行裁弯截直。为了实施这一工程 ，湘鄂两省政府动员了数万农民开挖河道。1968年底，不少长沙知青到华容插队落户“接受贫下中农再教育”，其中许多知青曾参加这一著名的长江改道开挖新河的劳动。 我下放所在的集成垸红旗大队，是离长江改道工地最近的几个大队之一。我到生产队的第三天，生产队长就安排了我们几个男知青去参加长江改道工程的劳动。我们到达工地，见数万民工如蚂蚁般的在狭长的荒洲上劳动，人山人海，场面很是壮观。当时开挖新河道工程已完成了一大半，河道已初见雏形。开挖河道就是将河床的泥土运至新河道两岸百余米的地方堆积成堤坝，那时没有使用一台所谓挖土机、推土机等机器设备，完全是用人工手挖肩挑。河道底部的泥土粘而含有水分，因此挖土不用锄头而用当地特有的一种挖土工具--铁锨铲，象切豆腐一样，把一大块一大块泥土切割，再装入筐萁运走。我们知青刚去还不会用铁锹就只能用肩去挑土了。其实挑土也很辛苦，从河床底部要将泥土挑到倒堆积土处，路途长，坡又陡，当时运土是采用分级接力运输办法，即一人挑一担土向上运送一段，另一人又将这担土接力运送上去。由于前几天刚下过一场大雪，运土的路都很泥泞，一不小心，鞋就陷进泥浆中拔不出来。知青们大多是刚从事这么繁重的劳动，整天用肩挑泥土，在泥泞中爬坡，感到很辛苦。我一、二天后肩膀就压红肿了，收工后躺在工棚里就不想爬起来………… 到1969年春节，新河道挖掘完工了，仅留下靠长江两端的河道未挖通，暂时以抵挡江水。我们集成垸的知青回长沙过春节，或去砖桥公社办事，来回都要从新开挖的河道中爬下爬上走过。直到那年3月份长江的江汛来了，长江水位达到一定标准后，有关部门动用炸药将新河道两端的泥坝炸毁。随着几声沉闷的爆炸声，滚滚长江从新河道奔流而下，新河道启用了。汹涌湍急的江水冲刷着河道两岸，更一步拓宽着河道，裁弯截直的河道才发挥作用。以后当地群众把这一段新开的长江河段称为“新河”，以后设立的渡口又叫“新河渡口”。 原文附图，红色部分就是农民和下乡知青一铲一铲挖出来的新长江。 然而这还不是全部的荆江截弯工程。看下面的百度地图和卫星图： 地图 卫星地图 连绵的长江牛轭湖（即截弯后的旧河道），约有一半是六七十年代战天斗地的成就，是无数农民和知青用肩膀挑出来的地理景观。这才是在太空中也能看得到的人力工程奇迹，从工程方面比较，长城瞬间就被比下去了]]></content>
  </entry>
  <entry>
    <title><![CDATA[淠史杭自流灌溉工程]]></title>
    <url>%2Fknowledge-base%2Fhistory%2F%E4%B8%AD%E5%9B%BD%E5%8F%B2%2F%E8%BF%91%E4%BB%A3%E5%8F%B2%2F%E7%8E%B0%E4%BB%A3%2F%E5%B7%A5%E7%A8%8B%2F%E6%B7%A0%E5%8F%B2%E6%9D%AD%E8%87%AA%E6%B5%81%E7%81%8C%E6%BA%89%E5%B7%A5%E7%A8%8B.html</url>
    <content type="text"><![CDATA[原文出处（来自知乎-马前卒的回答） 淠【pì】史杭自流灌溉工程。是1958年大跃进时想出来的疯狂项目。61年曾被点名要求下马停工，但当地的干部和民工最终咬牙坚持到底，在大别山外围建出了一个超级丰产区。 在毛主席 “一定要把淮河修好” 的伟大号召下，安徽人民先后在大别山区修建了佛子岭、梅山、响洪甸、磨子潭、龙河口五大水库，拦蓄大别山区上游来水，减轻淮河干流防洪压力。五大水库的修建，拓展了安徽省委、省政府的治水思路，为综合利用水资源，彻底解除江淮丘陵地区的旱涝灾害，在科学规划的基础上作出了战略决策，决定兴建淠史杭沟通工程，连接五大水库，沟通淠河、史河、杭埠河三大自然河流，建设完整、系统、科学的灌溉网络。1958年6月，淠史杭工程指挥部正式成立。 1958年8月19日，灌区工程总指挥赵子厚在淠河灌区渠首横排头开挖第一锹土，拉开了淠史杭工程的建设序幕，百万安徽人民开始了建设淠史杭工程的伟大征程。当时，正值国家三年自然灾害，资金困难，技术匮乏，材料短缺，安徽人民发扬“自力更生、艰苦奋斗”精神不卑不弃，坚忍不拔。面对原始的施工工具，他们开展技术革新，创造了专攻切岭工程的“洞室爆破法”，发明了专攻“麻僵土”的劈土法，研制了垂直运输土工具“倒拉器”，以自己的聪明才智克服了工程建设中的千难万险；面对短缺的建筑材料，他们无私奉献，自制炸药，自建水泥厂，捐献木料，保证了骨干工程和重要建筑物的建筑用材；在1958—1972年14年间，他们胼手胝足，肩挑手抬，艰苦奋战，以铁锹、十字镐、独轮车等原始工具，大干4亿个工日，开挖了2.5万公里渠道，完成近6亿\(m^3\)土方，建成了横跨江淮、沟通三河、造福皖豫的特大型灌区，创造了新中国水利史上的人民丰碑。一代文豪郭沫若在参观淠史杭工程时赋诗称赞：“人民力量不寻常”。 淠史杭灌区工程示意图 淠史杭灌区工程示意图 水脉图和地形图对照 水脉图和地形图对照，可以看到这是一个结合山区水库和平原灌溉网，沟通不同水系的自流灌溉项目。这个工程主体也是靠人力和农业社会的物资完成的。五六十年代的中国也实在没有多少工业物资可投入。 1958年，入夏以后，连续70多天无透雨，塘坝干涸，田地龟裂，庄稼枯死，500多万亩农田成灾，尚有152万亩不能下种，全区有200万人投入抗旱。 1958年8月19日，淠史杭工程开工典礼在六安县苏埠镇南５公里的横排头隆重举行，这里曾是当年徐向前创造“苏家埠48天战役”大捷的战场，而今为了创造建设新中国的奇迹，六安人民再一次在这里誓师，向大自然宣战。中共六安地委第一书记杜维佑为典礼剪彩，专员兼淠史杭工程指挥赵子厚发布开工命令，挥锹破土。 开工初期，国家没给一分钱，地区财政也拿不出钱，所需物质基本上靠群众自筹。据统计，在一、二两个工期，群众自筹石料14.22万立方米，木材2.16万立方米，树材22万多棵，圆竹65万公斤，毛竹12万多根，旧钢铁437吨。开山炸石，没有炸药，就发动群众刮墙土熬硝，自制土炸药。没有水泥，就自建了三个水泥厂，用石臼舂，用碾子碾，石料破碎以后，用筛子筛，用手工搅拌。木料不足，许多群众把家中盖房子的木头、门板都献出来了，有的甚至把给老人准备的棺材都拆散抬到工地。11条干渠全面铺开，最高上工人数达67.8万，民工们挑着粮食和铺盖，从四面八方聚集到工地，每个民工一个工日补助0.25-0.5公斤口粮和一毛钱菜金。 下图是当年的施工场面和奖状。 施工图 奖状 淠史杭工程的影响有多大呢？ 中国淠河、史河、杭埠河3个毗邻灌区的总称。位于安徽省中西部和河南省中南部，地处大别山余脉的丘陵地带，横跨长江、淮河两大流域，总面积1.31万平方千米。灌区水源来自佛子岭水库、响洪甸水库、磨子潭水库、梅山水库和龙河口水库。总库容66亿立方米。该灌区于1958年开工 ，1959年开始灌溉农田，以后逐年续建配套，1987年干渠以上工程完工，支渠以下工程还在进行。工程以灌溉为主，兼有发电、航运、水产养殖、城市用水的综合利用工程，包括：淠河、史河、杭埠河三大渠首枢纽工程，7级渠道的2条总干渠，11条干渠，19条分干渠，总长1384千米；1.3万条支渠、斗渠、农渠，总长2.26万千米；大小渠系建筑物6万多座；中小型调节水库1066座和21万口塘坝，有效库容12.3亿立方米；抽水站、补水站总装机容量14.1万千瓦。该工程实现了40万公顷农田的自流灌溉，实灌面积达58万公顷，并解除了淠、史河下游的洪灾，减轻了淮河干流的洪灾。. 四五十万公顷农田从旱地变成旱涝保收的水浇地，这个说法貌似不容易形成直观概念。我们可以和名声更大的都江堰灌区（不只是都江堰枢纽）对比。到1950年的时候，都江堰灌区修了2000多年，总灌溉面积是18万公顷（解放后扩建到60万公顷）。这还依赖于川西极有利的地形。淠史杭工程用14年时间在贫瘠的大别山外围搞了三个都江堰灌区出来，不依赖电力的自流灌溉面积也相当于2个都江堰灌区。效果不言而喻。 灌区枢纽之一，颇有都江堰的味道 灌区图片 灌区工程的建设和运行，大大改善了皖西、皖中地区的农业生产条件，区域内的灌溉面积由兴建时的120万亩发展到现在的1000万亩，粮食年产量由兴建时12.3亿公斤提高到目前的50亿公斤左右，灌区17个县（区）有7个是国家级商品粮生产基地县，正常年份提供的商品粮不少于18亿公斤。淠史杭灌区是安徽乃至全国的粮食主产区，它以占安徽1/10的土地面积、1/6的耕地面积、1/5的有效灌溉面积生产1/4的粮食产量、1/3的水稻产量，奠定了安徽粮食主产省的重要地位（河南效果另计）。]]></content>
  </entry>
  <entry>
    <title><![CDATA[ns3中的wave模块]]></title>
    <url>%2Fknowledge-base%2Facademic%2Fits%2Fwave%2Fns3%E4%B8%AD%E7%9A%84wave%E6%A8%A1%E5%9D%97%2Findex.html</url>
    <content type="text"><![CDATA[前言 ns-3 is a discrete-event network simulator for Internet systems, targeted primarily for research and educational use. ns-3 is free software, licensed under the GNU GPLv2 license, and is publicly available for research, development, and use. 简而言之，ns3是一款基于C++的离散事件网络模拟器，其内部实现了很多常见的网络协议。因此学术界通常使用ns3来作为论文仿真分析的框架。我们在这篇文章里梳理一下ns3中关于WAVE部分的内容。 WAVE的初始化 下面的代码给出了一种WAVE机制的初始化方法： 123456789101112131415161718192021222324252627282930313233343536373839404142/* * lossModelName: 信道损失模型，默认值是 * ns3::LogDistancePropagationLossModel */auto lossModelName = m_config-&gt;Get ("lossModel");double freq = 5e9;YansWifiChannelHelper waveChannel;waveChannel.SetPropagationDelay ("ns3::ConstantSpeedPropagationDelayModel");if (lossModelName == "ns3::TwoRayGroundPropagationLossModel") &#123; waveChannel.AddPropagationLoss (lossModelName, "Frequency", DoubleValue (freq), "HeightAboveZ", DoubleValue (1.5));&#125; else if (lossModelName == "ns3::LogDistancePropagationLossModel") &#123; waveChannel.AddPropagationLoss (lossModelName);&#125; else &#123; waveChannel.AddPropagationLoss (lossModelName, "Frequency", DoubleValue (freq));&#125;/** * propagationLossModel: 默认是None */auto propagationLossModel = m_config-&gt;Get ("propagationLossModel");if (propagationLossModel != "None") &#123; waveChannel.AddPropagationLoss (propagationLossModel);&#125;// Create the channel using settings aboveauto wavePhy = YansWavePhyHelper::Default ();wavePhy.SetChannel (waveChannel.Create ());wavePhy.SetPcapDataLinkType (WifiPhyHelper::DLT_IEEE802_11);/** * 发射功率，单位为dbm */auto txp = m_config-&gt;Get&lt;double&gt; ("txp");wavePhy.Set ("TxPowerStart",DoubleValue (txp));wavePhy.Set ("TxPowerEnd", DoubleValue (txp));QosWaveMacHelper waveMac = QosWaveMacHelper::Default ();WaveHelper waveHelper = WaveHelper::Default ();auto phyMode = m_config-&gt;Get ("phyMode");waveHelper.SetRemoteStationManager ("ns3::ConstantRateWifiManager", "DataMode",StringValue (phyMode), "ControlMode",StringValue (phyMode));m_devices = waveHelper.Install (wavePhy, waveMac, m_nodes); 这段代码中我们逐一创建了信道模型，物理层，链路层，最后通过waveHelper将各个部分组装在一起，并且安装到节点上： 1m_devices = waveHelper.Install (wavePhy, waveMac, m_nodes); waveHelper waveHelper-&gt;Install的核心代码如下： 1234567891011121314151617181920212223242526272829303132Ptr&lt;Node&gt; node = *i;Ptr&lt;WaveNetDevice&gt; device = CreateObject&lt;WaveNetDevice&gt; ();device-&gt;SetChannelManager (CreateObject&lt;ChannelManager&gt; ());device-&gt;SetChannelCoordinator (CreateObject&lt;ChannelCoordinator&gt; ());device-&gt;SetVsaManager (CreateObject&lt;VsaManager&gt; ());device-&gt;SetChannelScheduler (m_channelScheduler.Create&lt;ChannelScheduler&gt; ());for (uint32_t j = 0; j != m_physNumber; ++j) &#123; Ptr&lt;WifiPhy&gt; phy = phyHelper.Create (node, device); phy-&gt;ConfigureStandard (WIFI_PHY_STANDARD_80211_10MHZ); phy-&gt;SetChannelNumber (ChannelManager::GetCch ()); device-&gt;AddPhy (phy); &#125;for (std::vector&lt;uint32_t&gt;::const_iterator k = m_macsForChannelNumber.begin (); k != m_macsForChannelNumber.end (); ++k) &#123; Ptr&lt;WifiMac&gt; wifiMac = macHelper.Create (); Ptr&lt;OcbWifiMac&gt; ocbMac = DynamicCast&lt;OcbWifiMac&gt; (wifiMac); // we use WaveMacLow to replace original MacLow ocbMac-&gt;EnableForWave (device); ocbMac-&gt;SetWifiRemoteStationManager ( m_stationManager.Create&lt;WifiRemoteStationManager&gt; ()); ocbMac-&gt;ConfigureStandard (WIFI_PHY_STANDARD_80211_10MHZ); device-&gt;AddMac (*k, ocbMac); &#125;device-&gt;SetAddress (Mac48Address::Allocate ());node-&gt;AddDevice (device);devices.Add (device); 首先创建WAVE设备，并且设置ChannelCoordinator, VsaManager, ChannelScheduler，逐一最后一个是通过是通过工厂对象创建的。工厂对象默认创建的ChannelScheduler是ns3::DefaultChannelScheduler(事实上ns3内部只有这一个具体的ChannelCoordinator实现). 在接下来的循环中，waveHelper利用参数中传入的物理层Helper来创建物理层对象。这里的m_physNumber默认为1。对于物理层，这里进一步设置了信道带宽标准（10MHz），将信道号设置为CCH信道号。 在第二个循环中，waveHelpher创建WAVE的七个信道，这里的m_macsForChannelNumber默认来自ChannelManager::GetWaveChannels ()。在循环体内，对于每一个WAVE信道，wave进行如下操作： 启用WAVE支持(这一部分详细阅读以下面的waveMac章节) 设置RemoteStationManager 设置标准为WIFI_PHY_STANDARD_80211_10MHZ 最后为设备分配MAC地址。 wavePhy YansWavePhyHelper继承了YansWifiPhyHelper。相比于父类，wavePhy其实主要修改了自带的日志输出范式，对于功能主干影响不大。我们来看关键的YansWifiPhyHelper::Create函数。 12345678910Ptr&lt;WifiPhy&gt;YansWifiPhyHelper::Create (Ptr&lt;Node&gt; node, Ptr&lt;NetDevice&gt; device) const&#123; Ptr&lt;YansWifiPhy&gt; phy = m_phy.Create&lt;YansWifiPhy&gt; (); Ptr&lt;ErrorRateModel&gt; error = m_errorRateModel.Create&lt;ErrorRateModel&gt; (); phy-&gt;SetErrorRateModel (error); phy-&gt;SetChannel (m_channel); phy-&gt;SetDevice (device); return phy;&#125; 这个函数只是按部就班地设置对应的属性，没有特别的处理。 waveMac waveMac直接使用了QosWaveMacHelper的默认设置。这个部分Helper配置的部分极少。可以认为是直接从构造函数创建OcbWifiMac。 OCB，即Outside Context of BSS，即脱离BSS的组织形式，让节点直接直接进行通信的范式。 OcbWifiMac 的注释可以提供进一步的说明： In OCB mac mode,synchronization, association, dis-association and authentication of normal wifi are not used for wireless access in vehicular environments. Although Timing Advertisement frame is a specific management frame defined in 802.11p. It is mainly used by IEEE Std 1609.4 for channel switch synchronization. However in simulation nodes are supposed to have GPS synchronization ability, so we will not implement this feature. 关于OcbWifiMac::EnableForWave的说明： 在waveHelper的处理中，对创建的OcbWifiMac对象调用了EnableForMac函数。这个函数的主要作用是，将OcbWifiMac的m)low底层MAC实现，从MacLow替换为WaveMacLow。 WAVE中的Tx 通过WaveNetDevice直接发包方式下的路径 这里我们使用直接从WaveNetDevice的发送接口进行发包的方法。例如： 12345678auto sender = DynamicCast&lt;WaveNetDevice&gt; (m_devices.Get (0));auto receiver = DynamicCast&lt;WaveNetDevice&gt; (m_devices.Get (1));const Address dest = receiver-&gt;GetAddress ();SeqTsHeader seqTs;seqTs.SetSeq (1);packet-&gt;AddHeader (seqTs);// 0x0800是IP协议号sender-&gt;Send (packet, dest, 0x0800); 这里的协议号是0x0800，即发送的是IP包，IP包只能在CCH上发送 注意在执行上面的发送前还需要对WAVE进行信道配置，否则无法发送。信道配置不需要在每次发送前配置，只需要在设置发生变更的时候修改设置即可。配置的示例代码如下： 123456789101112auto schInfo = SchInfo (SCH1, immediateAccess, EXTENDED_ALTERNATING);auto txProfile = TxProfile (SCH1);auto sender = DynamicCast&lt;WaveNetDevice&gt; (m_devices.Get (0));auto receiver = DynamicCast&lt;WaveNetDevice&gt; (m_devices.Get (1));Simulator::Schedule ( Seconds (0), &amp;WaveNetDevice::RegisterTxProfile, sender, txProfile);Simulator::Schedule ( Seconds (0), &amp;WaveNetDevice::RegisterTxProfile, receiver, txProfile);Simulator::Schedule ( Seconds (0), &amp;WaveNetDevice::StartSch, sender, schInfo);Simulator::Schedule ( Seconds (0), &amp;WaveNetDevice::StartSch, receiver, schInfo); WaveNetDevice::Send 这里的调用入口是WaveNetDevice::Send(ns3::Ptr&lt;...&gt; packet, const ns3::Address &amp;dest, uint16_t protocol). 这个函数中做了如下处理: 检查m_txProfile，在WAVE中的，要发送数据必须要先注册一个TxProfile，这个结构提供了上层对于物理底层参数的控制能力。 检查还是否可以访问m_txProfile中指定的信道。 检查m_txProfile中的其他参数，并生成一个HigherLayerTxVectorTag的PacketTag添加到包中。 添加LlcSnapHeader，此Header中包含了协议类型（如是IP包，协议为0x0800）。 根据m_txProfile中制定的信道编号，获取对应的WifiMac(实质是OcbWifiMac)，将包压入其队列。这一级调用见下一个子部分。 OcbWifiMac::Enqueue 这个函数里的处理主要分为两个部分：一是m_stationManager的相关处理，二是QoS相关的处理。同时，MAC帧头WifiMacHeader也在这里生成。 注意，在WAVE中，QoS功能是启用的，即GetQosSupported返回true。那么发送队列的选择会由EDCA机制来控制: 1m_edca[QosUtilsMapTidToAc (tid)]-&gt;Queue (packet, hdr); 其中m_edca的类型为EdcaQeueus（typedef std::map&lt;AcIndex, Ptr&lt;QosTxop&gt; &gt; EdcaQueues;），本质从EDCA的Access Category index映射到对应对应队列的字典。 QosTxop::Queue QosTxOp继承自Txop。Queue这个函数没有改动。在Txop::Queue内，传入的包被纳入m_queue这个内部队列，然后StartAccessIfNeeded被调用来尝试访问信道。 m_queue是WifiMacQueue类型。这个队列实现了802.11协议中的超时功能。在包被取出时，队列检查其时间戳，如果超时会丢弃这个包。 ChannelAccessManager::StartAccessIfNeeded StartAccessIfNeeded是开始信道访问尝试的入口，这个过程涉及众多函数，我们在这里统一梳理。 在StartAccessIfNeeded函数中，若 m_currentPacket为空，即当前没有正在发送的包。 m_queue不是空，即还有包等待发送 IsAccessRequested()为false，为了避免请求信道重复 m_low-&gt;IsCfPeriod为false，底层mac是否处于可供发送的状态 (CF: Contention-Free) 以上条件全部得到满足，那么Txop会通过m_channelAccessManager-&gt;RequestAccess来请求访问信道。 这里的m_channelAccessManager是从RegularWifiMac::m_channelAccessManager赋值而来，不同的同一个mac层的不同Txop共享。 ChannelAccessManager会处理和退避相关的事宜： 如果信道可以访问，调用ChannelAccessManager::DoGrantAccess 不管在任何情况下，调用ChannelAccessManager::DoRestartAccessTimeoutIfNeeded，这一步是为了调度一下次对信道的访问尝试（例如如果本次访问信道失败，则重新更新退避信息后，在一定间隔后再次访问信道）。 在DoGrantAccess中，最终成功访问到信道的Txop的NotifyAccessGranted函数会被调用。 信道的访问规则使我们关注的重点，尤其是CCH和SCH的信道访问控制。经过测试发现，在CCHI时请求SCH信道时，不会调用DoGrantAccess。在CCHI发起SCH请求时，m_sleeping为true，因此会在RequestAccess函数开头即返回，这里也不会通过DoRestartAccessTimeoutIfNeeded来调度下一次信道访问（毕竟信道睡眠中）。可见WAVE的Aternative Accessing在MAC层是通过让OcbWaveMac周期性地睡眠实现的。这一功能主要实现于DefaultChannelScheduler中。 QosTxop::NotifyAccessGranted QosTxop覆盖了NotifyAccessGranted的实现。在这函数里面，WifiMacHeader中的一些参数进行了重新设置。主要包括： SeqNo 禁止分段（即将大包拆解成小包传输） NoRetry 注意，对于QoS数据包，ACK在这里被禁用： 12345678if (m_currentHdr.IsQosData () &amp;&amp; m_currentHdr.IsQosBlockAck ())&#123; m_currentParams.DisableAck ();&#125;else&#123; m_currentParams.EnableAck ();&#125; 在涉及参数配置以及AMSDU等方面的设置完成后调用m_low-&gt;StartTransmission。前面我们提到过，这里的m_low为WaveMacLow类型。 WaveMacLow::StartTransmission 发送过程中地址的处理 WaveNetDevice::Send接口发送数据时，我们发现发送的目标地址并不是设置到packet里面，而是独立传递进了接口。这里简要梳理一下在发送过程中地址的处理。 在WaveNetDevice::Send函数中，Address类型的目标地址被转换成Mac48Address类型，再传递给OcbWifiMac::Enqueue函数。在这个函数里面，这个地址被复制给802.11的帧头的addr1字段。帧头的类型为WifiMacHeader RTS/CTS RTS/CTS部分是由MacLow负责的，我们从MacLow::StartTransmission开始梳理。 NeedRTS 首先要讨论的是，系统如何决定一个包是否需要进行RTS 123456boolMacLow::NeedRts (void) const&#123; WifiTxVector dataTxVector = GetDataTxVector (m_currentPacket, &amp;m_currentHdr); return m_stationManager-&gt;NeedRts (m_currentHdr.GetAddr1 (), &amp;m_currentHdr, m_currentPacket, dataTxVector);&#125; 这里的取出来的dataTxVector的作用并不关键，其主要作用的是两个因素： 地址是否是group: address.IsGroup () 包的大小是否超过了WifiRemoteStationManager::m_rtsCtsThreshold。不过这个包被默认设置为65535，这个条件几乎无法满足. WSA包的发送 发送WSA包时，配置方法与发送IP包的是一致的，具体到发送上，餐卡wave-simple-device.cc里面的示例: 12345Ptr&lt;Packet&gt; wsaPacket = Create&lt;Packet&gt; (100);Mac48Address dest = Mac48Address::GetBroadcast ();const VsaInfo vsaInfo = VsaInfo (dest, OrganizationIdentifier (), 0, wsaPacket, SCH1, 100, VSA_TRANSMIT_IN_BOTHI);Simulator::Schedule (Seconds (1.0), &amp;WaveNetDevice::StartVsa, sender, vsaInfo);Simulator::Schedule (Seconds (3.0), &amp;WaveNetDevice::StopVsa, sender, SCH1); VsaInfo VsaInfo的定义如下： 12345678910struct VsaInfo&#123; Mac48Address peer; ///&lt; peer OrganizationIdentifier oi; ///&lt; OI uint8_t managementId; ///&lt; management ID Ptr&lt;Packet&gt; vsc; ///&lt; VSC uint32_t channelNumber; ///&lt; channel number uint8_t repeatRate; ///&lt; repeat rate enum VsaTransmitInterval sendInterval; ///&lt; send interval&#125; 其中： peer: 为发送目标地址，一般是广播地址 oi: 服务提供者的组织ID managementId: manage id vsc: 需要发送的包内容 channelNumber: 目标信道，这里指需要指定的SCH信道 repeatRate: 发送速度，即每秒多少个 sendInterval: 这是一个枚举类型，指定了包应该在哪些时隙上发送。其取值包括： VSA_TRANSMIT_IN_CCHI VSA_TRANSMIT_IN_SCHI VSA_TRANSMIT_IN_BOTHI WaveNetDevice::StartVsa 传入参数vsaInfo中规定了发送WSA包的必要信息。在WaveNetDevice::StartVsa函数中，设备检查了vsaInfo的数据的完整性，然后交给m_vsaManager-&gt;SendVsa来进行发送。在VsaManager中，CCHI和SCHI的访问控制，以及txVector的控制信息都在这里实现，同时，此包被赋予了EDCA最高优先级(AC_V0)。然后交给OcbWifiMac-&gt;SendVsc来执行发送。通过这个接口发送的包会被标记为管理包。 WAVE中的信道管理 ChannelCoordinator负责控制信道切换的时机，让所有的节点的信道切换同步，而ChannelScheduler负责执行具体的信道切换。在DefaultChannelScheduler::SetWaveNetDevice中，ChannelCoordinator和ChannelScheduler得以联系起来： 12m_coordinationListener = Create&lt;CoordinationListener&gt; (this);m_coordinator-&gt;RegisterListener (m_coordinationListener); ChannelCoordinator在调用其DoInitialize函数内部完成初始化之后即通过StartChannelCoordination函数开启往复调用的信道协调同步过程。这个过程首先进入的是Guard Interval(NotifyGuardSlot)。 1234567891011121314151617181920voidChannelCoordinator::NotifyGuardSlot (void)&#123; NS_LOG_FUNCTION (this); Time guardSlot = GetGuardInterval (); bool inCchi = ((m_guardCount % 2) == 0); if (inCchi) &#123; m_coordination = Simulator::Schedule (guardSlot, &amp;ChannelCoordinator::NotifyCchSlot, this); &#125; else &#123; m_coordination = Simulator::Schedule (guardSlot, &amp;ChannelCoordinator::NotifySchSlot, this); &#125; for (ListenersI i = m_listeners.begin (); i != m_listeners.end (); ++i) &#123; (*i)-&gt;NotifyGuardSlotStart (guardSlot, inCchi); &#125; m_guardCount++;&#125; 在这个函数里面根据inCchi来决定调度NotifyCchSlot还是NotifiySchSlot。在函数最末，通告所有的Listener，Guard Interval开始了。后续的NotifyCchSlot和NotifiySchSlot的做法也是类似的。 在DefaultChannelScheduler::NotifyGuardSlotStart中，开头的Guard Interval长度被设置为繁忙mac-&gt;MakeVirtualBusy (duration);。实际的信道切换过程也在这个函数中通过调用DefaultChannelScheduler::SwitchToNextChannel来进行。由于Guard Interval区间内被设置为繁忙，所以当设备结束睡眠时，检测信道繁忙，故而会开始执行退避。 这里有一个疑问：ChannelCoordinator内部的Schedule调度完全是独立进行的，如果采用了Extended Access，即CCHI会提前结束，那么原定的Guard Interval还是会被设置么？ 退避过程(Backoff) 退避过程主要实现在ChannelAccessManager内。在Txop::Queue函数收到一个包之后，会调用Txop::StartAccessIfNeeded这个函数来尝试访问信道。 123456789101112voidTxop::StartAccessIfNeeded (void)&#123; NS_LOG_FUNCTION (this); if (m_currentPacket == 0 &amp;&amp; !m_queue-&gt;IsEmpty () &amp;&amp; !IsAccessRequested () &amp;&amp; !m_low-&gt;IsCfPeriod ()) &#123; m_channelAccessManager-&gt;RequestAccess (this); &#125;&#125; 实质调用的ChannelAccessManager::RequestAccess这个函数。这个函数我们挑选其中重要的代码列在下面： 123456789101112131415161718192021222324252627282930313233343536voidChannelAccessManager::RequestAccess (Ptr&lt;Txop&gt; state, bool isCfPeriod)&#123; // ... UpdateBackoff (); NS_ASSERT (!state-&gt;IsAccessRequested ()); state-&gt;NotifyAccessRequested (); Time lastTxEnd = m_lastTxStart + m_lastTxDuration; if (lastTxEnd &gt; Simulator::Now ()) &#123; NS_LOG_DEBUG ("Internal collision (currently transmitting)"); state-&gt;NotifyInternalCollision (); DoRestartAccessTimeoutIfNeeded (); return; &#125; if (state-&gt;GetBackoffSlots () == 0) &#123; if (IsBusy ()) &#123; NS_LOG_DEBUG ("medium is busy: collision"); // someone else has accessed the medium; generate a backoff. state-&gt;NotifyCollision (); DoRestartAccessTimeoutIfNeeded (); return; &#125; else if (IsWithinAifs (state)) &#123; NS_LOG_DEBUG ("busy within AIFS"); state-&gt;NotifyCollision (); DoRestartAccessTimeoutIfNeeded (); return; &#125; &#125; DoGrantAccess (); DoRestartAccessTimeoutIfNeeded ();&#125; 这个函数内部主要步骤为： 检查是否有内部冲突，即当前是否正在发送一个数据包。如果发生了内部冲突，会调用Txop::NotifyInternalCollision回调，并通过DoRestartAccessTimeoutIfNeeded这个函数在一段时间后重新访问信道。 检查退避计数器的状态：如果计数器到0了，若信道繁忙，则认为产生了一次碰撞，若仍然在Aifs状态，那么也认为是一次碰撞（事实上这里的两个分支是一样的） 如果退避计数器不是0，即上一次退避未完成时，通过DoRestartAccessTimeoutIfNeeded这个函数延后访问信道（这里的DoGrantAccess函数不会允许访问信道）。 下面我们分解讲一下主要函数的作用。 UpdateBackoff 在实际的WAVE系统中，其退避过程为了性能考虑采用是离散的方法，即定一个退避计数器，每经过一个时隙（slot），这个退避计数器减一，直到变成0。有意思的是，在仿真系统中，NS3反而是使用了“连续”的方法来实现（当然本质是离散的，但是API调用形式上使用Simulator::Schedule直接调度backoff相关事件，显得是连续的）。此时，我们如果要访问退避计数器的值，如调用（state-&gt;GetBackoffSlots ()），就需要先调用UpdateBackoff这个函数来进行离散和连续的转化。 DoRestartAccessTimeoutIfNeeded 在ChannelAccessManager的实现中，ChannelAccessManager和Txop是一对多的关系，即多个Txop可以由同一个ChannelAccessManager来管理。不过在实际代码中，至少我们关注的RegularWifiMac及其子类，ChannelAccessManager和Txop都是一对一。 123456789101112131415RegularWifiMac::RegularWifiMac ()&#123; // ... m_channelAccessManager = CreateObject&lt;ChannelAccessManager&gt; (); m_channelAccessManager-&gt;SetupLow (m_low); m_txop = CreateObject&lt;Txop&gt; (); m_txop-&gt;SetMacLow (m_low); m_txop-&gt;SetChannelAccessManager (m_channelAccessManager); m_txop-&gt;SetTxMiddle (m_txMiddle); m_txop-&gt;SetTxOkCallback (MakeCallback (&amp;RegularWifiMac::TxOk, this)); m_txop-&gt;SetTxFailedCallback (MakeCallback (&amp;RegularWifiMac::TxFailed, this)); m_txop-&gt;SetTxDroppedCallback (MakeCallback (&amp;RegularWifiMac::NotifyTxDrop, this)); // ...&#125; 我们这里还是假定以存在多个txop的情况来讨论。在DoRestartAccessTimeoutIfNeeded中，函数首先根据当前的状态，选择出最近一个结束一轮退避过程Txop的退避结束时间expectedBackoffEnd。如果当前已经安排的m_accessTimeout时间在这个退避结束时间后面，那么以新的时间重新调调度一个m_accessTimeout事件。这一事件的回调函数是ChannelAccessManager::AccessTimeout AccessTimeout 这个函数内部非常简单： 12345678voidChannelAccessManager::AccessTimeout (void)&#123; NS_LOG_FUNCTION (this); UpdateBackoff (); DoGrantAccess (); DoRestartAccessTimeoutIfNeeded ();&#125; DoGrantAccess 这个函数内部进行真正的信道权限赋予的操作。不过函数仍然会检查每个Txop的退避状态，只有完成了退避的Txop才有可能被赋予信道访问权限。另外，对于 其他正在尝试访问信道的Txop，会出发一次Internal Collision. 被赋予信道访问权限的Txop的NotifyAccessGranted函数会被调用. EDCA优先级控制 发送过程优先级设置 EDCA优先级控制通过过程如下： 在WaveNetDevice::SendX函数的参数TxInfo中，包含一个priority的属性，这个属性被设置到SocketPriorityTag中，并被添加到包中。在OcbWifiMac::Enqueue函数中通过QosUtilsMapTidToAc函数转化成EDCA index，具体转化规则为： 0, 3 -&gt; VC_BE (Best Effort) 1, 2 -&gt; AC_BK (Background) 4, 5 -&gt; VC_VI (Video) 6, 7 -&gt; VC_VO (Audio) 这里的Priority的默认值是7 优先级的退避参数设置 WAVE使用的是OcbWifiMac，对EDCA队列的配置通过函数OcbWifiMac::ConfigureEdca来进行。这个函数的调用树如下： WaveHelper::Install -&gt; WifiMac::ConfigureStandard -&gt; OcbWifiMac::FinishConfigureStandard -&gt; OcbWifiMac::ConfigureEdca. OcbWifiMac::ConfigureEdca中的具体设置过程如下： 123456789101112131415161718192021222324252627282930313233343536373839404142voidOcbWifiMac::ConfigureEdca (uint32_t cwmin, uint32_t cwmax, uint32_t aifsn, enum AcIndex ac)&#123; NS_LOG_FUNCTION (this &lt;&lt; cwmin &lt;&lt; cwmax &lt;&lt; aifsn &lt;&lt; ac); Ptr&lt;Txop&gt; dcf; switch (ac) &#123; case AC_VO: dcf = RegularWifiMac::GetVOQueue (); dcf-&gt;SetMinCw ((cwmin + 1) / 4 - 1); dcf-&gt;SetMaxCw ((cwmin + 1) / 2 - 1); dcf-&gt;SetAifsn (aifsn); break; case AC_VI: dcf = RegularWifiMac::GetVIQueue (); dcf-&gt;SetMinCw ((cwmin + 1) / 2 - 1); dcf-&gt;SetMaxCw (cwmin); dcf-&gt;SetAifsn (aifsn); break; case AC_BE: dcf = RegularWifiMac::GetBEQueue (); dcf-&gt;SetMinCw (cwmin); dcf-&gt;SetMaxCw (cwmax); dcf-&gt;SetAifsn (aifsn); break; case AC_BK: dcf = RegularWifiMac::GetBKQueue (); dcf-&gt;SetMinCw (cwmin); dcf-&gt;SetMaxCw (cwmax); dcf-&gt;SetAifsn (aifsn); break; case AC_BE_NQOS: dcf = RegularWifiMac::GetTxop (); dcf-&gt;SetMinCw (cwmin); dcf-&gt;SetMaxCw (cwmax); dcf-&gt;SetAifsn (aifsn); break; case AC_UNDEF: NS_FATAL_ERROR ("I don't know what to do with this"); break; &#125;&#125; 这里AIFSN的取值为： AC_BE_NQOS: 2 AC_VO: 2 AC_VI: 3 AC_BE: 6 AC_BK: 9]]></content>
  </entry>
  <entry>
    <title><![CDATA[九一八事变前蒋张关于东北问题的讨论]]></title>
    <url>%2Fknowledge-base%2Fhistory%2F%E4%B8%AD%E5%9B%BD%E5%8F%B2%2F%E8%BF%91%E4%BB%A3%E5%8F%B2%2F%E6%B0%91%E5%9B%BD%2F%E5%8E%9F%E5%A7%8B%E5%8F%B2%E6%96%99%E9%9B%86%2F%E4%B9%9D%E4%B8%80%E5%85%AB%E4%BA%8B%E5%8F%98%E5%89%8D%E8%92%8B%E5%BC%A0%E5%85%B3%E4%BA%8E%E4%B8%9C%E5%8C%97%E9%97%AE%E9%A2%98%E7%9A%84%E8%AE%A8%E8%AE%BA.html</url>
    <content type="text"><![CDATA[其一 原文链接：知乎-理水的文章 日人对我国东北虎视眈眈已久。1931年夏以来，在东北，日本先后挑起万宝山事件和中村事件，在华北，挑动石友三叛乱，策动阎锡山回晋，迫使张学良抽调东北军精锐入关弹压局面。在这种情况下，蒋介石、张学良都预感到东北将有非常事件，并多次就东北问题进行讨论，最后达成采用“以不抵抗为抵抗”，寄望国联、依靠外交解决的战略方针。结合对岸新公布的资料，大致梳理一下九一八前蒋、张对于东北问题的讨论历程。 进入8月，东北局势日益紧张，驻沈独立第七旅王以哲派人到北平向张学良汇报，时任该旅参谋长的赵镇藩在《日军进攻北大营亲历记》中回忆： 基于上述种种情况，王以哲和我反复进行了研究，认为如果万一发生事变，我旅必将首当其冲。为了研究对策，遂于8月间召集第七旅上校以上军官和情报人员共同分析研究。大家一致判断必然要发生事故，当即将所得材料加以整理，交王以哲携赴北平向张学良报告，并请求将关内东北军调回一部分，以防万一。不久王以哲回沈阳，向我们传达了张学良的应变指示。王以哲说：“张副司令已经派人将情况报告了蒋介石，蒋指示暂不抵抗，准备好了再干，一切事先从外交解决；并告诉张学良要效法印度甘地对英国不合作的办法来应付日本，遇事要退让，军事上要避免冲突，外交上要采取拖延方针。”接着又接到张学良转来蒋介石的铣(8月16日)电，主要内容是：采取不抵抗政策，竭力退让，避免冲突，千万不要“逞一时之愤，置国家民族于不顾，希转饬遵照执行”等语。 虽然铣电原件至今尚未发现，但能够证伪该电的材料也并没有，甚至在九一八前，尚未见到一封蒋介石给张学良关于东北事件的电文。而近年来新披露的资料，恰好可以和铣电互相照应，可以说有力的佐证了该电的存在。 关于铣电，虽然原件未曾发现，但是九一八事变前日军方面曾接到了实际上一份“铣电”。这部分内容，参考其二。 8月24日，感到事态日趋严重的张学良致电陈群并转蒋介石，提出： 近来对日外交性情紧迫，彼国朝野上下公然密谋侵占我东北（彼方谓为满蒙），势甚积极，不可终日。弟曾尽力设法以谋疏解，终鲜效果，所有一切经维寅兄电达左右，荷蒙鉴誉，转呈总座，至深佩感。近数日来，情况益紧，……日人方面属有意动作，现已揭开面目，必将另造事端以为借口。似此情形，恐非退避所能了事。弟为此事，日夜焦虑，我兄卓识尽筹，对日外交研究有素，当此危急之时，我方应用何法以为应付，尚祈详赐指示并请密陈总座决定方策。弟意以为对立各种悬案应即与之开诚谈判，能解决者即解决之，其绝对不能许其要求者即拒绝之。为此了一件即少一件，而彼方即少一攻击之目标，是为釜底抽薪之计。总座明烛，几先对此必有良谋，亟望与外交方面负责人员切实商讨，指示遵行，不胜企祷。 这里的“似此情形，恐非退避所能了事”一句，显然意指之前蒋、张达成过“退避了事”的应对方略，这内容同铣电中提到的“采取不抵抗政策，竭力退让，避免冲突”是一致的。 电文1 电文2 8月28日，在官修《事略稿本》中，记载了蒋介石收到中村事件后的方应： 公叹曰：日人之侵略，其将日益加进乎 史略稿本原文 然而，蒋介石、张学良并没有调整应对策略。 9月6日，张学良发出给臧式毅、荣臻的“鱼电”，重申了铣电的要求 ： 现在日方外交渐趋吃紧，应付一切，亟宜力求稳慎。对于日人，无论其如何寻事，我方务当万方容忍，不可与之反抗，致酿事端。即希迅速密令各属，切实遵照注意为要。张学良。鱼子秘印。 不过张学良越发感到形势的严峻，两天之后的9月8日张学良发出给蒋介石的“限即刻到，不得停留”的齐申电，一方面表示已按蒋意下达鱼电（“特饬文武地方官竭力避免”），但同时报告日军有大规模入侵动向，希望蒋介石考虑应对措施： 日人于朝鲜暴动案发生后，百计寻事，特饬文武地方官竭力避免。近为中村失踪之事，由驻沈总领事严重交涉，语多挟制，东京方面陆军人员尤为激昂，显有借端侵略状态。我方已派人前往肇事地点详查，良不能亲自回辽，万分焦急。……内忧外患，应付殊难，仅密奉闻，敬乞指示。 电文3 按说张学良的齐申电规格已经相当之高（“限即刻到，不得停留”），用词已相当激动（内忧外患，应付殊难，仅密奉闻，敬乞指示），以张国府二把手的地位，蒋介石不可能没有表示，然而却没有齐申电的复电，这显然不合情理。但如果考虑何柱国在《“九一八”沈阳事变前后》记录的蒋张在石家庄的一次会面，那么蒋介石在接到张学良的齐申电后，决定和张面谈，就显得顺理成章： 张学良于九月十一日，在北平接到蒋介石的密电，叫他于十二日去石家庄与蒋会晤。那天上午，蒋、张分乘两辆专车，蒋介石的专车自汉口开来，张学良的专车从北平开来，就这样两个人都未下车，把两辆专车合拢后，在车厢里举行了秘密会谈。那时我正驻防在石家庄，得讯后提早在车站外围派部队布防警戒，以保安全；但专车及车站范围内，则均由蒋、张自带的卫队负责。 会谈后，张学良亲自告诉我，蒋介石对他说：“最近获得可靠情报，日军在东北马上要动手，我们的力量不足，不能打。我考虑到只有提请国际联盟主持正义，和平解决。我这次和你会面，最主要的是要你严令东北全军，凡遇到日军进攻，一律不准抵抗，如果我们回击了，事情就不好办了，明明是日军先开衅的，他们可以硬说是我们先打他的，他们的嘴大，我们的嘴小，到那时就分辩不清了。”过了一星期，九一八事变果然爆发了。 接下来，在官修《事略稿本》中，记载了蒋介石9月13日收到关东军高唱“击滅东北政权”的反应： 又闻日人高唱击滅东北政权，公曰：日人欲图东北，而其狡诈手段如此。其谁欺，欺天乎。独恨我国内之正多事耳。呜呼，岂天欲亡我中华乎。 事略稿本原文 9月14日，在官修《事略稿本》中，记载了蒋介石在得知日本进一步举动后方应，蒋介石考虑良久，仍然只是“严密注意”，寄望于这是日本的恫吓之举： 公考虑久之，曰：“日人之鬼魊诈险，吾当严密注意之也。” 事略稿本原文 可见，虽然各方情报让蒋介石虽然也感觉到事态严重，但蒋最后仍感“独恨我国内之正多事耳”，仍维持了既定的不抵抗立场。 不料，仅仅4天之后，蒋、张不愿意面对的“九一八”事变，还是发生了。 其二 原文链接：知乎-理水的文章 摘自《“九一八”全史》第一卷和第五卷（上）。 1、9月事变前陆海空总司令部给东北边防军司令长官公署密电。 密电内容 原文脚注标明密电内容如下：译自《日本外务省档案》，IMT523，《关东厅警务局长致外务次官信》，见该档案胶卷T66。 2、11月2日到5日江桥抗战决策过程 密电内容 密电内容 密电内容]]></content>
  </entry>
</search>
